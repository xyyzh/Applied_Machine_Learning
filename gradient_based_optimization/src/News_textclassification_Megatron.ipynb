{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "News_textclassification_Megatron.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1b484df892384de9851191eb580fa8ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fcc950e31563453984a32a4ce93b62bf",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_df7e784501af4a4f92af42a9225d89dd",
              "IPY_MODEL_1965dad504f548afab26b849ba5ce20a",
              "IPY_MODEL_512f33b85e6f415b8a1591a8ef3aac79"
            ]
          }
        },
        "fcc950e31563453984a32a4ce93b62bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "df7e784501af4a4f92af42a9225d89dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3bae5b274c5542678359faf653ab4a03",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_506adf1949ed4ae78b16d4ac96bd9e45"
          }
        },
        "1965dad504f548afab26b849ba5ce20a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cc9e16dbfe004821ba0872452663fda5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7a3449b8a8de4721adb40bf114cc4d79"
          }
        },
        "512f33b85e6f415b8a1591a8ef3aac79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_54d567f315f94df6ac00e2015f5d222b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 781B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6f380fbcff8a448b83ffa780b250065d"
          }
        },
        "3bae5b274c5542678359faf653ab4a03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "506adf1949ed4ae78b16d4ac96bd9e45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cc9e16dbfe004821ba0872452663fda5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7a3449b8a8de4721adb40bf114cc4d79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "54d567f315f94df6ac00e2015f5d222b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6f380fbcff8a448b83ffa780b250065d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d2ef5a2715eb4f24a02722ee44bbd70a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fa3d4030d0ed46e293e313353922268f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c55586f5cea14da4b800cc00e1372f23",
              "IPY_MODEL_a0f426aca08841b5ad1e2af732af2ebe",
              "IPY_MODEL_00d4007563eb4bcfb3127961b9141ff2"
            ]
          }
        },
        "fa3d4030d0ed46e293e313353922268f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c55586f5cea14da4b800cc00e1372f23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5a6dba5f50da434bb78c12729db68547",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_392230d82baf4ed89767a823589d7e9f"
          }
        },
        "a0f426aca08841b5ad1e2af732af2ebe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7d0b60e7978843e0b06ce61b834e3699",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 571,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 571,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9e62c3fc6f7e45889bf475a30f34e7d3"
          }
        },
        "00d4007563eb4bcfb3127961b9141ff2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_93753a7278d54c3e8b8ace34f66ac7eb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 571/571 [00:00&lt;00:00, 16.2kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_259b6a8b1b1b4077bd576d2fada488df"
          }
        },
        "5a6dba5f50da434bb78c12729db68547": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "392230d82baf4ed89767a823589d7e9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7d0b60e7978843e0b06ce61b834e3699": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9e62c3fc6f7e45889bf475a30f34e7d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "93753a7278d54c3e8b8ace34f66ac7eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "259b6a8b1b1b4077bd576d2fada488df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7116a35f61d9473c8d8db848948587c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2e3520434c5543e7971a321cf2be1d82",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_04bceeb432884e57af22fc371bbff15b",
              "IPY_MODEL_b1da165a7b9a4bec938b8bd89bb5f20b",
              "IPY_MODEL_60059fb56fc0429fa232af6ced446adc"
            ]
          }
        },
        "2e3520434c5543e7971a321cf2be1d82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "04bceeb432884e57af22fc371bbff15b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6a5fbdc055af491c862f03ba39ba99d2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0a3d92c5fec54166a894e8be6a82f2a9"
          }
        },
        "b1da165a7b9a4bec938b8bd89bb5f20b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6a7f4acd604e4afba9529f87ed1568f8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_97888bacb00f4dce8c932e6728d94e86"
          }
        },
        "60059fb56fc0429fa232af6ced446adc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2f638cd06e4a4e1a8e98afb7eed1a308",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 226k/226k [00:00&lt;00:00, 634kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_72970c6db6da45afa3273eca93122ab1"
          }
        },
        "6a5fbdc055af491c862f03ba39ba99d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0a3d92c5fec54166a894e8be6a82f2a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6a7f4acd604e4afba9529f87ed1568f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "97888bacb00f4dce8c932e6728d94e86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2f638cd06e4a4e1a8e98afb7eed1a308": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "72970c6db6da45afa3273eca93122ab1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8bba05a2552d47eba0ea40a66cba6a66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a5d3d2b8d1354b049c8c854bd176eaf6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_48ea48d47049446e903f011653716195",
              "IPY_MODEL_b6b3629768db401c900c0f01cf377ffc",
              "IPY_MODEL_e913a2adf84c499d852f9148ccae8e1c"
            ]
          }
        },
        "a5d3d2b8d1354b049c8c854bd176eaf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "48ea48d47049446e903f011653716195": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0f7ba1b159734c4198606fd34284aa28",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c2d879399b2b41baa5933fe523a5fe24"
          }
        },
        "b6b3629768db401c900c0f01cf377ffc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a1d329c2344543c7bfc8b426bb7cd277",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_399f4996d1f34fa1af49509339cd3a8e"
          }
        },
        "e913a2adf84c499d852f9148ccae8e1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_74c2bc9924794ff2bcb4ed077e386a3c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 455k/455k [00:00&lt;00:00, 839kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d6c85c097b0048a6af2de9d2a2a64bc4"
          }
        },
        "0f7ba1b159734c4198606fd34284aa28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c2d879399b2b41baa5933fe523a5fe24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a1d329c2344543c7bfc8b426bb7cd277": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "399f4996d1f34fa1af49509339cd3a8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "74c2bc9924794ff2bcb4ed077e386a3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d6c85c097b0048a6af2de9d2a2a64bc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c02e855193d64605965a6f881f44e914": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_db0ba14f1436449394315567f8cfd2ea",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1926458526a3497c961e728ac6b67dd2",
              "IPY_MODEL_5637b9f457a84ecfa7445b1e917c132d",
              "IPY_MODEL_ba1646195fee4f02a757f67ace4bc8fa"
            ]
          }
        },
        "db0ba14f1436449394315567f8cfd2ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "1926458526a3497c961e728ac6b67dd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_06cf4a0977b84fb5a1eb12100d5337d9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Epoch 0:   0%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cecd66b5c58f4aba88503a6f83480382"
          }
        },
        "5637b9f457a84ecfa7445b1e917c132d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d1fc52cc114449e49fb640a293eb4185",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 2750,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_49d83be84cea45d394cc24bd8ae33391"
          }
        },
        "ba1646195fee4f02a757f67ace4bc8fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7a15107f251e470086020b5809cd3afd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/2750 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eba1b67beab7435cb77bd8916eefc8b5"
          }
        },
        "06cf4a0977b84fb5a1eb12100d5337d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cecd66b5c58f4aba88503a6f83480382": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d1fc52cc114449e49fb640a293eb4185": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "49d83be84cea45d394cc24bd8ae33391": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7a15107f251e470086020b5809cd3afd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eba1b67beab7435cb77bd8916eefc8b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtTJdj6cCdfK"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import string\n",
        "from collections import defaultdict\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5j-m3ToREU7",
        "outputId": "bd8a8dc0-74af-4a91-ebb1-03d9334dbaf1"
      },
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "wn = WordNetLemmatizer()\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "ps = PorterStemmer()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shNlA-IxCnvH"
      },
      "source": [
        "DATA_DIR = os.path.join(os.getcwd(), 'DATA_DIR')\n",
        "RE_DATA_DIR = os.path.join(DATA_DIR, 'RE')\n",
        "WORK_DIR = os.path.join(os.getcwd(), 'WORK_DIR')\n",
        "MODEL_CONFIG = 'text_classification_config.yaml'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOdUGcrSCnoa"
      },
      "source": [
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "os.makedirs(os.path.join(DATA_DIR, 'RE'), exist_ok=True)\n",
        "os.makedirs(WORK_DIR, exist_ok=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTDISB_xCnic"
      },
      "source": [
        "ABS_PATH ='/content/DATA_DIR/RE/'\n",
        "RE_DATA_DIR = os.path.join(ABS_PATH, 'data')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xecJfiMKCncO"
      },
      "source": [
        "RE_DATA_DIR ='/content/DATA_DIR/RE'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cpFEJ-dCnWQ",
        "outputId": "344345f1-e967-4888-d060-b49bffa2c3b3"
      },
      "source": [
        "! ls -l $RE_DATA_DIR"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 77984\n",
            "-rw-r--r-- 1 root root  9484222 Oct 26 22:22 fake_news_test.csv\n",
            "-rw-r--r-- 1 root root 63830816 Oct 26 22:23 fake_news_train.csv\n",
            "-rw-r--r-- 1 root root  6533293 Oct 26 22:22 fake_news_val.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adws9fRXDKm9"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "fack_news = pd.read_csv('/content/DATA_DIR/RE/fake_news_train.csv')\n",
        "test = pd.read_csv('/content/DATA_DIR/RE/fake_news_test.csv')\n",
        "val = pd.read_csv('/content/DATA_DIR/RE/fake_news_val.csv')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DApGYHbns7RE"
      },
      "source": [
        "fack_news.isnull().sum()\n",
        "X_train = fack_news['text']\n",
        "y_train = fack_news['label']\n",
        "val.isnull().sum()\n",
        "X_vali = val['text']\n",
        "y_vali = val['label']\n",
        "test.isnull().sum()\n",
        "X_test = test['text']\n",
        "y_test = test['label']"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gw3jydIMtOl7",
        "outputId": "3f56e040-74f6-4eb7-e74a-b62670c7968d"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import nltk\n",
        "import string\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DNPoU4hs-GD",
        "outputId": "5b5b4fcb-53bf-4697-8170-94f88ba8075f"
      },
      "source": [
        "text_clf = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', LogisticRegression())\n",
        "])\n",
        "\n",
        "text_clf.fit(X_train, y_train)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vect',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, vocabulary=None)),\n",
              "                ('tfidf',\n",
              "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
              "                                  sublinear_tf=False, use_idf=True)),\n",
              "                ('clf',\n",
              "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='auto', n_jobs=None,\n",
              "                                    penalty='l2', random_state=None,\n",
              "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBsRhK-9s_kg",
        "outputId": "e5f025a1-91f7-47de-dad3-8748272c270f"
      },
      "source": [
        "predicted = text_clf.predict(X_vali)\n",
        "print(\"Validation accuracy:\", np.mean(predicted == y_vali))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy: 0.731\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A36Q0GUatB_3",
        "outputId": "97f4ad84-ef05-4475-805e-abe7d1a5c323"
      },
      "source": [
        "predicted = text_clf.predict(X_test)\n",
        "print(\"Testing accuracy:\", np.mean(predicted == y_test))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing accuracy: 0.71\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXhRMu162PgS"
      },
      "source": [
        "### Initial number of data:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZiu1H3L2aFS"
      },
      "source": [
        "### Data preprocessing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSqu7GGHLf-l"
      },
      "source": [
        "abbreviations = {\n",
        "    \"$\" : \" dollar \",\n",
        "    \"€\" : \" euro \",\n",
        "    \"4ao\" : \"for adults only\",\n",
        "    \"a.m\" : \"before midday\",\n",
        "    \"a3\" : \"anytime anywhere anyplace\",\n",
        "    \"aamof\" : \"as a matter of fact\",\n",
        "    \"acct\" : \"account\",\n",
        "    \"adih\" : \"another day in hell\",\n",
        "    \"afaic\" : \"as far as i am concerned\",\n",
        "    \"afaict\" : \"as far as i can tell\",\n",
        "    \"afaik\" : \"as far as i know\",\n",
        "    \"afair\" : \"as far as i remember\",\n",
        "    \"afk\" : \"away from keyboard\",\n",
        "    \"app\" : \"application\",\n",
        "    \n",
        "    \"approx\" : \"approximately\",\n",
        "    \"apps\" : \"applications\",\n",
        "    \"asap\" : \"as soon as possible\",\n",
        "    \"asl\" : \"age, sex, location\",\n",
        "    \"atk\" : \"at the keyboard\",\n",
        "    \"ave.\" : \"avenue\",\n",
        "    \"aymm\" : \"are you my mother\",\n",
        "    \"ayor\" : \"at your own risk\", \n",
        "    \"b&b\" : \"bed and breakfast\",\n",
        "    \"b+b\" : \"bed and breakfast\",\n",
        "    \"b.c\" : \"before christ\",\n",
        "    \"b2b\" : \"business to business\",\n",
        "    \"b2c\" : \"business to customer\",\n",
        "    \"b4\" : \"before\",\n",
        "    \"b4n\" : \"bye for now\",\n",
        "    \"b@u\" : \"back at you\",\n",
        "    \"bae\" : \"before anyone else\",\n",
        "    \"bak\" : \"back at keyboard\",\n",
        "    \"bbbg\" : \"bye bye be good\",\n",
        "    \"bbc\" : \"british broadcasting corporation\",\n",
        "    \"bbias\" : \"be back in a second\",\n",
        "    \"bbl\" : \"be back later\",\n",
        "    \"bbs\" : \"be back soon\",\n",
        "    \"be4\" : \"before\",\n",
        "    \"bfn\" : \"bye for now\",\n",
        "    \"blvd\" : \"boulevard\",\n",
        "    \"bout\" : \"about\",\n",
        "    \"brb\" : \"be right back\",\n",
        "    \"bros\" : \"brothers\",\n",
        "    \"brt\" : \"be right there\",\n",
        "    \"bsaaw\" : \"big smile and a wink\",\n",
        "     \"btw\" : \"by the way\",\n",
        "    \"bwl\" : \"bursting with laughter\",\n",
        "    \"c/o\" : \"care of\",\n",
        "    \"cet\" : \"central european time\",\n",
        "    \"cf\" : \"compare\",\n",
        "    \"cia\" : \"central intelligence agency\",\n",
        "    \"csl\" : \"can not stop laughing\",\n",
        "    \"cu\" : \"see you\",\n",
        "    \"cul8r\" : \"see you later\",\n",
        "    \"cv\" : \"curriculum vitae\",\n",
        "    \"cwot\" : \"complete waste of time\",\n",
        "    \"cya\" : \"see you\",\n",
        "    \"cyt\" : \"see you tomorrow\",\n",
        "    \"dae\" : \"does anyone else\",\n",
        "    \"dbmib\" : \"do not bother me i am busy\",\n",
        "    \"diy\" : \"do it yourself\",\n",
        "    \"dm\" : \"direct message\",\n",
        "    \"dwh\" : \"during work hours\",\n",
        "    \"e123\" : \"easy as one two three\",\n",
        "    \"eet\" : \"eastern european time\",\n",
        "    \"eg\" : \"example\",\n",
        "    \"embm\" : \"early morning business meeting\",\n",
        "    \"encl\" : \"enclosed\",\n",
        "    \"encl.\" : \"enclosed\",\n",
        "    \"etc\" : \"and so on\",\n",
        "    \"faq\" : \"frequently asked questions\",\n",
        "    \"fawc\" : \"for anyone who cares\",\n",
        "    \"fb\" : \"facebook\",\n",
        "    \"fc\" : \"fingers crossed\",\n",
        "    \"fig\" : \"figure\",\n",
        "    \"fimh\" : \"forever in my heart\", \n",
        "    \"ft.\" : \"feet\",\n",
        "    \"ft\" : \"featuring\",\n",
        "    \"ftl\" : \"for the loss\",\n",
        "    \"ftw\" : \"for the win\",\n",
        "    \"fwiw\" : \"for what it is worth\",\n",
        "    \"fyi\" : \"for your information\",\n",
        "    \"g9\" : \"genius\",\n",
        "    \"gahoy\" : \"get a hold of yourself\",\n",
        "    \"gal\" : \"get a life\",\n",
        "    \"gcse\" : \"general certificate of secondary education\",\n",
        "    \"gfn\" : \"gone for now\",\n",
        "    \"gg\" : \"good game\",\n",
        "    \"gl\" : \"good luck\",\n",
        "    \"glhf\" : \"good luck have fun\",\n",
        "    \"gmt\" : \"greenwich mean time\",\n",
        "    \"gmta\" : \"great minds think alike\",\n",
        "    \"gn\" : \"good night\",\n",
        "    \"g.o.a.t\" : \"greatest of all time\",\n",
        "    \"goat\" : \"greatest of all time\",\n",
        "    \"goi\" : \"get over it\",\n",
        "    \"gps\" : \"global positioning system\",\n",
        "    \"gr8\" : \"great\",\n",
        "    \"gratz\" : \"congratulations\",\n",
        "    \"gyal\" : \"girl\",\n",
        "    \"h&c\" : \"hot and cold\",\n",
        "    \"hp\" : \"horsepower\",\n",
        "    \"hr\" : \"hour\",\n",
        "    \"hrh\" : \"his royal highness\",\n",
        "    \"ht\" : \"height\",\n",
        "    \"ibrb\" : \"i will be right back\",\n",
        "    \"ic\" : \"i see\",\n",
        "    \"icq\" : \"i seek you\",\n",
        "    \"icymi\" : \"in case you missed it\",\n",
        "    \"idc\" : \"i do not care\",\n",
        "    \"idgadf\" : \"i do not give a damn fuck\",\n",
        "    \"idgaf\" : \"i do not give a fuck\",\n",
        "    \"idk\" : \"i do not know\",\n",
        "    \"ie\" : \"that is\",\n",
        "    \"i.e\" : \"that is\",\n",
        "    \"ifyp\" : \"i feel your pain\",\n",
        "    \"IG\" : \"instagram\",\n",
        "    \"iirc\" : \"if i remember correctly\",\n",
        "    \"ilu\" : \"i love you\",\n",
        "    \"ily\" : \"i love you\",\n",
        "    \"imho\" : \"in my humble opinion\",\n",
        "    \"imo\" : \"in my opinion\",\n",
        "    \"imu\" : \"i miss you\",\n",
        "    \"iow\" : \"in other words\",\n",
        "    \"irl\" : \"in real life\",\n",
        "    \"j4f\" : \"just for fun\",\n",
        "    \"jic\" : \"just in case\",\n",
        "    \"jk\" : \"just kidding\",\n",
        "    \"jsyk\" : \"just so you know\",\n",
        "    \"l8r\" : \"later\",\n",
        "    \"lb\" : \"pound\",\n",
        "    \"lbs\" : \"pounds\",\n",
        "    \"ldr\" : \"long distance relationship\",\n",
        "    \"lmao\" : \"laugh my ass off\",\n",
        "    \"lmfao\" : \"laugh my fucking ass off\",\n",
        "    \"lol\" : \"laughing out loud\",\n",
        "    \"ltd\" : \"limited\",\"ltns\" : \"long time no see\",\n",
        "    \"m8\" : \"mate\",\n",
        "    \"mf\" : \"motherfucker\",\n",
        "    \"mfs\" : \"motherfuckers\",\n",
        "    \"mfw\" : \"my face when\",\n",
        "    \"mofo\" : \"motherfucker\",\n",
        "    \"mph\" : \"miles per hour\",\n",
        "    \"mr\" : \"mister\",\n",
        "    \"mrw\" : \"my reaction when\",\n",
        "    \"ms\" : \"miss\",\n",
        "    \"mte\" : \"my thoughts exactly\",\n",
        "    \"nagi\" : \"not a good idea\",\n",
        "    \"nbc\" : \"national broadcasting company\",\n",
        "    \"nbd\" : \"not big deal\",\n",
        "    \"nfs\" : \"not for sale\",\n",
        "    \"ngl\" : \"not going to lie\",\n",
        "    \"nhs\" : \"national health service\",\n",
        "    \"nrn\" : \"no reply necessary\",\n",
        "    \"nsfl\" : \"not safe for life\",\n",
        "    \"nsfw\" : \"not safe for work\",\n",
        "    \"nth\" : \"nice to have\",\n",
        "    \"nvr\" : \"never\",\n",
        "    \"nyc\" : \"new york city\",\n",
        "    \"oc\" : \"original content\",\n",
        "    \"og\" : \"original\",\n",
        "    \"ohp\" : \"overhead projector\",\n",
        "    \"oic\" : \"oh i see\",\n",
        "    \"omdb\" : \"over my dead body\",\n",
        "    \"omg\" : \"oh my god\",\n",
        "    \"omw\" : \"on my way\",\n",
        "    \"p.a\" : \"per annum\",\n",
        "    \"p.m\" : \"after midday\",\n",
        "    \"pm\" : \"prime minister\",\n",
        "    \"poc\" : \"people of color\",\n",
        "    \"pov\" : \"point of view\",\n",
        "    \"pp\" : \"pages\",\n",
        "    \"ppl\" : \"people\",\n",
        "    \"prw\" : \"parents are watching\",\n",
        "    \"ps\" : \"postscript\",\n",
        "    \"pt\" : \"point\",\n",
        "    \"ptb\" : \"please text back\",\n",
        "    \"pto\" : \"please turn over\",\n",
        "    \"qpsa\" : \"what happens\", #\"que pasa\",\n",
        "    \"ratchet\" : \"rude\",\n",
        "    \"rbtl\" : \"read between the lines\",\n",
        "    \"rlrt\" : \"real life retext\", \n",
        "    \"rofl\" : \"rolling on the floor laughing\",\n",
        "    \"roflol\" : \"rolling on the floor laughing out loud\",\n",
        "    \"rotflmao\" : \"rolling on the floor laughing my ass off\",\n",
        "    \"rt\" : \"retext\",\n",
        "    \"ruok\" : \"are you ok\",\n",
        "    \"sfw\" : \"safe for work\",\n",
        "    \"sk8\" : \"skate\",\n",
        "    \"smh\" : \"shake my head\",\n",
        "    \"sq\" : \"square\",\n",
        "    \"srsly\" : \"seriously\", \n",
        "    \"ssdd\" : \"same stuff different day\",\n",
        "    \"tbh\" : \"to be honest\",\n",
        "    \"tbs\" : \"tablespooful\",\n",
        "    \"tbsp\" : \"tablespooful\",\n",
        "    \"tfw\" : \"that feeling when\",\n",
        "    \"thks\" : \"thank you\",\n",
        "    \"tho\" : \"though\",\n",
        "    \"thx\" : \"thank you\",\n",
        "    \"tia\" : \"thanks in advance\",\n",
        "    \"til\" : \"today i learned\",\n",
        "    \"tl;dr\" : \"too long i did not read\",\n",
        "    \"tldr\" : \"too long i did not read\",\n",
        "    \"tmb\" : \"tweet me back\",\n",
        "    \"tntl\" : \"trying not to laugh\",\n",
        "    \"ttyl\" : \"talk to you later\",\n",
        "    \"u\" : \"you\",\n",
        "    \"u2\" : \"you too\",\n",
        "    \"u4e\" : \"yours for ever\",\n",
        "    \"utc\" : \"coordinated universal time\",\n",
        "    \"w/\" : \"with\",\n",
        "    \"w/o\" : \"without\",\n",
        "    \"w8\" : \"wait\",\n",
        "    \"wassup\" : \"what is up\",\n",
        "    \"wb\" : \"welcome back\",\n",
        "    \"wtf\" : \"what the fuck\",\n",
        "    \"wtg\" : \"way to go\",\n",
        "    \"wtpa\" : \"where the party at\",\n",
        "    \"wuf\" : \"where are you from\",\n",
        "    \"wuzup\" : \"what is up\",\n",
        "    \"wywh\" : \"wish you were here\",\n",
        "    \"yd\" : \"yard\",\n",
        "    \"ygtr\" : \"you got that right\",\n",
        "    \"ynk\" : \"you never know\",\n",
        "    \"zzz\" : \"sleeping bored and tired\",\n",
        "    \"pic\" : \"picture\"\n",
        "}"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfofsH33Llep"
      },
      "source": [
        "def word_abbrev(word):\n",
        "    return abbreviations[word.lower()] if word.lower() in abbreviations.keys() else word\n",
        "\n",
        "# Replace all abbreviations\n",
        "def replace_abbrev(text):\n",
        "    string = \"\"\n",
        "    for word in text.split():\n",
        "        string += word_abbrev(word) + \" \"        \n",
        "    return string"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0L3fJRF7cQ8y"
      },
      "source": [
        "fack_news['text'] = fack_news['text'].apply(lambda x : replace_abbrev(x))\n",
        "test['text'] = test['text'].apply(lambda x : replace_abbrev(x))\n",
        "val['text'] = val['text'].apply(lambda x : replace_abbrev(x))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_tuUfk9Jqej"
      },
      "source": [
        "EMOTICONS = {\n",
        "    u\":‑\\)\":\"Happy face or smiley\",\n",
        "    u\":\\)\":\"Happy face or smiley\",\n",
        "    u\":-\\]\":\"Happy face or smiley\",\n",
        "    u\":\\]\":\"Happy face or smiley\",\n",
        "    u\":-3\":\"Happy face smiley\",\n",
        "    u\":3\":\"Happy face smiley\",\n",
        "    u\":->\":\"Happy face smiley\",\n",
        "    u\":>\":\"Happy face smiley\",\n",
        "    u\"8-\\)\":\"Happy face smiley\",\n",
        "    u\":o\\)\":\"Happy face smiley\",\n",
        "    u\":-\\}\":\"Happy face smiley\",\n",
        "    u\":\\}\":\"Happy face smiley\",\n",
        "    u\":-\\)\":\"Happy face smiley\",\n",
        "    u\":c\\)\":\"Happy face smiley\",\n",
        "    u\":\\^\\)\":\"Happy face smiley\",\n",
        "    u\"=\\]\":\"Happy face smiley\",\n",
        "    u\"=\\)\":\"Happy face smiley\",\n",
        "    u\":‑D\":\"Laughing, big grin or laugh with glasses\",\n",
        "    u\":D\":\"Laughing, big grin or laugh with glasses\",\n",
        "    u\"8‑D\":\"Laughing, big grin or laugh with glasses\",\n",
        "    u\"8D\":\"Laughing, big grin or laugh with glasses\",\n",
        "    u\"X‑D\":\"Laughing, big grin or laugh with glasses\",\n",
        "    u\"XD\":\"Laughing, big grin or laugh with glasses\",\n",
        "    u\"=D\":\"Laughing, big grin or laugh with glasses\",\n",
        "    u\"=3\":\"Laughing, big grin or laugh with glasses\",\n",
        "    u\"B\\^D\":\"Laughing, big grin or laugh with glasses\",\n",
        "    u\":-\\)\\)\":\"Very happy\",\n",
        "    u\":‑\\(\":\"Frown, sad, andry or pouting\",\n",
        "    u\":-\\(\":\"Frown, sad, andry or pouting\",\n",
        "    u\":\\(\":\"Frown, sad, andry or pouting\",\n",
        "    u\":‑c\":\"Frown, sad, andry or pouting\",\n",
        "    u\":c\":\"Frown, sad, andry or pouting\",\n",
        "    u\":‑<\":\"Frown, sad, andry or pouting\",\n",
        "    u\":<\":\"Frown, sad, andry or pouting\",\n",
        "    u\":‑\\[\":\"Frown, sad, andry or pouting\",\n",
        "    u\":\\[\":\"Frown, sad, andry or pouting\",\n",
        "    u\":-\\|\\|\":\"Frown, sad, andry or pouting\",\n",
        "    u\">:\\[\":\"Frown, sad, andry or pouting\",\n",
        "    u\":\\{\":\"Frown, sad, andry or pouting\",\n",
        "    u\":@\":\"Frown, sad, andry or pouting\",\n",
        "    u\">:\\(\":\"Frown, sad, andry or pouting\",\n",
        "    u\":'‑\\(\":\"Crying\",\n",
        "    u\":'\\(\":\"Crying\",\n",
        "    u\":'‑\\)\":\"Tears of happiness\",\n",
        "    u\":'\\)\":\"Tears of happiness\",\n",
        "    u\"D‑':\":\"Horror\",\n",
        "    u\"D:<\":\"Disgust\",\n",
        "    u\"D:\":\"Sadness\",\n",
        "    u\"D8\":\"Great dismay\",\n",
        "    u\"D;\":\"Great dismay\",\n",
        "    u\"D=\":\"Great dismay\",\n",
        "    u\"DX\":\"Great dismay\",\n",
        "    u\":‑O\":\"Surprise\",\n",
        "    u\":O\":\"Surprise\",\n",
        "    u\":‑o\":\"Surprise\",\n",
        "    u\":o\":\"Surprise\",\n",
        "    u\":-0\":\"Shock\",\n",
        "    u\"8‑0\":\"Yawn\",\n",
        "    u\">:O\":\"Yawn\",\n",
        "    u\":-\\*\":\"Kiss\",\n",
        "    u\":\\*\":\"Kiss\",\n",
        "    u\":X\":\"Kiss\",\n",
        "    u\";‑\\)\":\"Wink or smirk\",\n",
        "    u\";\\)\":\"Wink or smirk\",\n",
        "    u\"\\*-\\)\":\"Wink or smirk\",\n",
        "    u\"\\*\\)\":\"Wink or smirk\",\n",
        "    u\";‑\\]\":\"Wink or smirk\",\n",
        "    u\";\\]\":\"Wink or smirk\",\n",
        "    u\";\\^\\)\":\"Wink or smirk\",\n",
        "    u\":‑,\":\"Wink or smirk\",\n",
        "    u\";D\":\"Wink or smirk\",\n",
        "    u\":‑P\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
        "    u\":P\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
        "    u\"X‑P\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
        "    u\"XP\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
        "    u\":‑Þ\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
        "    u\":Þ\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
        "    u\":b\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
        "    u\"d:\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
        "    u\"=p\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
        "    u\">:P\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
        "    u\":‑/\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
        "    u\":/\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
        "    u\":-[.]\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
        "    u\">:[(\\\\\\)]\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
        "    u\">:/\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
        "    u\":[(\\\\\\)]\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
        "    u\"=/\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
        "    u\"=[(\\\\\\)]\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
        "    u\":L\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
        "    u\"=L\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
        "    u\":S\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
        "    u\":‑\\|\":\"Straight face\",\n",
        "    u\":\\|\":\"Straight face\",\n",
        "    u\":$\":\"Embarrassed or blushing\",\n",
        "    u\":‑x\":\"Sealed lips or wearing braces or tongue-tied\",\n",
        "    u\":x\":\"Sealed lips or wearing braces or tongue-tied\",\n",
        "    u\":‑#\":\"Sealed lips or wearing braces or tongue-tied\",\n",
        "    u\":#\":\"Sealed lips or wearing braces or tongue-tied\",\n",
        "    u\":‑&\":\"Sealed lips or wearing braces or tongue-tied\",\n",
        "    u\":&\":\"Sealed lips or wearing braces or tongue-tied\",\n",
        "    u\"O:‑\\)\":\"Angel, saint or innocent\",\n",
        "    u\"O:\\)\":\"Angel, saint or innocent\",\n",
        "    u\"0:‑3\":\"Angel, saint or innocent\",\n",
        "    u\"0:3\":\"Angel, saint or innocent\",\n",
        "    u\"0:‑\\)\":\"Angel, saint or innocent\",\n",
        "    u\"0:\\)\":\"Angel, saint or innocent\",\n",
        "    u\":‑b\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
        "    u\"0;\\^\\)\":\"Angel, saint or innocent\",\n",
        "    u\">:‑\\)\":\"Evil or devilish\",\n",
        "    u\">:\\)\":\"Evil or devilish\",\n",
        "    u\"\\}:‑\\)\":\"Evil or devilish\",\n",
        "    u\"\\}:\\)\":\"Evil or devilish\",\n",
        "    u\"3:‑\\)\":\"Evil or devilish\",\n",
        "    u\"3:\\)\":\"Evil or devilish\",\n",
        "    u\">;\\)\":\"Evil or devilish\",\n",
        "    u\"\\|;‑\\)\":\"Cool\",\n",
        "    u\"\\|‑O\":\"Bored\",\n",
        "    u\":‑J\":\"Tongue-in-cheek\",\n",
        "    u\"#‑\\)\":\"Party all night\",\n",
        "    u\"%‑\\)\":\"Drunk or confused\",\n",
        "    u\"%\\)\":\"Drunk or confused\",\n",
        "    u\":-###..\":\"Being sick\",\n",
        "    u\":###..\":\"Being sick\",\n",
        "    u\"<:‑\\|\":\"Dump\",\n",
        "    u\"\\(>_<\\)\":\"Troubled\",\n",
        "    u\"\\(>_<\\)>\":\"Troubled\",\n",
        "    u\"\\(';'\\)\":\"Baby\",\n",
        "    u\"\\(\\^\\^>``\":\"Nervous or Embarrassed or Troubled or Shy or Sweat drop\",\n",
        "    u\"\\(\\^_\\^;\\)\":\"Nervous or Embarrassed or Troubled or Shy or Sweat drop\",\n",
        "    u\"\\(-_-;\\)\":\"Nervous or Embarrassed or Troubled or Shy or Sweat drop\",\n",
        "    u\"\\(~_~;\\) \\(・\\.・;\\)\":\"Nervous or Embarrassed or Troubled or Shy or Sweat drop\",\n",
        "    u\"\\(-_-\\)zzz\":\"Sleeping\",\n",
        "    u\"\\(\\^_-\\)\":\"Wink\",\n",
        "    u\"\\(\\(\\+_\\+\\)\\)\":\"Confused\",\n",
        "    u\"\\(\\+o\\+\\)\":\"Confused\",\n",
        "    u\"\\(o\\|o\\)\":\"Ultraman\",\n",
        "    u\"\\^_\\^\":\"Joyful\",\n",
        "    u\"\\(\\^_\\^\\)/\":\"Joyful\",\n",
        "    u\"\\(\\^O\\^\\)／\":\"Joyful\",\n",
        "    u\"\\(\\^o\\^\\)／\":\"Joyful\",\n",
        "    u\"\\(__\\)\":\"Kowtow as a sign of respect, or dogeza for apology\",\n",
        "    u\"_\\(\\._\\.\\)_\":\"Kowtow as a sign of respect, or dogeza for apology\",\n",
        "    u\"<\\(_ _\\)>\":\"Kowtow as a sign of respect, or dogeza for apology\",\n",
        "    u\"<m\\(__\\)m>\":\"Kowtow as a sign of respect, or dogeza for apology\",\n",
        "    u\"m\\(__\\)m\":\"Kowtow as a sign of respect, or dogeza for apology\",\n",
        "    u\"m\\(_ _\\)m\":\"Kowtow as a sign of respect, or dogeza for apology\",\n",
        "    u\"\\('_'\\)\":\"Sad or Crying\",\n",
        "    u\"\\(/_;\\)\":\"Sad or Crying\",\n",
        "    u\"\\(T_T\\) \\(;_;\\)\":\"Sad or Crying\",\n",
        "    u\"\\(;_;\":\"Sad of Crying\",\n",
        "    u\"\\(;_:\\)\":\"Sad or Crying\",\n",
        "    u\"\\(;O;\\)\":\"Sad or Crying\",\n",
        "    u\"\\(:_;\\)\":\"Sad or Crying\",\n",
        "    u\"\\(ToT\\)\":\"Sad or Crying\",\n",
        "    u\";_;\":\"Sad or Crying\",\n",
        "    u\";-;\":\"Sad or Crying\",\n",
        "    u\";n;\":\"Sad or Crying\",\n",
        "    u\";;\":\"Sad or Crying\",\n",
        "    u\"Q\\.Q\":\"Sad or Crying\",\n",
        "    u\"T\\.T\":\"Sad or Crying\",\n",
        "    u\"QQ\":\"Sad or Crying\",\n",
        "    u\"Q_Q\":\"Sad or Crying\",\n",
        "    u\"\\(-\\.-\\)\":\"Shame\",\n",
        "    u\"\\(-_-\\)\":\"Shame\",\n",
        "    u\"\\(一一\\)\":\"Shame\",\n",
        "    u\"\\(；一_一\\)\":\"Shame\",\n",
        "    u\"\\(=_=\\)\":\"Tired\",\n",
        "    u\"\\(=\\^\\·\\^=\\)\":\"cat\",\n",
        "    u\"\\(=\\^\\·\\·\\^=\\)\":\"cat\",\n",
        "    u\"=_\\^=\t\":\"cat\",\n",
        "    u\"\\(\\.\\.\\)\":\"Looking down\",\n",
        "    u\"\\(\\._\\.\\)\":\"Looking down\",\n",
        "    u\"\\^m\\^\":\"Giggling with hand covering mouth\",\n",
        "    u\"\\(\\・\\・?\":\"Confusion\",\n",
        "    u\"\\(?_?\\)\":\"Confusion\",\n",
        "    u\">\\^_\\^<\":\"Normal Laugh\",\n",
        "    u\"<\\^!\\^>\":\"Normal Laugh\",\n",
        "    u\"\\^/\\^\":\"Normal Laugh\",\n",
        "    u\"\\（\\*\\^_\\^\\*）\" :\"Normal Laugh\",\n",
        "    u\"\\(\\^<\\^\\) \\(\\^\\.\\^\\)\":\"Normal Laugh\",\n",
        "    u\"\\(^\\^\\)\":\"Normal Laugh\",\n",
        "    u\"\\(\\^\\.\\^\\)\":\"Normal Laugh\",\n",
        "    u\"\\(\\^_\\^\\.\\)\":\"Normal Laugh\",\n",
        "    u\"\\(\\^_\\^\\)\":\"Normal Laugh\",\n",
        "    u\"\\(\\^\\^\\)\":\"Normal Laugh\",\n",
        "    u\"\\(\\^J\\^\\)\":\"Normal Laugh\",\n",
        "    u\"\\(\\*\\^\\.\\^\\*\\)\":\"Normal Laugh\",\n",
        "    u\"\\(\\^—\\^\\）\":\"Normal Laugh\",\n",
        "    u\"\\(#\\^\\.\\^#\\)\":\"Normal Laugh\",\n",
        "    u\"\\（\\^—\\^\\）\":\"Waving\",\n",
        "    u\"\\(;_;\\)/~~~\":\"Waving\",\n",
        "    u\"\\(\\^\\.\\^\\)/~~~\":\"Waving\",\n",
        "    u\"\\(-_-\\)/~~~ \\($\\·\\·\\)/~~~\":\"Waving\",\n",
        "    u\"\\(T_T\\)/~~~\":\"Waving\",\n",
        "    u\"\\(ToT\\)/~~~\":\"Waving\",\n",
        "    u\"\\(\\*\\^0\\^\\*\\)\":\"Excited\",\n",
        "    u\"\\(\\*_\\*\\)\":\"Amazed\",\n",
        "    u\"\\(\\*_\\*;\":\"Amazed\",\n",
        "    u\"\\(\\+_\\+\\) \\(@_@\\)\":\"Amazed\",\n",
        "    u\"\\(\\*\\^\\^\\)v\":\"Laughing,Cheerful\",\n",
        "    u\"\\(\\^_\\^\\)v\":\"Laughing,Cheerful\",\n",
        "    u\"\\(\\(d[-_-]b\\)\\)\":\"Headphones,Listening to music\",\n",
        "    u'\\(-\"-\\)':\"Worried\",\n",
        "    u\"\\(ーー;\\)\":\"Worried\",\n",
        "    u\"\\(\\^0_0\\^\\)\":\"Eyeglasses\",\n",
        "    u\"\\(\\＾ｖ\\＾\\)\":\"Happy\",\n",
        "    u\"\\(\\＾ｕ\\＾\\)\":\"Happy\",\n",
        "    u\"\\(\\^\\)o\\(\\^\\)\":\"Happy\",\n",
        "    u\"\\(\\^O\\^\\)\":\"Happy\",\n",
        "    u\"\\(\\^o\\^\\)\":\"Happy\",\n",
        "    u\"\\)\\^o\\^\\(\":\"Happy\",\n",
        "    u\":O o_O\":\"Surprised\",\n",
        "    u\"o_0\":\"Surprised\",\n",
        "    u\"o\\.O\":\"Surpised\",\n",
        "    u\"\\(o\\.o\\)\":\"Surprised\",\n",
        "    u\"oO\":\"Surprised\",\n",
        "    u\"\\(\\*￣m￣\\)\":\"Dissatisfied\",\n",
        "    u\":  )\":\" \",\n",
        "    u\"\\(‘A`\\)\":\"Snubbed or Deflated\"\n",
        "}"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smbtRGyDJKub"
      },
      "source": [
        "def remove_emoticons(text):\n",
        "    emoticon_pattern = re.compile(u'(' + u'|'.join(k for k in EMOTICONS) + u')')\n",
        "    return emoticon_pattern.sub(r'', text)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VS6pv-LPM9Vm"
      },
      "source": [
        "def remove_not_ASCII(text):\n",
        "    text = ''.join([word for word in text if word in string.printable])\n",
        "    return text"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5SRRKzlNOP_"
      },
      "source": [
        "def remove_punct(text):\n",
        "    punctuations = '@#!?+&*[]-%.:/();$=><|{}^' + \"'`\" \n",
        "    for p in punctuations:\n",
        "        text = text.replace(p, f' {p} ')\n",
        "\n",
        "    text = text.replace('...', '.')\n",
        "    if '...' not in text:\n",
        "        text = text.replace('..', '.')   \n",
        "    return text"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKBVTlWaN_yZ"
      },
      "source": [
        "def remove_mention(text):\n",
        "    text = text.replace(\"@ \", \"@\")\n",
        "    at=re.compile(r'@\\S+')\n",
        "    return at.sub(r'',text)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2d2nArG7OJen"
      },
      "source": [
        "def remove_HTML(text):\n",
        "    html=re.compile(r'<.*?>')\n",
        "    return html.sub(r'',text)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WCJf_CnMS7O"
      },
      "source": [
        "def data_clean(text):\n",
        "    text = remove_not_ASCII(text)\n",
        "    text = remove_HTML(text)\n",
        "    text = text.lower()\n",
        "    text = remove_mention(text)\n",
        "    text = remove_punct(text)\n",
        "    return text"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzaDiuGIHLur"
      },
      "source": [
        "fack_news['text'] = fack_news['text'].apply(lambda x : data_clean(x))\n",
        "test['text'] = test['text'].apply(lambda x : data_clean(x))\n",
        "val['text'] = val['text'].apply(lambda x : data_clean(x))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vk6OBdauPYpp"
      },
      "source": [
        "fack_news['text'].replace('', np.nan, inplace=True)\n",
        "fack_news['text'].dropna(axis='rows',inplace=True)\n",
        "\n",
        "test['text'].replace('', np.nan, inplace=True)\n",
        "test['text'].dropna(axis='rows',inplace=True)\n",
        "\n",
        "val['text'].replace('', np.nan, inplace=True)\n",
        "val['text'].dropna(axis='rows',inplace=True)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGBaQWj3MYsE"
      },
      "source": [
        "def move_whitespace(text):\n",
        "    text = text.replace('  ', ' ') \n",
        "    return text"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfF0M-n3MsRs"
      },
      "source": [
        "fack_news['text'] = fack_news['text'].apply(lambda x : move_whitespace(x))\n",
        "test['text'] = test['text'].apply(lambda x : move_whitespace(x))\n",
        "val['text'] = val['text'].apply(lambda x : move_whitespace(x))"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQ73dM8URiNG"
      },
      "source": [
        "def tokenize(text):\n",
        "    split=re.split(\"\\W+\",text) \n",
        "    return split"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xf_s78fAQ0-0"
      },
      "source": [
        "stopword = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    text=[word for word in text if word not in stopword]\n",
        "    return text"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnyir-8sQ8yn"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "  \n",
        "lemmatizer=nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_text(word_list):\n",
        "    lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n",
        "    return lemmatized_output"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMAS8X3aRsOn"
      },
      "source": [
        "def remove_tokenizer(text):\n",
        "    text = tokenize(text)\n",
        "    text = remove_stopwords(text)\n",
        "    text = lemmatize_text(text)\n",
        "    return text"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiR_Ge13R5sJ"
      },
      "source": [
        "fack_news['text'] = fack_news['text'].apply(lambda x : remove_tokenizer(x))\n",
        "test['text'] = test['text'].apply(lambda x : remove_tokenizer(x))\n",
        "val['text'] = val['text'].apply(lambda x : remove_tokenizer(x))"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPQAiuMDwqgF"
      },
      "source": [
        "def remove_number(text):\n",
        "    num = re.compile(r'[-+]?[.\\d]*[\\d]+[:,.\\d]*')\n",
        "    return num.sub(r' ', text)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHgccUvqUPyB"
      },
      "source": [
        "fack_news['text'] = fack_news['text'].apply(lambda x : remove_number(x))\n",
        "test['text'] = test['text'].apply(lambda x : remove_number(x))\n",
        "val['text'] = val['text'].apply(lambda x : remove_number(x))"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WVvwyOX4jb6"
      },
      "source": [
        "replace_words = {\n",
        "    \"u\" : \"you\",\n",
        "    \"wasnt\" : \"was not\",\n",
        "    \"werent\" : \"were not\",\n",
        "    \"isnt\" : \"is not\",\n",
        "    \"arent\" : \"are not\",\n",
        "    \"hadnt\" : \"had not\",\n",
        "    \"havent\" : \"have not\",\n",
        "    \"saaaaame\" : \"same\",\n",
        "    \"dont\" : \"do not\",\n",
        "    \"doesnt\" : \"does not\",\n",
        "    \"thats\" : \"that is\",\n",
        "    \"youll\" : \"you all\",\n",
        "    \"whats\" : \"what is\",\n",
        "    \"wouldnt\" : \"would not\",\n",
        "    \"ill\" : \"I will\", \n",
        "    \"i\" : \"I\", \n",
        "    \"im\" : \"I am\",\n",
        "    \"ive\" : \"I have\", \n",
        "    \"theyre\" : \"they are\",\n",
        "    \"youre\" : \"you are\",\n",
        "    \"theyll\" : \"they will\",\n",
        "    \"didnt\" : \"did not\",\n",
        "    \"cant\" : \"can not\",\n",
        "    \"couldnt\" : \"could not\",\n",
        "    \"id\" : \"I would\",\n",
        "    \"youd\" : \"you would\",\n",
        "    \"wed\" : \"we would\",\n",
        "    \"theyd\" : \"they would\",\n",
        "    \"mi\" : \"mile\",\n",
        "    \"wouldve\" : \"would have\",\n",
        "    \"couldve\" : \"could have\",\n",
        "    \"youve\" : \"you have\",\n",
        "    \"weve\" : \"we have\",\n",
        "    \"theyve\" : \"they have\",\n",
        "    \"info\" : \"information\",\n",
        "    \"nooooo\" : \"no\",\n",
        "    \"cannot\" : \"can not\",\n",
        "    \"fwd\" : \"forward\",\n",
        "    \"mi\" : \"mile\",\n",
        "    \"veg\" : \"vegtable\",\n",
        "    \"yeeeeeeees\" : \"yes\",\n",
        "    \"waaaaaaay\" : \"way\", \n",
        "    \"muuuuuuuch\" : \"much\", \n",
        "    \"neverrrrrr\" : \"never\",\n",
        "    \"noooo\" : \"no\",\n",
        "    \"evverrr\" : \"ever\",\n",
        "    \"rwd\" : 'Rear Wheel Drive',\n",
        "    \"lb\" : \"pound\",\n",
        "    \"lbs\" : \"pounds\",\n",
        "    \"mr\" : \"mister\",\n",
        "    \"mrw\" : \"my reaction when\",\n",
        "    \"ms\" : \"miss\",\n",
        "    \"etc\" : \"and so on\"\n",
        "}"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23PfU3P37WTj"
      },
      "source": [
        "def word_replace(word):\n",
        "    return replace_words[word.lower()] if word.lower() in replace_words.keys() else word\n",
        "\n",
        "def replace_unsuitable(text):\n",
        "    string = \"\"\n",
        "    for word in text.split():\n",
        "        string += word_replace(word) + \" \"        \n",
        "    return string"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeuCuwPO7zDX"
      },
      "source": [
        "fack_news['text'] = fack_news['text'].apply(lambda x : replace_unsuitable(x))\n",
        "test['text'] = test['text'].apply(lambda x : replace_unsuitable(x))\n",
        "val['text'] = val['text'].apply(lambda x : replace_unsuitable(x))"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXj4bo_DoRlV"
      },
      "source": [
        "fack_news['text'] = fack_news['text'].apply(lambda x : replace_abbrev(x))\n",
        "test['text'] = test['text'].apply(lambda x : replace_abbrev(x))\n",
        "val['text'] = val['text'].apply(lambda x : replace_abbrev(x))"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcF6dfES2FNQ"
      },
      "source": [
        "Remove special words in the datasets such as month, week: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkgC7WXWHnOL"
      },
      "source": [
        "word_list = ['january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', 'october','november', 'decenber', 'week', 'month', 'year', 'ago', 'one', 'two', 'three','four','five','six','seven', 'eight','nine','old','ooh']"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0UnD_6qIjh9"
      },
      "source": [
        "pat = r'\\b(?:{})\\b'.format('|'.join(word_list))\n",
        "fack_news['text'] = fack_news['text'].str.replace(pat, '')\n",
        "test['text'] = test['text'].str.replace(pat, '')\n",
        "val['text'] = val['text'].str.replace(pat, '')"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tqoXm9z192Q"
      },
      "source": [
        "Remove single words except \"I\", \" \", \"i\" and \"a\":"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBp_wzcCS76T",
        "outputId": "a9b69aaa-352d-4481-a529-ca79eb762b05"
      },
      "source": [
        "single = []\n",
        "for i in range(0, len(fack_news)):\n",
        "    temp = fack_news.iloc[i]['text']\n",
        "    for j in range(0, len(temp)-2):\n",
        "        k = j+2\n",
        "        h = j+1\n",
        "        if temp[j] == temp[k] == ' ':\n",
        "            single.append(temp[h])\n",
        "#print(single)\n",
        "symbol = []\n",
        "for i in single:\n",
        "    if i not in symbol:\n",
        "        if i != ' ':\n",
        "            if i != 'I':\n",
        "                if i != 'i':\n",
        "                    if i != 'a':\n",
        "                        symbol.append(i) \n",
        "print(symbol)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['g', 'p', 's', 'm', 'l', 'r', 'b', 'e', 'k', 'j', 'f', 'x', 'v', '_', 'w', 'c', 'd', 'n', 'h', 'z', 'q', 'o', 't', 'y']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKaCrQYDUNkh"
      },
      "source": [
        "pat = r'\\b(?:{})\\b'.format('|'.join(symbol))\n",
        "fack_news['text'] = fack_news['text'].str.replace(pat, '')\n",
        "test['text'] = test['text'].str.replace(pat, '')\n",
        "val['text'] = val['text'].str.replace(pat, '')"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5jKXCm7z1GI"
      },
      "source": [
        "def move_white(text):\n",
        "    text = text.replace('   ', ' ') \n",
        "    text = text.replace('  ', ' ')\n",
        "    return text "
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHiAMw1uz63H"
      },
      "source": [
        "fack_news['text'] = fack_news['text'].apply(lambda x : move_white(x))\n",
        "test['text'] = test['text'].apply(lambda x : move_white(x))\n",
        "val['text'] = val['text'].apply(lambda x : move_white(x))"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Y68gkG913Ax"
      },
      "source": [
        "To check whether there are any oral words, such as oooh, helllo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cB0_-VNbX71P"
      },
      "source": [
        "for i in range(0, len(fack_news)):\n",
        "    temp = fack_news.iloc[i]['text']\n",
        "    if j in range(0, len(temp)-2):\n",
        "        k = j+2\n",
        "        h = j+1\n",
        "        if str(temp[j]) == str(temp[k]) == str(temp[h]):\n",
        "            print(fack_news.iloc[i]['text'])"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weKtYlc8uDLv"
      },
      "source": [
        "fack_news.isnull().sum()\n",
        "X_train = fack_news['text']\n",
        "y_train = fack_news['label']\n",
        "val.isnull().sum()\n",
        "X_vali = val['text']\n",
        "y_vali = val['label']\n",
        "test.isnull().sum()\n",
        "X_test = test['text']\n",
        "y_test = test['label']"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoUlwyP4uHwf",
        "outputId": "17fa8a27-68ce-4338-c960-4ec6e71cfc14"
      },
      "source": [
        "text_clf = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', LogisticRegression())\n",
        "])\n",
        "\n",
        "text_clf.fit(X_train, y_train)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vect',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, vocabulary=None)),\n",
              "                ('tfidf',\n",
              "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
              "                                  sublinear_tf=False, use_idf=True)),\n",
              "                ('clf',\n",
              "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='auto', n_jobs=None,\n",
              "                                    penalty='l2', random_state=None,\n",
              "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WEwXz6cuJf9",
        "outputId": "a39841ad-8592-4309-8d1d-79e515fe33cb"
      },
      "source": [
        "predicted = text_clf.predict(X_vali)\n",
        "print(\"Validation accuracy:\", np.mean(predicted == y_vali))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy: 0.7015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1BDc7LJuLjw",
        "outputId": "bc36a870-ba9c-4095-ea4f-1f99836eb268"
      },
      "source": [
        "predicted = text_clf.predict(X_test)\n",
        "print(\"Testing accuracy:\", np.mean(predicted == y_test))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing accuracy: 0.682\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaIv3IraDGKA"
      },
      "source": [
        "fack_news = fack_news.rename(columns={'sentence': 'label'})\n",
        "test = test.rename(columns={'sentence': 'label'})\n",
        "val = val.rename(columns={'sentence': 'label'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlyAk7T3iBvD"
      },
      "source": [
        "test.to_csv('/content/DATA_DIR/RE/test.tsv', index=False)\n",
        "\n",
        "val.to_csv('/content/DATA_DIR/RE/dev.tsv', index=False)\n",
        "\n",
        "fack_news.to_csv(r'/content/DATA_DIR/RE/train.tsv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSZ5Gx0y14s-"
      },
      "source": [
        "### Fit with the Megatron Model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYz5Nd07iBlR"
      },
      "source": [
        "!apt install psmisc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jY6siUQ1SU5K",
        "outputId": "0524b396-0e60-4c5a-9b32-24a035ae0936"
      },
      "source": [
        "!python -m pip install pip==19.3.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip==19.3.1 in /usr/local/lib/python3.7/dist-packages (19.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcYJORvsiBaw"
      },
      "source": [
        "!sudo fuser /dev/nvidia*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pg43swDDhUa6"
      },
      "source": [
        "!pip install torch==1.8.1+cu101 torchtext==0.9.1 -f https://download.pytorch.org/whl/cu101/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrRXyL_W-9Hy"
      },
      "source": [
        "!ls /usr/local/lib/python3.7/dist-packages"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCFmBx-ShUMu"
      },
      "source": [
        "%env CUDA_HOME=/usr/local/cuda-10.1\n",
        "!git clone https://github.com/NVIDIA/apex\n",
        "!pip install -v --disable-pip-version-check --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbsaXTqDhT-c",
        "outputId": "516b0b81-84ce-434f-f16e-f92d9801e401"
      },
      "source": [
        "%%writefile setup.sh\n",
        "export CUDA_HOME=/usr/local/cuda-10.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing setup.sh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fv3YDN9ThTra"
      },
      "source": [
        "!sh setup.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhW_57qKh-To"
      },
      "source": [
        "!pip install rapidfuzz\n",
        "!pip install megatron \n",
        "!pip install omegaconf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lRn0TgYzEYR"
      },
      "source": [
        "BRANCH = 'v1.0.0b2'\n",
        "!python -m pip install git+https://github.com/NVIDIA/NeMo.git@$BRANCH#egg=nemo_toolkit[nlp]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vw7oUEubwXjD"
      },
      "source": [
        "BRANCH = 'r1.1.0'\n",
        "!python -m pip install git+https://github.com/NVIDIA/NeMo.git@$BRANCH#egg=nemo_toolkit[nlp]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wU7o0QY9Epun"
      },
      "source": [
        "!pip install -q torch==1.8.1 -f https://download.pytorch.org/whl/cu101/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgErKidYiFMt"
      },
      "source": [
        "import os\n",
        "import wget\n",
        "import torch\n",
        "from omegaconf import OmegaConf\n",
        "import pytorch_lightning as pl\n",
        "from nemo.collections import nlp as nemo_nlp\n",
        "from nemo.utils.exp_manager import exp_manager"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tO9az7HiE95"
      },
      "source": [
        "DATA_DIR = os.path.join(os.getcwd(), 'DATA_DIR')\n",
        "RE_DATA_DIR = os.path.join(DATA_DIR, 'RE')\n",
        "WORK_DIR = os.path.join(os.getcwd(), 'WORK_DIR')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Qdiyi9Vh-GA"
      },
      "source": [
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "os.makedirs(os.path.join(DATA_DIR, 'RE'), exist_ok=True)\n",
        "os.makedirs(WORK_DIR, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLcQR_jIiQE0",
        "outputId": "0bdb85ed-ec33-484c-ae41-4cc282880e50"
      },
      "source": [
        "WORK_DIR = \"WORK_DIR\"\n",
        "os.makedirs(WORK_DIR, exist_ok=True)\n",
        "MODEL_CONFIG = \"text_classification_config.yaml\"\n",
        "\n",
        "CONFIG_DIR = WORK_DIR + '/configs/'\n",
        "os.makedirs(CONFIG_DIR, exist_ok=True)\n",
        "if not os.path.exists(CONFIG_DIR + MODEL_CONFIG):\n",
        "    print('Downloading config file...')\n",
        "    wget.download('https://raw.githubusercontent.com/NVIDIA/NeMo/v1.0.0b2/examples/nlp/text_classification/conf/' + MODEL_CONFIG, CONFIG_DIR)\n",
        "else:\n",
        "    print ('config file is already exists')\n",
        "config_path = f'{WORK_DIR}/configs/{MODEL_CONFIG}'\n",
        "print(config_path)\n",
        "config = OmegaConf.load(config_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading config file...\n",
            "WORK_DIR/configs/text_classification_config.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Et7IWKftiuc2",
        "outputId": "03fc6af3-5e94-414d-f045-fbe8501a1426"
      },
      "source": [
        "config.model.dataset.data_dir = os.path.join(RE_DATA_DIR)\n",
        "\n",
        "config.trainer.max_epochs = 10\n",
        "config.model.dataset.do_lower_case = False\n",
        "config.save_to = 'trained-model.nemo'\n",
        "config.export_to = 'trained-model.onnx'\n",
        "cuda = 1 if torch.cuda.is_available() else 0\n",
        "config.trainer.gpus = cuda\n",
        "config.model.dataset.num_classes= 2\n",
        "config.model.test_ds.file_path = os.path.join(RE_DATA_DIR, 'test.tsv')\n",
        "config.model.train_ds.file_path = os.path.join(RE_DATA_DIR, 'train.tsv')\n",
        "config.model.validation_ds.file_path = os.path.join(RE_DATA_DIR, 'dev.tsv')\n",
        "config.trainer.precision = 16 if torch.cuda.is_available() else 32\n",
        "config.model.test_ds.batch_size = 8\n",
        "config.model.train_ds.batch_size = 8\n",
        "config.model.validation_ds.batch_size = 8\n",
        "config.model.test_ds.num_workers = 2\n",
        "config.model.train_ds.num_workers = 2\n",
        "config.model.validation_ds.num_workers = 2\n",
        "config.model.dataset.num_workers = 2\n",
        "config.trainer.accelerator = None\n",
        "\n",
        "trainer = pl.Trainer(**config.trainer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "Using native 16bit precision.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jw_Tt_1u4ERB"
      },
      "source": [
        "def validate(NUM_EPOCHS, epoch, model, testloader):\n",
        "    model.eval()\n",
        "    loss = 0.0\n",
        "    acc = 0\n",
        "    running_loss = 0.0\n",
        "    running_correct = 0\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(testloader):\n",
        "            img, labels = data[0].to(device), data[1].to(device)\n",
        "            new_img = new_img.to(device)\n",
        "            outputs = model(new_img)\n",
        "            loss = criterion(outputs, labels)\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            running_loss += loss.item()\n",
        "            running_correct += (preds == labels).sum().item()\n",
        "\n",
        "    loss = running_loss / len(testset)\n",
        "    acc = 100. * running_correct / len(testset)\n",
        "    return loss, acc "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGzEE5DviBQb",
        "outputId": "1889cc0d-4519-4286-fd61-f28861465e57"
      },
      "source": [
        "trainer = pl.Trainer(**config.trainer)\n",
        "\n",
        "config.exp_manager.exp_dir = 'LOG_CHECKPOINT_DIR'\n",
        "\n",
        "print(OmegaConf.to_yaml(config.exp_manager))\n",
        "\n",
        "exp_dir = exp_manager(trainer, config.exp_manager)\n",
        "\n",
        "print(exp_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "Using native 16bit precision.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "exp_dir: LOG_CHECKPOINT_DIR\n",
            "name: TextClassification\n",
            "create_tensorboard_logger: true\n",
            "create_checkpoint_callback: true\n",
            "\n",
            "[NeMo I 2021-10-20 20:56:14 exp_manager:217] Experiments will be logged at LOG_CHECKPOINT_DIR/TextClassification/2021-10-20_20-56-14\n",
            "[NeMo I 2021-10-20 20:56:14 exp_manager:564] TensorboardLogger has been set up\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2021-10-20 20:56:14 nemo_logging:349] /usr/local/lib/python3.7/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:397: LightningDeprecationWarning: Argument `period` in `ModelCheckpoint` is deprecated in v1.3 and will be removed in v1.5. Please use `every_n_val_epochs` instead.\n",
            "      'Argument `period` in `ModelCheckpoint` is deprecated in v1.3 and will be removed in v1.5.'\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOG_CHECKPOINT_DIR/TextClassification/2021-10-20_20-56-14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKb4Jk91i7Za"
      },
      "source": [
        "config.model.language_model.pretrained_model_name = \"megatron-bert-345m-uncased\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rz8Wgvp8i69r",
        "outputId": "c8e9756c-74c7-40bf-e7b0-cd468fe3ed2e"
      },
      "source": [
        "print(OmegaConf.to_yaml(config))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainer:\n",
            "  gpus: 1\n",
            "  num_nodes: 1\n",
            "  max_epochs: 10\n",
            "  max_steps: null\n",
            "  accumulate_grad_batches: 1\n",
            "  gradient_clip_val: 0.0\n",
            "  amp_level: O0\n",
            "  precision: 16\n",
            "  accelerator: null\n",
            "  log_every_n_steps: 1\n",
            "  val_check_interval: 1.0\n",
            "  resume_from_checkpoint: null\n",
            "  num_sanity_val_steps: 0\n",
            "  checkpoint_callback: false\n",
            "  logger: false\n",
            "model:\n",
            "  nemo_path: text_classification_model.nemo\n",
            "  tokenizer:\n",
            "    tokenizer_name: ${model.language_model.pretrained_model_name}\n",
            "    vocab_file: null\n",
            "    tokenizer_model: null\n",
            "    special_tokens: null\n",
            "  language_model:\n",
            "    pretrained_model_name: megatron-bert-345m-uncased\n",
            "    lm_checkpoint: null\n",
            "    config_file: null\n",
            "    config: null\n",
            "  classifier_head:\n",
            "    num_output_layers: 2\n",
            "    fc_dropout: 0.1\n",
            "  dataset:\n",
            "    num_classes: 2\n",
            "    do_lower_case: false\n",
            "    max_seq_length: 256\n",
            "    class_balancing: null\n",
            "    use_cache: false\n",
            "    num_workers: 2\n",
            "    drop_last: false\n",
            "    pin_memory: false\n",
            "    data_dir: /content/DATA_DIR/RE\n",
            "  train_ds:\n",
            "    file_path: /content/DATA_DIR/RE/train.tsv\n",
            "    batch_size: 8\n",
            "    shuffle: true\n",
            "    num_samples: -1\n",
            "    num_workers: 2\n",
            "    drop_last: ${model.dataset.drop_last}\n",
            "    pin_memory: ${model.dataset.pin_memory}\n",
            "  validation_ds:\n",
            "    file_path: /content/DATA_DIR/RE/dev.tsv\n",
            "    batch_size: 8\n",
            "    shuffle: false\n",
            "    num_samples: -1\n",
            "    num_workers: 2\n",
            "    drop_last: ${model.dataset.drop_last}\n",
            "    pin_memory: ${model.dataset.pin_memory}\n",
            "  test_ds:\n",
            "    file_path: /content/DATA_DIR/RE/test.tsv\n",
            "    batch_size: 8\n",
            "    shuffle: false\n",
            "    num_samples: -1\n",
            "    num_workers: 2\n",
            "    drop_last: ${model.dataset.drop_last}\n",
            "    pin_memory: ${model.dataset.pin_memory}\n",
            "  optim:\n",
            "    name: adam\n",
            "    lr: 2.0e-05\n",
            "    betas:\n",
            "    - 0.9\n",
            "    - 0.999\n",
            "    weight_decay: 0.01\n",
            "    sched:\n",
            "      name: WarmupAnnealing\n",
            "      warmup_steps: null\n",
            "      warmup_ratio: 0.1\n",
            "      last_epoch: -1\n",
            "      monitor: val_loss\n",
            "      reduce_on_plateau: false\n",
            "  infer_samples:\n",
            "  - by the end of no such thing the audience , like beatrice , has a watchful affection\n",
            "    for the monster .\n",
            "  - director rob marshall went out gunning to make a great one .\n",
            "  - uneasy mishmash of styles and genres .\n",
            "exp_manager:\n",
            "  exp_dir: LOG_CHECKPOINT_DIR\n",
            "  name: TextClassification\n",
            "  create_tensorboard_logger: true\n",
            "  create_checkpoint_callback: true\n",
            "hydra:\n",
            "  run:\n",
            "    dir: .\n",
            "  job_logging:\n",
            "    root:\n",
            "      handlers: null\n",
            "save_to: trained-model.nemo\n",
            "export_to: trained-model.onnx\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1b484df892384de9851191eb580fa8ce",
            "fcc950e31563453984a32a4ce93b62bf",
            "df7e784501af4a4f92af42a9225d89dd",
            "1965dad504f548afab26b849ba5ce20a",
            "512f33b85e6f415b8a1591a8ef3aac79",
            "3bae5b274c5542678359faf653ab4a03",
            "506adf1949ed4ae78b16d4ac96bd9e45",
            "cc9e16dbfe004821ba0872452663fda5",
            "7a3449b8a8de4721adb40bf114cc4d79",
            "54d567f315f94df6ac00e2015f5d222b",
            "6f380fbcff8a448b83ffa780b250065d",
            "d2ef5a2715eb4f24a02722ee44bbd70a",
            "fa3d4030d0ed46e293e313353922268f",
            "c55586f5cea14da4b800cc00e1372f23",
            "a0f426aca08841b5ad1e2af732af2ebe",
            "00d4007563eb4bcfb3127961b9141ff2",
            "5a6dba5f50da434bb78c12729db68547",
            "392230d82baf4ed89767a823589d7e9f",
            "7d0b60e7978843e0b06ce61b834e3699",
            "9e62c3fc6f7e45889bf475a30f34e7d3",
            "93753a7278d54c3e8b8ace34f66ac7eb",
            "259b6a8b1b1b4077bd576d2fada488df",
            "7116a35f61d9473c8d8db848948587c5",
            "2e3520434c5543e7971a321cf2be1d82",
            "04bceeb432884e57af22fc371bbff15b",
            "b1da165a7b9a4bec938b8bd89bb5f20b",
            "60059fb56fc0429fa232af6ced446adc",
            "6a5fbdc055af491c862f03ba39ba99d2",
            "0a3d92c5fec54166a894e8be6a82f2a9",
            "6a7f4acd604e4afba9529f87ed1568f8",
            "97888bacb00f4dce8c932e6728d94e86",
            "2f638cd06e4a4e1a8e98afb7eed1a308",
            "72970c6db6da45afa3273eca93122ab1",
            "8bba05a2552d47eba0ea40a66cba6a66",
            "a5d3d2b8d1354b049c8c854bd176eaf6",
            "48ea48d47049446e903f011653716195",
            "b6b3629768db401c900c0f01cf377ffc",
            "e913a2adf84c499d852f9148ccae8e1c",
            "0f7ba1b159734c4198606fd34284aa28",
            "c2d879399b2b41baa5933fe523a5fe24",
            "a1d329c2344543c7bfc8b426bb7cd277",
            "399f4996d1f34fa1af49509339cd3a8e",
            "74c2bc9924794ff2bcb4ed077e386a3c",
            "d6c85c097b0048a6af2de9d2a2a64bc4"
          ]
        },
        "id": "hrbWvbj2Cmxa",
        "outputId": "1bfb2bb7-2dbe-4c4c-cdfc-a90114464e51"
      },
      "source": [
        "model = nemo_nlp.models.TextClassificationModel(cfg=config.model, trainer=trainer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2021-10-20 20:56:43 megatron_utils:274] Downloading from https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt\n",
            "[NeMo I 2021-10-20 20:56:43 tokenizer_utils:99] Getting HuggingFace AutoTokenizer with pretrained_model_name: bert-large-uncased, vocab_file: /root/.cache/torch/megatron/megatron-bert-345m-uncased_vocab, special_tokens_dict: {}, and use_fast: False\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b484df892384de9851191eb580fa8ce",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d2ef5a2715eb4f24a02722ee44bbd70a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7116a35f61d9473c8d8db848948587c5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8bba05a2552d47eba0ea40a66cba6a66",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using bos_token, but it is not set yet.\n",
            "Using eos_token, but it is not set yet.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2021-10-20 20:56:49 text_classification_dataset:120] Read 20001 examples from /content/DATA_DIR/RE/train.tsv.\n",
            "[NeMo I 2021-10-20 20:56:49 text_classification_dataset:238] *** Example ***\n",
            "[NeMo I 2021-10-20 20:56:49 text_classification_dataset:239] example 0: ['news', 'local', 'news', 'australian', 'twice', 'likely', 'drown', 'public', 'holiday', 'border', 'resident', 'holidaymaker', 'warned', 'alert', 'enjoying', 'murray', 'easter', 'period', 'data', 'royal', 'lifesaving', 'australia', 'show', 'australian', 'drowned', 'public', 'holiday', 'past', 'forty', 'people', 'died', 'murray', 'decade', 'leading', 'named', 'number', 'river', 'blackspot', 'drownings', 'already', 'tragedy', 'struck', 'public', 'holiday', 'leigh', 'marshall', 'melbourne', 'drowned', 'swimming', 'murray', 'river', 'yarrawonga', 'australia', 'day', 'drowning', 'came', 'nepalese', 'student', 'bigul', 'pandit', 'swept', 'underwater', 'murray', 'presumed', 'drowned', 'albury', 'border', 'rescue', 'squad', 'captain', 'paul', 'marshall', 'said', 'someone', 'dy', 'waterway', 'affect', 'vast', 'number', 'people', 'person', 'family', 'friend', 'fellow', 'swimmer', 'rescuer', 'like', 'rock', 'water', 'ripple', 'spread', 'far', 'wide', 'said', 'recent', 'drowning', 'albury', 'mister', 'pandit', 'still', 'feeling', 'ripple', 'upset', 'stress', 'rescuer', 'emergency', 'worker', 'want', 'see', 'level', 'grief', 'loss', 'anyone', 'life', 'news', 'mister', 'marshall', 'said', 'number', 'factor', 'made', 'drownings', 'likely', 'public', 'holiday', 'especially', 'easter', 'break', 'proportionate', 'lot', 'people', 'holidaying', 'around', 'area', 'using', 'river', 'said', 'holiday', 'people', 'drink', 'eat', 'enjoy', 'bit', 'barrier', 'unfortunately', 'mixed', 'water', 'result', 'tragic', 'event', 'mister', 'marshall', 'said', 'many', 'easter', 'holiday', 'period', 'last', 'chance', 'enjoy', 'water', 'weather', 'becomes', 'decidedly', 'wintry', 'said', 'although', 'temperature', 'still', 'reaching', 'mid', 'water', 'river', 'significantly', 'cooler', 'increased', 'risk', 'drownings', 'people', 'go', 'shock', 'said', 'jump', 'water', 'hit', 'cold', 'take', 'gulp', 'air', 'body', 'gone', 'shock', 'often', 'water', 'get', 'gulp', 'people', 'get', 'trouble', 'also', 'initial', 'shock', 'body', 'lead', 'people', 'struggling', 'try', 'get', 'getting', 'overcome', 'mister', 'marshall', 'said', 'canoeist', 'wear', 'life', 'jacket', 'carry', 'phone', 'aware', 'low', 'river', 'level', 'upper', 'murray', 'could', 'exposed', 'snag', 'said', 'anyone', 'using', 'river', 'alone', 'tell', 'people', 'plan', 'receive', 'daily', 'newsletter', 'straight', 'inbox', 'morning', 'border', 'mail', 'sign', 'http', 'nnimgt', 'akamaihd', 'net', 'transform', 'crop', 'frm', 'sophie', 'boyd', 'a', 'jpg', '_w', '_h', '_fmax', 'jpg']\n",
            "[NeMo I 2021-10-20 20:56:49 text_classification_dataset:240] subtokens: [CLS] news local news australian twice likely drown public holiday border resident holiday ##maker warned alert enjoying murray easter period data royal life ##sa ##ving australia show australian drowned public holiday past forty people died murray decade leading named number river blacks ##pot drowning ##s already tragedy struck public holiday leigh marshall melbourne drowned swimming murray river ya ##rra ##won ##ga australia day drowning came nepal ##ese student big ##ul pandit swept underwater murray presumed drowned al ##bury border rescue squad captain paul marshall said someone d ##y waterway affect vast number people person family friend fellow swimmer rescue ##r like rock water ripple spread far wide said recent drowning al ##bury mister pandit still feeling ripple upset stress rescue ##r emergency worker want see level grief loss anyone life news mister marshall said number factor made drowning ##s likely public holiday especially easter break proportion ##ate lot people holiday ##ing around area using river said holiday people drink eat enjoy bit barrier unfortunately mixed water result tragic event mister marshall said many easter holiday period last chance enjoy water weather becomes decidedly win ##try said although temperature still reaching mid water river significantly cooler increased risk drowning ##s people go shock said jump water hit cold take gulp air body gone shock often water get gulp people get trouble also initial shock body lead people struggling try get getting overcome mister marshall said canoe ##ist wear life jacket carry phone aware low river level upper murray could exposed s ##na ##g said anyone using river [SEP]\n",
            "[NeMo I 2021-10-20 20:56:49 text_classification_dataset:241] input_ids: 101 2739 2334 2739 2827 3807 3497 19549 2270 6209 3675 6319 6209 8571 7420 9499 9107 6264 10957 2558 2951 2548 2166 3736 6455 2660 2265 2827 12805 2270 6209 2627 5659 2111 2351 6264 5476 2877 2315 2193 2314 10823 11008 14759 2015 2525 10576 4930 2270 6209 11797 5832 4940 12805 5742 6264 2314 8038 11335 19291 3654 2660 2154 14759 2234 8222 6810 3076 2502 5313 29331 7260 11564 6264 14609 12805 2632 4917 3675 5343 4686 2952 2703 5832 2056 2619 1040 2100 23668 7461 6565 2193 2111 2711 2155 2767 3507 13361 5343 2099 2066 2600 2300 24644 3659 2521 2898 2056 3522 14759 2632 4917 12525 29331 2145 3110 24644 6314 6911 5343 2099 5057 7309 2215 2156 2504 9940 3279 3087 2166 2739 12525 5832 2056 2193 5387 2081 14759 2015 3497 2270 6209 2926 10957 3338 10817 3686 2843 2111 6209 2075 2105 2181 2478 2314 2056 6209 2111 4392 4521 5959 2978 8803 6854 3816 2300 2765 13800 2724 12525 5832 2056 2116 10957 6209 2558 2197 3382 5959 2300 4633 4150 27873 2663 11129 2056 2348 4860 2145 4285 3054 2300 2314 6022 14976 3445 3891 14759 2015 2111 2175 5213 2056 5376 2300 2718 3147 2202 26546 2250 2303 2908 5213 2411 2300 2131 26546 2111 2131 4390 2036 3988 5213 2303 2599 2111 8084 3046 2131 2893 9462 12525 5832 2056 14347 2923 4929 2166 6598 4287 3042 5204 2659 2314 2504 3356 6264 2071 6086 1055 2532 2290 2056 3087 2478 2314 102\n",
            "[NeMo I 2021-10-20 20:56:49 text_classification_dataset:242] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "[NeMo I 2021-10-20 20:56:49 text_classification_dataset:243] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "[NeMo I 2021-10-20 20:56:49 text_classification_dataset:244] label: 1\n",
            "[NeMo I 2021-10-20 20:56:49 text_classification_dataset:238] *** Example ***\n",
            "[NeMo I 2021-10-20 20:56:49 text_classification_dataset:239] example 1: ['emirate', 'arabia', 'crowned', 'grand', 'prize', 'winner', 'spoken', 'hard', 'win', 'prize', 'abudhajah', 'born', 'illiterate', 'single', 'mother', 'toddler', 'country', 'madinah', 'intensive', 'research', 'family', 'pay', 'half', 'prize', 'rent', 'house', 'half', 'buy', 'school', 'care', 'home', 'desert', 'town', 'atzeel', 'overwhelmed', 'enrolled', 'online', 'tutoring', 'programme', 'child', 'study', 'foundation', 'almost', 'later', 'money', 'dubai', 'preparation', 'sold', 'house', 'dh', 'december', 'story', 'unique', 'arabian', 'peninsula', 'last', 'uae', 'ayaan', 'abbasi', 'first', 'eleven', 'girl', 'ayyubai', 'district', 'jeddah', 'grand', 'prize', 'th', 'edition', 'cultural', 'contest', 'held', 'dubai', 'abbasi', 'started', 'using', 'online', 'learning', 'programme', 'age', 'used', 'complete', 'exam', 'experience', 'culture', 'experience', 'rare', 'chance', 'fly', 'school', 'abroad', 'nowhere', 'obvious', 'girl', 'boy', 'capable', 'buying', 'school', 'acquiring', 'care', 'home', 'might', 'also', 'construct', 'initial', 'school', 'building', 'rather', 'buying', 'home', 'selling', 'mother', 'house', 'reason', 'explain', 'saeed', 'abdul', 'wali', 'boy', 'ben', 'wah', 'performing', 'well', 'arab', 'school', 'amal', 'quite', 'capable', 'buying', 'house', 'saudi', 'arabia', 'mother', 'another', 'country', 'could', 'reason', 'many', 'reason', 'female', 'arab', 'country', 'purchase', 'home', 'striking', 'definite', 'awareness', 'education', 'nation', 'make', 'big', 'splash', 'wider', 'arabic', 'medium', 'girl', 'buy', 'parent', 'house', 'seem', 'le', 'aberration', 'hapless', 'follow', 'inquiry', 'ordinary', 'people', 'also', 'official', 'education', 'system', 'enables', 'girl', 'learn', 'read', 'write', 'family', 'relatively', 'educated', 'economically', 'successful', 'help', 'push', 'towards', 'buying', 'home', 'unfortunately', 'also', 'difficult', 'deal', 'fact', 'absolute', 'absence', 'education', 'impedes', 'buying', 'anything', 'yet', 'parent', 'seem', 'share', 'frustration', 'inability', 'parent', 'provide', 'child', 'world', 'economic', 'policymakers', 'run', 'state', 'india', 'seen', 'burgeoning', 'desire', 'buy', 'home', 'engaging', 'family', 'work', 'family', 'group', 'according', 'international', 'organization', 'migration', 'million', 'woman', 'joined', 'workforce', 'saudi', 'arabia', 'percent', 'saudi', 'population', 'full', 'time', 'bringing', 'saudi', 'fifth', 'number', 'young', 'woman', 'kingdom', 'risk', 'government', 'policy', 'imposing', 'minimum', 'wage', 'formidable', 'still', 'hopeful', 'symmetry', 'tale', 'award', 'country', 'emirate', 'arabian', 'peninsula', 'took', 'part', 'annual', 'th', 'world', 'childrens', 'prize', 'ceremony', 'yet', 'announce', 'win', 'another', 'upside', 'uaes', 'success', 'put', 'rest', 'misconception', 'vulnerable', 'marginalised', 'uae', 'first', 'demonstrate', 'woman', 'particularly', 'capable', 'winning', 'prize', 'many', 'working', 'class', 'family', 'lack', 'resource', 'university', 'education', 'borrow', 'spend', 'huge', 'sum', 'money', 'getting', 'around', 'large', 'size', 'workforce', 'uae', 'scored', 'spectacularly', 'well', 'many', 'crucial', 'measure', 'aid', 'free', 'higher', 'education', 'instead', 'lying', 'around', 'waiting', 'get', 'kicked', 'school', 'forced', 'fend', 'encouraging', 'woman', 'minded', 'participate', 'community', 'million', 'general', 'population', 'insecure', 'well', 'do', 'not', 'join', 'force', 'work', 'hard', 'keep', 'hope', 'alive', 'uae', 'made', 'little', 'progress', 'achieving', 'goal', 'paying', 'back', 'university', 'generous', 'possible', 'meantime', 'might', 'wonder', 'whether', 'society', 'could', 'afford', 'give', 'additional', 'schooling', 'earning', 'decent', 'living', 'good', 'job']\n",
            "[NeMo I 2021-10-20 20:56:49 text_classification_dataset:240] subtokens: [CLS] emir ##ate arabia crowned grand prize winner spoken hard win prize abu ##dha ##jah born ill ##iter ##ate single mother todd ##ler country mad ##ina ##h intensive research family pay half prize rent house half buy school care home desert town at ##zee ##l overwhelmed enrolled online tutor ##ing programme child study foundation almost later money dubai preparation sold house dh december story unique arabian peninsula last uae a ##ya ##an abbas ##i first eleven girl a ##y ##yu ##bai district jed ##dah grand prize th edition cultural contest held dubai abbas ##i started using online learning programme age used complete exam experience culture experience rare chance fly school abroad nowhere obvious girl boy capable buying school acquiring care home might also construct initial school building rather buying home selling mother house reason explain sa ##eed abdul wal ##i boy ben wah performing well arab school ama ##l quite capable buying house saudi arabia mother another country could reason many reason female arab country purchase home striking definite awareness education nation make big splash wider arabic medium girl buy parent house seem le abe ##rra ##tion ha ##ples ##s follow inquiry ordinary people also official education system enables girl learn read write family relatively educated economically successful help push towards buying home unfortunately also difficult deal fact absolute absence education imp ##edes buying anything yet parent seem share frustration inability parent provide child world economic policy ##makers run state india seen bu ##rgeon ##ing desire buy home engaging family work family group according international organization [SEP]\n",
            "[NeMo I 2021-10-20 20:56:49 text_classification_dataset:241] input_ids: 101 23434 3686 9264 10249 2882 3396 3453 5287 2524 2663 3396 8273 17516 18878 2141 5665 21646 3686 2309 2388 6927 3917 2406 5506 3981 2232 11806 2470 2155 3477 2431 3396 9278 2160 2431 4965 2082 2729 2188 5532 2237 2012 23940 2140 13394 8302 3784 14924 2075 4746 2775 2817 3192 2471 2101 2769 11558 7547 2853 2160 28144 2285 2466 4310 13771 6000 2197 17641 1037 3148 2319 17532 2072 2034 5408 2611 1037 2100 10513 26068 2212 24401 18417 2882 3396 16215 3179 3451 5049 2218 11558 17532 2072 2318 2478 3784 4083 4746 2287 2109 3143 11360 3325 3226 3325 4678 3382 4875 2082 6917 7880 5793 2611 2879 5214 9343 2082 13868 2729 2188 2453 2036 9570 3988 2082 2311 2738 9343 2188 4855 2388 2160 3114 4863 7842 13089 10298 24547 2072 2879 3841 22894 4488 2092 5424 2082 25933 2140 3243 5214 9343 2160 8174 9264 2388 2178 2406 2071 3114 2116 3114 2931 5424 2406 5309 2188 8478 15298 7073 2495 3842 2191 2502 17624 7289 5640 5396 2611 4965 6687 2160 4025 3393 14863 11335 3508 5292 21112 2015 3582 9934 6623 2111 2036 2880 2495 2291 12939 2611 4553 3191 4339 2155 4659 5161 15318 3144 2393 5245 2875 9343 2188 6854 2036 3697 3066 2755 7619 6438 2495 17727 18352 9343 2505 2664 6687 4025 3745 9135 13720 6687 3073 2775 2088 3171 3343 12088 2448 2110 2634 2464 20934 28242 2075 4792 4965 2188 11973 2155 2147 2155 2177 2429 2248 3029 102\n",
            "[NeMo I 2021-10-20 20:56:49 text_classification_dataset:242] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "[NeMo I 2021-10-20 20:56:49 text_classification_dataset:243] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "[NeMo I 2021-10-20 20:56:49 text_classification_dataset:244] label: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2021-10-20 21:03:56 text_classification_dataset:251] Found 11207 out of 20000 sentences with more than 256 subtokens. Truncated long sentences from the end.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2021-10-20 21:03:56 data_preprocessing:299] Some stats of the lengths of the sequences:\n",
            "[NeMo I 2021-10-20 21:03:56 data_preprocessing:305] Min: 10 |                  Max: 257 |                  Mean: 224.62605 |                  Median: 257.0\n",
            "[NeMo I 2021-10-20 21:03:56 data_preprocessing:307] 75 percentile: 257.00\n",
            "[NeMo I 2021-10-20 21:03:56 data_preprocessing:308] 99 percentile: 257.00\n",
            "[NeMo I 2021-10-20 21:03:57 text_classification_dataset:120] Read 2001 examples from /content/DATA_DIR/RE/dev.tsv.\n",
            "[NeMo I 2021-10-20 21:03:57 text_classification_dataset:238] *** Example ***\n",
            "[NeMo I 2021-10-20 21:03:57 text_classification_dataset:239] example 0: ['something', 'appropriate', 'wear', 'great', 'look', 'mean', 'think', 'point', 'retirement', 'sunglass', 'wear', 'public', 'know', 'exactly', 'got', 'advertisement', 'continue', 'reading', 'end', 'lens', 'make', 'wearer', 'look', 'they', 'are', 'wearing', 'part', 'heavenly', 'life', 'special', 'effect', 'glass', 'get', 'lost', 'stolen', 'lost', 'pesky', 'gap', 'appearance', 'style', 'recently', 'included', 'peter', 'frampton', 'sunglass', 'scarlett', 'johansson', 'light', 'sunglass', 'lupita', 'nyong', 'light', 'sunglass', 'armie', 'hammer', 'light', 'sunglass', 'timey', 'yego', 'posito', 'prescription', 'sunglass', 'course', 'flat', 'art', 'house', 'sunglass', 'kind', 'made', 'possible', 'people', 'sell', 'sale', 'christie', 'writes', 'good', 'they', 'are', 'going', 'get', 'beautiful', 'top', 'designer', 'said', 'pricey', 'frame', 'joke', 'added', 'they', 'are', 'really', 'indestructible', 'call', 'sunglass', 'famous', 'jeweler', 'famed', 'letting', 'you', 'know', 'matte', 'coated', 'lens', 'actually', 'make', 'difference', 'even', 'aid', 'instagram', 'worthy', 'selfies', 'making', 'look', 'little', 'sequin', 'jointed', 'advertisement', 'continue', 'reading', 'frame', 'do', 'not', 'function', 'cheap', 'accessory', 'work', 'well', 'sadly', 'do', 'not', 'stay', 'long', 'wear', 'much', 'longer', 'die', 'anyway', 'replaced', 'generic', 'expensive', 'sunglass', 'incisor']\n",
            "[NeMo I 2021-10-20 21:03:57 text_classification_dataset:240] subtokens: [CLS] something appropriate wear great look mean think point retirement sung ##lass wear public know exactly got advertisement continue reading end lens make wear ##er look they are wearing part heavenly life special effect glass get lost stolen lost pe ##sky gap appearance style recently included peter fra ##mpton sung ##lass scarlett johansson light sung ##lass lu ##pit ##a ny ##ong light sung ##lass arm ##ie hammer light sung ##lass time ##y ye ##go po ##sit ##o prescription sung ##lass course flat art house sung ##lass kind made possible people sell sale christie writes good they are going get beautiful top designer said price ##y frame joke added they are really ind ##est ##ru ##ct ##ible call sung ##lass famous jewel ##er famed letting you know matt ##e coated lens actually make difference even aid ins ##tagram worthy self ##ies making look little se ##quin joint ##ed advertisement continue reading frame do not function cheap accessory work well sadly do not stay long wear much longer die anyway replaced generic expensive sung ##lass inc ##iso ##r [SEP]\n",
            "[NeMo I 2021-10-20 21:03:57 text_classification_dataset:241] input_ids: 101 2242 6413 4929 2307 2298 2812 2228 2391 5075 7042 27102 4929 2270 2113 3599 2288 15147 3613 3752 2203 10014 2191 4929 2121 2298 2027 2024 4147 2112 16581 2166 2569 3466 3221 2131 2439 7376 2439 21877 5874 6578 3311 2806 3728 2443 2848 25312 26793 7042 27102 20862 26447 2422 7042 27102 11320 23270 2050 6396 5063 2422 7042 27102 2849 2666 8691 2422 7042 27102 2051 2100 6300 3995 13433 28032 2080 20422 7042 27102 2607 4257 2396 2160 7042 27102 2785 2081 2825 2111 5271 5096 13144 7009 2204 2027 2024 2183 2131 3376 2327 5859 2056 3976 2100 4853 8257 2794 2027 2024 2428 27427 4355 6820 6593 7028 2655 7042 27102 3297 13713 2121 15607 5599 2017 2113 4717 2063 15026 10014 2941 2191 4489 2130 4681 16021 23091 11007 2969 3111 2437 2298 2210 7367 12519 4101 2098 15147 3613 3752 4853 2079 2025 3853 10036 25339 2147 2092 13718 2079 2025 2994 2146 4929 2172 2936 3280 4312 2999 12391 6450 7042 27102 4297 19565 2099 102\n",
            "[NeMo I 2021-10-20 21:03:57 text_classification_dataset:242] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "[NeMo I 2021-10-20 21:03:57 text_classification_dataset:243] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "[NeMo I 2021-10-20 21:03:57 text_classification_dataset:244] label: 0\n",
            "[NeMo I 2021-10-20 21:03:57 text_classification_dataset:238] *** Example ***\n",
            "[NeMo I 2021-10-20 21:03:57 text_classification_dataset:239] example 1: ['share', 'article', 'google', 'plus', 'brief', 'guide', 'battlefield', 'earned', 'premium', 'xbox', 'pc', 'gamers', 'xbox', 'live', 'member', 'new', 'warfare', 'subscription', 'free', 'people', 'buy', 'game', 'monthly', 'basis', 'however', 'many', 'people', 'opting', 'reduce', 'subscription', 'unable', 'pay', 'premium', 'battlefield', 'game', 'choose', 'ea', 'fifa', 'fantastic', 'example', 'addition', 'spending', 'premium', 'meaning', 'dead', 'space', 'men', 'black', 'plant', 'zombie', 'super', 'mario', 'brothers', 'god', 'war', 'able', 'buy', 'additional', 'premium', 'title', 'ea', 'newstv', 'premium', 'russian', 'relevance', 'premium', 'madden', 'nfl', 'premium', 'battlefield', 'starter', 'premium', 'find', 'battlefield', 'premium', 'visiting', 'igns', 'battlefield', 'page', 'battlefield', 'premium', 'premium', 'mark', 'end', 'long', 'history', 'company', 'trend', 'started', 'first', 'spin', 'shooter', 'battlefield', 'bad', 'company', 'last', 'battlefield', 'earned', 'excess', 'billion', 'blew', 'away', 'every', 'premium', 'paid', 'game', 'history', 'xbox', 'playstation', 'we', 'have', 'learned', 'far', 'battlefield', 'focused', 'brand', 'build', 'ubisofts', 'design', 'extent', 'even', 'enhances', 'character', 'protagonist', 'lot', 'favourably', 'hooking', 'different', 'console', 'great', 'balance', 'premium', 'dice', 'project', 'bring', 'platformer', 'neck', 'take', 'look', 'screenshots', 'game', 'idea', 'behind', 'bringing', 'battlefield', 'console', 'already', 'worked', 'way', 'console', 'industry', 'major', 'hit', 'console', 'era', 'postscript', 'game', 'released', 'trend', 'started', 'early', 'especially', 'gear', 'war', 'playstation', 'introduced', 'launch', 'version', 'allowed', 'pc', 'gaming', 'later', 'xbox', 'were', 'not', 'seen', 'successful', 'we', 'have', 'brought', 'screenshots', 'battlefield', 'final', 'fantasy', 'xv', 'shipjacker', 'map', 'hinted', 'compared', 'modern', 'warfare', 'indie', 'side', 'mediocre', 'product', 'hinted', 'compared', 'modern', 'warfare', 'army', 'dead', 'knack', 'super', 'soldier', 'event', 'hinted', 'compared', 'modern', 'warfare', 'navy', 'seal', 'report', 'hinted', 'compared', 'modern', 'warfare', 'liberation', 'player', 'guide', 'hinted', 'compared', 'modern', 'warfare', 'generating', 'revenue', 'category', 'hinted', 'compared', 'modern', 'warfare', 'peak', 'contrast', 'contrast', 'contrast', 'contrast', 'hinted', 'compared', 'modern', 'warfare', 'serving', 'inventor', 'directive', 'hinted', 'compared', 'modern', 'warfare', 'mentioning', 'pr', 'facebook', 'hinted', 'compared', 'modern', 'warfare', 'battleline', 'project', 'making', 'comeback', 'day', 'hinted', 'compared', 'modern', 'warfare', 'expanding', 'premium', 'digital', 'hinted', 'compared', 'modern', 'warfare', 'free', 'flight', 'moscow', 'london', 'battlefield', 'hinted', 'compared', 'modern', 'warfare', 'backed', 'ubisoft', 'you', 'hinted', 'compared', 'modern', 'warfare', 'free', 'brilliant', 'new', 'character', 'vow', 'hinted', 'compared', 'modern', 'warfare', 'learn', 'battlefield', 'visiting', 'igns', 'battlefield', 'page', 'virtual', 'chess', 'fortnite', 'board', 'player', 'training', 'hinted', 'compared', 'modern', 'warfare', 'tackling', 'new', 'enemy', 'sidekick', 'hinted', 'compared', 'modern']\n",
            "[NeMo I 2021-10-20 21:03:57 text_classification_dataset:240] subtokens: [CLS] share article google plus brief guide battlefield earned premium xbox pc gamer ##s xbox live member new warfare subscription free people buy game monthly basis however many people opt ##ing reduce subscription unable pay premium battlefield game choose ea fifa fantastic example addition spending premium meaning dead space men black plant zombie super mario brothers god war able buy additional premium title ea news ##tv premium russian relevance premium madden nfl premium battlefield starter premium find battlefield premium visiting ign ##s battlefield page battlefield premium premium mark end long history company trend started first spin shooter battlefield bad company last battlefield earned excess billion blew away every premium paid game history xbox playstation we have learned far battlefield focused brand build u ##bis ##oft ##s design extent even enhance ##s character protagonist lot favour ##ably hook ##ing different console great balance premium dice project bring platform ##er neck take look screens ##hot ##s game idea behind bringing battlefield console already worked way console industry major hit console era posts ##cript game released trend started early especially gear war playstation introduced launch version allowed pc gaming later xbox were not seen successful we have brought screens ##hot ##s battlefield final fantasy xv ship ##jack ##er map hinted compared modern warfare indie side med ##io ##cre product hinted compared modern warfare army dead kn ##ack super soldier event hinted compared modern warfare navy seal report hinted compared modern warfare liberation player guide hinted compared modern warfare generating revenue category hinted compared modern warfare peak contrast contrast contrast [SEP]\n",
            "[NeMo I 2021-10-20 21:03:57 text_classification_dataset:241] input_ids: 101 3745 3720 8224 4606 4766 5009 11686 3687 12882 12202 7473 27911 2015 12202 2444 2266 2047 8309 15002 2489 2111 4965 2208 7058 3978 2174 2116 2111 23569 2075 5547 15002 4039 3477 12882 11686 2208 5454 19413 5713 10392 2742 2804 5938 12882 3574 2757 2686 2273 2304 3269 11798 3565 7986 3428 2643 2162 2583 4965 3176 12882 2516 19413 2739 9189 12882 2845 21923 12882 24890 5088 12882 11686 11753 12882 2424 11686 12882 5873 16270 2015 11686 3931 11686 12882 12882 2928 2203 2146 2381 2194 9874 2318 2034 6714 13108 11686 2919 2194 2197 11686 3687 9987 4551 8682 2185 2296 12882 3825 2208 2381 12202 9160 2057 2031 4342 2521 11686 4208 4435 3857 1057 18477 15794 2015 2640 6698 2130 11598 2015 2839 10191 2843 7927 8231 8103 2075 2367 10122 2307 5703 12882 18740 2622 3288 4132 2121 3300 2202 2298 12117 12326 2015 2208 2801 2369 5026 11686 10122 2525 2499 2126 10122 3068 2350 2718 10122 3690 8466 23235 2208 2207 9874 2318 2220 2926 6718 2162 9160 3107 4888 2544 3039 7473 10355 2101 12202 2020 2025 2464 3144 2057 2031 2716 12117 12326 2015 11686 2345 5913 15566 2911 17364 2121 4949 21795 4102 2715 8309 10271 2217 19960 3695 16748 4031 21795 4102 2715 8309 2390 2757 14161 8684 3565 5268 2724 21795 4102 2715 8309 3212 7744 3189 21795 4102 2715 8309 7931 2447 5009 21795 4102 2715 8309 11717 6599 4696 21795 4102 2715 8309 4672 5688 5688 5688 102\n",
            "[NeMo I 2021-10-20 21:03:57 text_classification_dataset:242] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "[NeMo I 2021-10-20 21:03:57 text_classification_dataset:243] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "[NeMo I 2021-10-20 21:03:57 text_classification_dataset:244] label: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2021-10-20 21:04:41 text_classification_dataset:251] Found 1115 out of 2000 sentences with more than 256 subtokens. Truncated long sentences from the end.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2021-10-20 21:04:41 data_preprocessing:299] Some stats of the lengths of the sequences:\n",
            "[NeMo I 2021-10-20 21:04:41 data_preprocessing:305] Min: 73 |                  Max: 257 |                  Mean: 224.549 |                  Median: 257.0\n",
            "[NeMo I 2021-10-20 21:04:41 data_preprocessing:307] 75 percentile: 257.00\n",
            "[NeMo I 2021-10-20 21:04:41 data_preprocessing:308] 99 percentile: 257.00\n",
            "[NeMo I 2021-10-20 21:04:41 text_classification_dataset:120] Read 3001 examples from /content/DATA_DIR/RE/test.tsv.\n",
            "[NeMo I 2021-10-20 21:04:41 text_classification_dataset:238] *** Example ***\n",
            "[NeMo I 2021-10-20 21:04:41 text_classification_dataset:239] example 0: ['possible', 'president', 'pressure', 'campaign', 'helping', 'israeli', 'prime', 'minister', 'benjamin', 'netanyahu', 'government', 'right', 'that', 'is', 'argument', 'raised', 'monitor', 'breakfast', 'wednesday', 'george', 'washington', 'university', 'professor', 'frank', 'schaffner', 'like', 'nfl', 'quarterback', 'game', 'player', 'regard', 'president', 'trump', 'willingness', 'act', 'ultimate', 'savior', 'israel', 'you', 'israeli', 'relationship', 'say', 'key', 'encouraging', 'prime', 'minister', 'netanyahu', 'second', 'term', 'team', 'player', 'there', 'lot', 'consequence', 'president', 'do', 'not', 'see', 'worth', 'sacrifice', 'do', 'not', 'see', 'showing', 'he', 'openly', 'support', 'american', 'mister', 'schaffner', 'told', 'monitor', 'breakfast', 'you', 'are', 'israeli', 'box', 'office', 'do', 'not', 'care', 'obviously', 'that', 'is', 'violation', 'usip', 'financial', 'system', 'added', 'schaffner', 'longtime', 'you', 'official', 'lecture', 'regularly', 'international', 'affair', 'republican', 'politics', 'published', 'book', 'you', 'foreign', 'policy', 'you', 'government', 'asked', 'president', 'united', 'state', 'love', 'goodness', 'particularly', 'come', 'israel', 'say', 'trump', 'often', 'feel', 'proportion', 'israeli', 'do', 'not', 'get', 'along', 'trump', 'jewish', 'family', 'visible', 'life', 'schaffner', 'say', 'he', 'controversial', 'come', 'israel', 'mister', 'trump', 'schaffner', 'argues', 'does', 'not', 'like', 'aggressive', 'israeli', 'jew', 'see', 'israel', 'bit', 'extreme', 'system', 'tyranny', 'prevails', 'goodness', 'schaffner', 'say', 'note', 'since', 'netanyahu', 'returned', 'office', 'he', 'attacked', 'attacking', 'you', 'opponent', 'donald', 'trump', 'rather', 'israeli', 'leader', 'netanyahu', 'schaffner', 'subsequent', 'interview', 'say', 'president', 'constructive', 'pragmatic', 'steward', 'israel', 'economic', 'security', 'political', 'clout', 'recently', 'budget', 'billion', 'fiscal', 'rejected', 'bipartisan', 'majority', 'congress', 'tried', 'push', 'budget', 'netanyahu', 'took', 'seriously', 'schaffner', 'say', 'understands', 'important', 'people', 'comfortable', 'view', 'sense', 'entitlement', 'schaffner', 'say', 'climate', 'israel', 'serve', 'beacon', 'peace', 'middle', 'east', 'fostered', 'american', 'foreign', 'policy', 'last', 'half', 'century', 'get', 'monitor', 'story', 'care', 'delivered', 'inbox', 'signing', 'agree', 'privacy', 'policy', 'important', 'thing', 'spencer', 'proposed', 'president', 'keep', 'goal', 'place', 'win', 'war', 'terror', 'learn', 'put', 'every', 'fallback', 'schaffner', 'say']\n",
            "[NeMo I 2021-10-20 21:04:41 text_classification_dataset:240] subtokens: [CLS] possible president pressure campaign helping israeli prime minister benjamin net ##any ##ahu government right that is argument raised monitor breakfast wednesday george washington university professor frank sc ##ha ##ff ##ner like nfl quarterback game player regard president trump willingness act ultimate savior israel you israeli relationship say key encouraging prime minister net ##any ##ahu second term team player there lot consequence president do not see worth sacrifice do not see showing he openly support american mister sc ##ha ##ff ##ner told monitor breakfast you are israeli box office do not care obviously that is violation us ##ip financial system added sc ##ha ##ff ##ner longtime you official lecture regularly international affair republican politics published book you foreign policy you government asked president united state love goodness particularly come israel say trump often feel proportion israeli do not get along trump jewish family visible life sc ##ha ##ff ##ner say he controversial come israel mister trump sc ##ha ##ff ##ner argues does not like aggressive israeli jew see israel bit extreme system ty ##ran ##ny pre ##va ##ils goodness sc ##ha ##ff ##ner say note since net ##any ##ahu returned office he attacked attacking you opponent donald trump rather israeli leader net ##any ##ahu sc ##ha ##ff ##ner subsequent interview say president constructive pr ##ag ##matic steward israel economic security political cl ##out recently budget billion fiscal rejected bi ##partisan majority congress tried push budget net ##any ##ahu took seriously sc ##ha ##ff ##ner say understands important people comfortable view sense en ##ti ##tlement sc ##ha [SEP]\n",
            "[NeMo I 2021-10-20 21:04:41 text_classification_dataset:241] input_ids: 101 2825 2343 3778 3049 5094 5611 3539 2704 6425 5658 19092 21463 2231 2157 2008 2003 6685 2992 8080 6350 9317 2577 2899 2118 2934 3581 8040 3270 4246 3678 2066 5088 9074 2208 2447 7634 2343 8398 19732 2552 7209 24859 3956 2017 5611 3276 2360 3145 11434 3539 2704 5658 19092 21463 2117 2744 2136 2447 2045 2843 9509 2343 2079 2025 2156 4276 8688 2079 2025 2156 4760 2002 10132 2490 2137 12525 8040 3270 4246 3678 2409 8080 6350 2017 2024 5611 3482 2436 2079 2025 2729 5525 2008 2003 11371 2149 11514 3361 2291 2794 8040 3270 4246 3678 11155 2017 2880 8835 5570 2248 6771 3951 4331 2405 2338 2017 3097 3343 2017 2231 2356 2343 2142 2110 2293 15003 3391 2272 3956 2360 8398 2411 2514 10817 5611 2079 2025 2131 2247 8398 3644 2155 5710 2166 8040 3270 4246 3678 2360 2002 6801 2272 3956 12525 8398 8040 3270 4246 3678 9251 2515 2025 2066 9376 5611 16522 2156 3956 2978 6034 2291 5939 5521 4890 3653 3567 12146 15003 8040 3270 4246 3678 2360 3602 2144 5658 19092 21463 2513 2436 2002 4457 7866 2017 7116 6221 8398 2738 5611 3003 5658 19092 21463 8040 3270 4246 3678 4745 4357 2360 2343 26157 10975 8490 12644 17946 3956 3171 3036 2576 18856 5833 3728 5166 4551 10807 5837 12170 26053 3484 3519 2699 5245 5166 5658 19092 21463 2165 5667 8040 3270 4246 3678 2360 19821 2590 2111 6625 3193 3168 4372 3775 24007 8040 3270 102\n",
            "[NeMo I 2021-10-20 21:04:41 text_classification_dataset:242] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "[NeMo I 2021-10-20 21:04:41 text_classification_dataset:243] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "[NeMo I 2021-10-20 21:04:41 text_classification_dataset:244] label: 0\n",
            "[NeMo I 2021-10-20 21:04:41 text_classification_dataset:238] *** Example ***\n",
            "[NeMo I 2021-10-20 21:04:41 text_classification_dataset:239] example 1: ['pennsylvania', 'place', 'go', 'farmer', 'market', 'you', 'are', 'looking', 'purchase', 'fresh', 'locally', 'produced', 'good', 'shortage', 'market', 'visit', 'keystone', 'state', 'recognize', 'outdoor', 'market', 'season', 'kick', 'soon', 'list', 'picked', 'must', 'visit', 'indoor', 'market', 'obviously', 'can', 'not', 'write', 'please', 'share', 'favorite', 'indoor', 'market', 'spot', 'you', 'comment', 'section', 'lancaster', 'central', 'market', 'vibrant', 'alive', 'thriving', 'credit', 'among', 'recognized', 'farmer', 'market', 'central', 'pennsylvania', 'nation', 'market', 'destination', 'shopper', 'come', 'food', 'history', 'architecture', 'amish', 'culture', 'known', 'oldest', 'continuously', 'operated', 'farmer', 'market', 'country', 'established', 'vendor', 'range', 'longtime', 'stand', 'owner', 'like', 'longs', 'horseradish', 'clyde', 'weaver', 'newcomer', 'jb', 'kelly', 'seafood', 'connection', 'rooster', 'street', 'butcher', 'shopper', 'come', 'produce', 'deli', 'item', 'meat', 'seafood', 'prepared', 'food', 'market', 'numerous', 'award', 'recognition', 'named', 'top', 'best', 'fresh', 'market', 'world', 'cnn', 'travel', 'day', 'market', 'basking', 'glow', 'new', 'slate', 'roof', 'thanks', 'nearly', 'million', 'raise', 'roof', 'campaign', 'market', 'st', 'lancaster', 'hour', 'tuesday', 'friday', 'saturday', 'har', 'reading', 'terminal', 'market', 'sign', 'feb', 'julia', 'hatmaker', 'jhatmaker', 'har', 'food', 'hall', 'heart', 'phillys', 'food', 'scene', 'you', 'all', 'find', 'row', 'row', 'vendor', 'popular', 'destination', 'must', 'stop', 'town', 'visitor', 'looking', 'taste', 'philadelphia', 'amish', 'food', 'famous', 'roast', 'pork', 'ethnic', 'eats', 'dessert', 'beer', 'head', 'spinning', 'many', 'choice', 'recognized', 'stand', 'include', 'beilers', 'donut', 'carmens', 'famous', 'italian', 'hoagy', 'beck', 'cajun', 'cafe', 'dinics', 'among', 'others', 'market', 'rich', 'history', 'philadelphia', 'around', 'since', 'word', 'terminal', 'name', 'arrived', 'fact', 'vendor', 'refused', 'move', 'created', 'market', 'underneath', 'track', 'terminal', 'philadelphia', 'reading', 'railroad', 'company', 'railroad', 'left', 'luckily', 'shopper', 'market', 'remained', 'evolved', 'ethnic', 'regional', 'offering', 'market', 'big', 'anniversary', 'celebrate', 'topped', 'online', 'farmer', 'market', 'list', 'best', 'farmer', 'market', 'united', 'state', 'th', 'arch', 'street', 'center', 'city', 'philadelphia', 'hour', 'daily', 'vicki', 'vellios', 'briner', 'special', 'pennlive', 'seen', 'burg', 'broad', 'street', 'market', 'harrisburg', 'friday', 'vicki', 'vellios', 'briner', 'special', 'pennlive', 'hard', 'believe', 'broad', 'street', 'market', 'brink', 'closing', 'today', 'historic', 'market', 'flourishing', 'thanks', 'influx', 'vendor', 'part', 'farmer', 'market', 'part', 'food', 'hall', 'broad', 'street', 'market', 'much', 'place', 'fill', 'weekly', 'grocery', 'list', 'spot', 'order', 'artisan', 'pizza', 'greek', 'food', 'cheesesteaks', 'craft', 'beer', 'plenty', 'explore', 'market', 'building', 'offering', 'fuse', 'pa', 'favorite', 'shoofly', 'pie', 'broasted', 'chicken', 'organic', 'food', 'international', 'cuisine', 'sip', 'coffee', 'elementary', 'coffee', 'co', 'nibble', 'fudge', 'fudge', 'lutely', 'pick', 'fried', 'fish', 'teps', 'seafood', 'founded', 'broad', 'street', 'oldest', 'continuously', 'operating', 'farmer', 'market', 'country', 'operates', 'nonprofit', 'entity', 'broad', 'street', 'market', 'alliance', 'recommendation', 'task', 'force', 'sure', 'check', 'market', 'monthly', 'rd', 'burg', 'event', 'held', 'every', 'third', 'friday', 'third', 'st', 'harrisburg', 'hour', 'thursday', 'friday', 'saturday', 'christine', 'baker', 'cbaker', 'central', 'market', 'york', 'located', 'west', 'philadelphia', 'street', 'downtown', 'york', 'pennlive', 'file', 'photo', 'wont', 'leave', 'empty', 'handed', 'visit', 'york', 'central', 'market', 'popular', 'meeting', 'place', 'pick', 'everything', 'produce', 'cupcake', 'also', 'community', 'gathering', 'spot', 'place', 'you', 'all', 'bump', 'neighbor', 'friend', 'acquaintance', 'shop', 'aisle', 'saturday', 'morning', 'also', 'unexpected', 'stop', 'tourist', 'market', 'built', 'first', 'building', 'york', 'indoor', 'plumbing', 'market', 'operates', 'private', 'corporation', 'vendor', 'comprise', 'market', 'selling', 'produce', 'prepared', 'food', 'well', 'gift', 'item', 'soap', 'glass', 'art', 'creation', 'sure', 'check', 'conrad', 'deli', 'copper', 'crust', 'loaf', 'fish', 'cupcake', 'philadelphia', 'st', 'york', 'hour', 'tuesday', 'thursday', 'saturday', 'shortage', 'food', 'buy', 'vendor', 'allentown', 'farmer', 'market', 'located', 'next', 'famed', 'fair', 'grand', 'stand', 'customer', 'come', 'food', 'amish', 'food', 'middle', 'eastern', 'indian', 'fare', 'burger', 'pretzel', 'well', 'atmosphere', 'do', 'not', 'call', 'oldest', 'tradition', 'lehigh', 'valley', 'nothing', 'among', 'vendor', 'gannons', 'gourmet', 'dans', 'bbq', 'chicken', 'stand', 'mary', 'anns', 'donut', 'kitchen', 'peter', 'brothers', 'meat', 'market', 'charlie', 'customer', 'rave', 'service', 'selection', 'school', 'market', 'atmosphere', 'market', 'date', 'chew', 'st', 'allentown', 'hour', 'thursday', 'friday', 'saturday', 'admit', 'green', 'dragon', 'farmer', 'market', 'definitely', 'leave', 'nearly', 'everything', 'sun', 'tool', 'dish', 'towel', 'local', 'visitor', 'crowd', 'acre', 'every', 'friday', 'auction', 'purchase', 'item', 'plant', 'home', 'good', 'clothing', 'complex', 'also', 'house', 'farmer', 'market', 'vendor', 'you', 'all', 'find', 'everything', 'need', 'produce', 'meat', 'cheese', 'bakery', 'product', 'way', 'can', 'not', 'miss', 'market', 'look', 'green', 'dragon', 'atop', 'farmer', 'market', 'sign', 'state', 'st', 'ephrata', 'hour', 'friday', 'pittsburgh', 'market', 'connects', 'shopper', 'farmer', 'permanent', 'round', 'market', 'open', 'hour', 'every', 'noon', 'sunday', 'east', 'liberty', 'neighborhood', 'pittsburgh', 'regular', 'say', 'love', 'variety', 'vendor', 'quality', 'item', 'sold', 'cooperative', 'oldest', 'continuously', 'operating', 'market', 'western', 'pennsylvania', 'dating', 'set', 'market', 'apart', 'others', 'owned', 'cooperative', 'group', 'farmer', 'owner', 'include', 'kennedy', 'family', 'operate', 'kennedy', 'meat', 'stand', 'rick', 'zang', 'owner', 'zangs', 'greenhouse', 'tim', 'suzanne', 'hileman', 'owner', 'kistaco', 'farm', 'ina', 'john', 'greenawalt', 'owner', 'greenawalt', 'farm', 'plus', 'additional', 'vendor', 'selling', 'bedding', 'plant', 'produce', 'baked', 'good', 'north', 'sheridan', 'avenue', 'pittsburgh', 'hour', 'noon', 'saturday', 'market', 'hub', 'meadville', 'since', 'constructed', 'say', 'oldest', 'continuously', 'run', 'market', 'structure', 'state', 'meeting', 'place', 'market', 'shopper', 'purchase', 'local', 'produce', 'egg', 'meat', 'home', 'baked', 'good', 'local', 'organic', 'good', 'gourmet', 'good', 'artisan', 'craft', 'meadville', 'council', 'art', 'located', 'second', 'floor', 'art', 'gallery', 'dance', 'studio', 'small', 'theater', 'market', 'also', 'house', 'market', 'house', 'grille', 'zest', 'kitchen', 'pantry', 'save', 'room', 'dessert', 'market', 'st', 'meadville', 'hour', 'wednesday', 'saturday']\n",
            "[NeMo I 2021-10-20 21:04:41 text_classification_dataset:240] subtokens: [CLS] pennsylvania place go farmer market you are looking purchase fresh locally produced good shortage market visit keystone state recognize outdoor market season kick soon list picked must visit indoor market obviously can not write please share favorite indoor market spot you comment section lancaster central market vibrant alive thriving credit among recognized farmer market central pennsylvania nation market destination shop ##per come food history architecture ami ##sh culture known oldest continuously operated farmer market country established vendor range longtime stand owner like long ##s horse ##rad ##ish clyde weaver newcomer j ##b kelly seafood connection rooster street butcher shop ##per come produce del ##i item meat seafood prepared food market numerous award recognition named top best fresh market world cnn travel day market bas ##king glow new slate roof thanks nearly million raise roof campaign market st lancaster hour tuesday friday saturday ha ##r reading terminal market sign feb julia hat ##maker j ##hat ##maker ha ##r food hall heart phil ##ly ##s food scene you all find row row vendor popular destination must stop town visitor looking taste philadelphia ami ##sh food famous roast pork ethnic eats dessert beer head spinning many choice recognized stand include bei ##lers don ##ut carmen ##s famous italian ho ##ag ##y beck ca ##jun cafe din ##ics among others market rich history philadelphia around since word terminal name arrived fact vendor refused move created market underneath track terminal philadelphia reading railroad company railroad left luckily shop ##per market remained evolved ethnic regional offering market big anniversary celebrate topped [SEP]\n",
            "[NeMo I 2021-10-20 21:04:41 text_classification_dataset:241] input_ids: 101 3552 2173 2175 7500 3006 2017 2024 2559 5309 4840 7246 2550 2204 15843 3006 3942 22271 2110 6807 7254 3006 2161 5926 2574 2862 3856 2442 3942 7169 3006 5525 2064 2025 4339 3531 3745 5440 7169 3006 3962 2017 7615 2930 10237 2430 3006 17026 4142 20319 4923 2426 3858 7500 3006 2430 3552 3842 3006 7688 4497 4842 2272 2833 2381 4294 26445 4095 3226 2124 4587 10843 3498 7500 3006 2406 2511 21431 2846 11155 3233 3954 2066 2146 2015 3586 12173 4509 12085 14077 16866 1046 2497 5163 23621 4434 27681 2395 14998 4497 4842 2272 3965 3972 2072 8875 6240 23621 4810 2833 3006 3365 2400 5038 2315 2327 2190 4840 3006 2088 13229 3604 2154 3006 19021 6834 8652 2047 12796 4412 4283 3053 2454 5333 4412 3049 3006 2358 10237 3178 9857 5958 5095 5292 2099 3752 5536 3006 3696 13114 6423 6045 8571 1046 12707 8571 5292 2099 2833 2534 2540 6316 2135 2015 2833 3496 2017 2035 2424 5216 5216 21431 2759 7688 2442 2644 2237 10367 2559 5510 4407 26445 4095 2833 3297 25043 15960 5636 20323 18064 5404 2132 9419 2116 3601 3858 3233 2421 21388 12910 2123 4904 11425 2015 3297 3059 7570 8490 2100 10272 6187 19792 7668 11586 6558 2426 2500 3006 4138 2381 4407 2105 2144 2773 5536 2171 3369 2755 21431 4188 2693 2580 3006 7650 2650 5536 4407 3752 4296 2194 4296 2187 15798 4497 4842 3006 2815 7964 5636 3164 5378 3006 2502 5315 8439 9370 102\n",
            "[NeMo I 2021-10-20 21:04:41 text_classification_dataset:242] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "[NeMo I 2021-10-20 21:04:41 text_classification_dataset:243] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "[NeMo I 2021-10-20 21:04:41 text_classification_dataset:244] label: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2021-10-20 21:05:45 text_classification_dataset:251] Found 1689 out of 3000 sentences with more than 256 subtokens. Truncated long sentences from the end.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2021-10-20 21:05:45 data_preprocessing:299] Some stats of the lengths of the sequences:\n",
            "[NeMo I 2021-10-20 21:05:45 data_preprocessing:305] Min: 55 |                  Max: 257 |                  Mean: 226.15433333333334 |                  Median: 257.0\n",
            "[NeMo I 2021-10-20 21:05:45 data_preprocessing:307] 75 percentile: 257.00\n",
            "[NeMo I 2021-10-20 21:05:45 data_preprocessing:308] 99 percentile: 257.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2021-10-20 21:05:45 modelPT:201] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2021-10-20 21:05:45 megatron_utils:274] Downloading from https://api.ngc.nvidia.com/v2/models/nvidia/megatron_bert_345m/versions/v0.0/files/release/mp_rank_00/model_optim_rng.pt\n",
            "using world size: 1, data-parallel-size: 1, tensor-model-parallel size: 1, pipeline-model-parallel size: 1 \n",
            "setting global batch size to 1\n",
            "using torch.float32 for parameters ...\n",
            "------------------------ arguments ------------------------\n",
            "  adam_beta1 ...................................... 0.9\n",
            "  adam_beta2 ...................................... 0.999\n",
            "  adam_eps ........................................ 1e-08\n",
            "  adlr_autoresume ................................. False\n",
            "  adlr_autoresume_interval ........................ 1000\n",
            "  apply_query_key_layer_scaling ................... True\n",
            "  apply_residual_connection_post_layernorm ........ False\n",
            "  attention_dropout ............................... 0.1\n",
            "  attention_softmax_in_fp32 ....................... False\n",
            "  bert_load ....................................... None\n",
            "  bias_dropout_fusion ............................. False\n",
            "  bias_gelu_fusion ................................ False\n",
            "  block_data_path ................................. None\n",
            "  checkpoint_activations .......................... False\n",
            "  checkpoint_num_layers ........................... 1\n",
            "  clip_grad ....................................... 1.0\n",
            "  consumed_train_samples .......................... 0\n",
            "  consumed_valid_samples .......................... 0\n",
            "  data_impl ....................................... infer\n",
            "  data_parallel_size .............................. 1\n",
            "  data_path ....................................... None\n",
            "  DDP_impl ........................................ local\n",
            "  distribute_checkpointed_activations ............. False\n",
            "  distributed_backend ............................. nccl\n",
            "  eod_mask_loss ................................... False\n",
            "  eval_interval ................................... 1000\n",
            "  eval_iters ...................................... 100\n",
            "  exit_duration_in_mins ........................... None\n",
            "  exit_interval ................................... None\n",
            "  faiss_use_gpu ................................... False\n",
            "  finetune ........................................ False\n",
            "  fp16 ............................................ False\n",
            "  fp16_lm_cross_entropy ........................... False\n",
            "  fp32_allreduce .................................. False\n",
            "  fp32_residual_connection ........................ False\n",
            "  global_batch_size ............................... 1\n",
            "  hidden_dropout .................................. 0.1\n",
            "  hidden_size ..................................... 1024\n",
            "  hysteresis ...................................... 2\n",
            "  ict_head_size ................................... None\n",
            "  ict_load ........................................ None\n",
            "  indexer_batch_size .............................. 128\n",
            "  indexer_log_interval ............................ 1000\n",
            "  init_method_std ................................. 0.02\n",
            "  initial_loss_scale .............................. 4294967296\n",
            "  layernorm_epsilon ............................... 1e-05\n",
            "  lazy_mpu_init ................................... True\n",
            "  load ............................................ None\n",
            "  local_rank ...................................... None\n",
            "  log_interval .................................... 100\n",
            "  loss_scale ...................................... None\n",
            "  loss_scale_window ............................... 1000\n",
            "  lr .............................................. None\n",
            "  lr_decay_iters .................................. None\n",
            "  lr_decay_samples ................................ None\n",
            "  lr_decay_style .................................. linear\n",
            "  lr_warmup_fraction .............................. None\n",
            "  lr_warmup_iters ................................. 0\n",
            "  lr_warmup_samples ............................... 0\n",
            "  make_vocab_size_divisible_by .................... 128\n",
            "  mask_prob ....................................... 0.15\n",
            "  max_position_embeddings ......................... 512\n",
            "  merge_file ...................................... None\n",
            "  micro_batch_size ................................ 1\n",
            "  min_loss_scale .................................. 1.0\n",
            "  min_lr .......................................... 0.0\n",
            "  mmap_warmup ..................................... False\n",
            "  no_load_optim ................................... False\n",
            "  no_load_rng ..................................... False\n",
            "  no_save_optim ................................... False\n",
            "  no_save_rng ..................................... False\n",
            "  num_attention_heads ............................. 16\n",
            "  num_layers ...................................... 24\n",
            "  num_workers ..................................... 2\n",
            "  onnx_safe ....................................... True\n",
            "  openai_gelu ..................................... False\n",
            "  override_lr_scheduler ........................... False\n",
            "  params_dtype .................................... torch.float32\n",
            "  pipeline_model_parallel_size .................... 1\n",
            "  query_in_block_prob ............................. 0.1\n",
            "  rampup_batch_size ............................... None\n",
            "  rank ............................................ 0\n",
            "  report_topk_accuracies .......................... []\n",
            "  reset_attention_mask ............................ False\n",
            "  reset_position_ids .............................. False\n",
            "  save ............................................ None\n",
            "  save_interval ................................... None\n",
            "  scaled_masked_softmax_fusion .................... False\n",
            "  scaled_upper_triang_masked_softmax_fusion ....... False\n",
            "  seed ............................................ 1234\n",
            "  seq_length ...................................... None\n",
            "  short_seq_prob .................................. 0.1\n",
            "  split ........................................... 969, 30, 1\n",
            "  tensor_model_parallel_size ...................... 1\n",
            "  tensorboard_dir ................................. None\n",
            "  titles_data_path ................................ None\n",
            "  tokenizer_type .................................. BertWordPieceLowerCase\n",
            "  train_iters ..................................... None\n",
            "  train_samples ................................... None\n",
            "  use_checkpoint_lr_scheduler ..................... False\n",
            "  use_cpu_initialization .......................... False\n",
            "  use_one_sent_docs ............................... False\n",
            "  vocab_file ...................................... /root/.cache/huggingface/nemo_nlp_tmp/61306d8edc128c2e2f3207632faeaa45/tokenizer.vocab_file\n",
            "  weight_decay .................................... 0.01\n",
            "  world_size ...................................... 1\n",
            "-------------------- end of arguments ---------------------\n",
            "setting number of micro-batches to constant 1\n",
            "> building BertWordPieceLowerCase tokenizer ...\n",
            " > padded vocab (size: 30522) with 70 dummy tokens (new size: 30592)\n",
            "[NeMo I 2021-10-20 21:06:13 megatron_bert:118] Megatron-lm argparse args: Namespace(DDP_impl='local', adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, adlr_autoresume=False, adlr_autoresume_interval=1000, apply_query_key_layer_scaling=True, apply_residual_connection_post_layernorm=False, attention_dropout=0.1, attention_softmax_in_fp32=False, bert_load=None, bias_dropout_fusion=False, bias_gelu_fusion=False, block_data_path=None, checkpoint_activations=False, checkpoint_num_layers=1, clip_grad=1.0, consumed_train_samples=0, consumed_valid_samples=0, data_impl='infer', data_parallel_size=1, data_path=None, distribute_checkpointed_activations=False, distributed_backend='nccl', eod_mask_loss=False, eval_interval=1000, eval_iters=100, exit_duration_in_mins=None, exit_interval=None, faiss_use_gpu=False, finetune=False, fp16=False, fp16_lm_cross_entropy=False, fp32_allreduce=False, fp32_residual_connection=False, global_batch_size=1, hidden_dropout=0.1, hidden_size=1024, hysteresis=2, ict_head_size=None, ict_load=None, indexer_batch_size=128, indexer_log_interval=1000, init_method_std=0.02, initial_loss_scale=4294967296, layernorm_epsilon=1e-05, lazy_mpu_init=True, load=None, local_rank=None, log_interval=100, loss_scale=None, loss_scale_window=1000, lr=None, lr_decay_iters=None, lr_decay_samples=None, lr_decay_style='linear', lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, make_vocab_size_divisible_by=128, mask_prob=0.15, max_position_embeddings=512, merge_file=None, micro_batch_size=1, min_loss_scale=1.0, min_lr=0.0, mmap_warmup=False, no_load_optim=False, no_load_rng=False, no_save_optim=False, no_save_rng=False, num_attention_heads=16, num_layers=24, num_workers=2, onnx_safe=True, openai_gelu=False, override_lr_scheduler=False, padded_vocab_size=30592, params_dtype=torch.float32, pipeline_model_parallel_size=1, query_in_block_prob=0.1, rampup_batch_size=None, rank=0, report_topk_accuracies=[], reset_attention_mask=False, reset_position_ids=False, save=None, save_interval=None, scaled_masked_softmax_fusion=False, scaled_upper_triang_masked_softmax_fusion=False, seed=1234, seq_length=None, short_seq_prob=0.1, split='969, 30, 1', tensor_model_parallel_size=1, tensorboard_dir=None, titles_data_path=None, tokenizer_type='BertWordPieceLowerCase', train_iters=None, train_samples=None, use_checkpoint_lr_scheduler=False, use_cpu_initialization=True, use_one_sent_docs=False, vocab_file='/root/.cache/huggingface/nemo_nlp_tmp/61306d8edc128c2e2f3207632faeaa45/tokenizer.vocab_file', weight_decay=0.01, world_size=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2021-10-20 21:06:18 megatron_bert:204] Megatron-lm checkpoint version not found. Setting checkpoint_version to 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2021-10-20 21:06:18 megatron_bert:212] Checkpoint loaded from from /root/.cache/torch/megatron/megatron-bert-345m-uncased\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeMkOTe0rG6w"
      },
      "source": [
        "import gc\n",
        "\n",
        "gc.collect()\n",
        "\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GoA1lOD0WML",
        "outputId": "bf927ce3-a9d3-4298-e31c-a19b31b9c38c"
      },
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "    process = psutil.Process(os.getpid())\n",
        "    print(\"Gen RAM Free: \" + humanize.naturalsize(psutil.virtual_memory().available), \" |     Proc size: \" + humanize.naturalsize(process.memory_info().rss))\n",
        "    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total     {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp37-none-any.whl size=7411 sha256=2c8c6598681f23c8fd80ca3faff6b10f0a4d4f2be217af6305971eab8a0ead46\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.7/dist-packages (0.5.1)\n",
            "Gen RAM Free: 12.0 GB  |     Proc size: 3.0 GB\n",
            "GPU RAM Free: 16278MB | Used: 2MB | Util   0% | Total     16280MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpdKYJgpiXdK"
      },
      "source": [
        "import torch\n",
        "import torchvision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZuO-3gviyLr",
        "outputId": "f5d96709-1bb5-4966-adde-f3c55f4ec788"
      },
      "source": [
        "print (torch.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.8.1+cu101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTADmrX4i2Nz",
        "outputId": "768eda56-c9bb-4676-c66f-139764619140"
      },
      "source": [
        "print (torchvision.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.10.0+cu111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "eKx7ly57mn9F",
        "outputId": "b6c755ee-3328-488e-f77f-01fadb7048a9"
      },
      "source": [
        "torch.cuda.amp.autocast_mode._cast(args, torch.get_autocast_gpu_dtype())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-9fa86aa41ab4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast_mode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_autocast_gpu_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPjXWy6QsPRf",
        "outputId": "54f5a72f-f60a-4266-c150-36f33d868ce2"
      },
      "source": [
        "torch.cuda.amp.autocast(enabled=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.cuda.amp.autocast_mode.autocast at 0x7fbf8b820c50>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "ump9ypc3iYMc",
        "outputId": "a61719b6-5913-424b-dd49-f37fecea0481"
      },
      "source": [
        "torch.get_autocast_gpu_dtype()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-8e87bed13784>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_autocast_gpu_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'get_autocast_gpu_dtype'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 852,
          "referenced_widgets": [
            "c02e855193d64605965a6f881f44e914",
            "db0ba14f1436449394315567f8cfd2ea",
            "1926458526a3497c961e728ac6b67dd2",
            "5637b9f457a84ecfa7445b1e917c132d",
            "ba1646195fee4f02a757f67ace4bc8fa",
            "06cf4a0977b84fb5a1eb12100d5337d9",
            "cecd66b5c58f4aba88503a6f83480382",
            "d1fc52cc114449e49fb640a293eb4185",
            "49d83be84cea45d394cc24bd8ae33391",
            "7a15107f251e470086020b5809cd3afd",
            "eba1b67beab7435cb77bd8916eefc8b5"
          ]
        },
        "id": "vYa-dPVsmaqT",
        "outputId": "5fbb8f14-1ddf-4355-cd76-77a203a01f90"
      },
      "source": [
        "trainer.fit(model)\n",
        "model.save_to(config.save_to)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2021-10-20 21:52:34 modelPT:201] You tried to register an artifact under config key=language_model.config_file but an artifact for it has already been registered.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2021-10-20 21:52:34 modelPT:751] Optimizer config = Adam (\n",
            "    Parameter Group 0\n",
            "        amsgrad: False\n",
            "        betas: [0.9, 0.999]\n",
            "        eps: 1e-08\n",
            "        lr: 2e-05\n",
            "        weight_decay: 0.01\n",
            "    )\n",
            "[NeMo I 2021-10-20 21:52:34 lr_scheduler:625] Scheduler \"<nemo.core.optim.lr_scheduler.WarmupAnnealing object at 0x7fbf8b8241d0>\" \n",
            "    will be used during training (effective maximum steps = 25000) - \n",
            "    Parameters : \n",
            "    (warmup_steps: null\n",
            "    warmup_ratio: 0.1\n",
            "    last_epoch: -1\n",
            "    max_steps: 25000\n",
            "    )\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  | Name                  | Type                 | Params\n",
            "---------------------------------------------------------------\n",
            "0 | loss                  | CrossEntropyLoss     | 0     \n",
            "1 | bert_model            | MegatronBertEncoder  | 334 M \n",
            "2 | classifier            | SequenceClassifier   | 1.1 M \n",
            "3 | classification_report | ClassificationReport | 0     \n",
            "---------------------------------------------------------------\n",
            "335 M     Trainable params\n",
            "0         Non-trainable params\n",
            "335 M     Total params\n",
            "1,340.862 Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c02e855193d64605965a6f881f44e914",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-0a60a6974eaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[1;32m    456\u001b[0m         )\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0;31m# dispatch `start_training` or `start_evaluating` or `start_predicting`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m         \u001b[0;31m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mdispatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    795\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_predicting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'pl.Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_evaluating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'pl.Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'pl.Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;31m# double dispatch to initiate the training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_evaluating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'pl.Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pre_training_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    867\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m                     \u001b[0;31m# run train epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 869\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0;31m# ------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_batch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m                 \u001b[0mbatch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0;31m# when returning -1 from train_step, we end epoch early\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_batch\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                         \u001b[0;31m# optimizer step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 738\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_and_backward_closure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m                             \u001b[0;31m# revert back to previous state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, opt_idx, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0mon_tpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_device_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mDeviceType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPU\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_TPU_AVAILABLE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0musing_native_amp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0musing_native_amp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m             \u001b[0musing_lbfgs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_lbfgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m         )\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/lightning.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_idx, optimizer_closure, on_tpu, using_native_amp, using_lbfgs)\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1402\u001b[0m         \"\"\"\n\u001b[0;32m-> 1403\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer_closure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimizer_zero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/optimizer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure, *args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0mprofiler_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"optimizer_step_and_closure_{self._optimizer_idx}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofiler_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofiler_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_optimizer_step_calls\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/optimizer.py\u001b[0m in \u001b[0;36m__optimizer_step\u001b[0;34m(self, closure, profiler_name, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofiler_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_closure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, opt_idx, lambda_closure, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \"\"\"\n\u001b[1;32m    325\u001b[0m         make_optimizer_step = self.precision_plugin.pre_optimizer_step(\n\u001b[0;32m--> 326\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_closure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m         )\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmake_optimizer_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/precision/native_amp.py\u001b[0m in \u001b[0;36mpre_optimizer_step\u001b[0;34m(self, pl_module, optimizer, optimizer_idx, lambda_closure, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlambda_closure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m             \u001b[0;31m# lambda_closure returning None indicates that backward has been skipped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtrain_step_and_backward_closure\u001b[0;34m()\u001b[0m\n\u001b[1;32m    731\u001b[0m                         \u001b[0;32mdef\u001b[0m \u001b[0mtrain_step_and_backward_closure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m                             result = self.training_step_and_backward(\n\u001b[0;32m--> 733\u001b[0;31m                                 \u001b[0msplit_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhiddens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    734\u001b[0m                             )\n\u001b[1;32m    735\u001b[0m                             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtraining_step_and_backward\u001b[0;34m(self, split_batch, batch_idx, opt_idx, optimizer, hiddens)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training_step_and_backward\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m             \u001b[0;31m# lightning module hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhiddens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_curr_step_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, split_batch, batch_idx, opt_idx, hiddens)\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0mmodel_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training_step\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m                 \u001b[0mtraining_step_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpost_training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpost_training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nemo/utils/model_utils.py\u001b[0m in \u001b[0;36mwrap_training_step\u001b[0;34m(wrapped, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mwrapt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwrap_training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLightningModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m     \u001b[0moutput_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0moutput_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'log'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nemo/collections/nlp/models/text_classification/text_classification_model.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;31m# forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nemo/core/classes/common.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, wrapped, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0;31m# Call the method - this can be forward, or any other callable method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m         instance._attach_and_validate_output_types(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nemo/collections/nlp/models/text_classification/text_classification_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, attention_mask)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \"\"\"\n\u001b[1;32m    105\u001b[0m         hidden_states = self.bert_model(\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         )\n\u001b[1;32m    108\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nemo/core/classes/common.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, wrapped, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0;31m# Call the method - this can be forward, or any other callable method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m         instance._attach_and_validate_output_types(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nemo/collections/nlp/modules/common/megatron/megatron_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0mtokentype_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         )\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msequence_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/megatron/model/language_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, position_ids, attention_mask, tokentype_ids, layer_past, get_key_value, pooling_sequence_index)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0mlayer_past\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0mget_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0mpooling_sequence_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpooling_sequence_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m         )\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/megatron/model/language_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, language_model_input, attention_mask, tokentype_ids, layer_past, get_key_value, pooling_sequence_index)\u001b[0m\n\u001b[1;32m    329\u001b[0m                                               \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                                               \u001b[0mlayer_past\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                                               get_key_value=get_key_value)\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_pipeline_last_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_pooler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/megatron/model/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, layer_past, get_key_value)\u001b[0m\n\u001b[1;32m    590\u001b[0m                                       \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                                       \u001b[0mlayer_past\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m                                       get_key_value=get_key_value)\n\u001b[0m\u001b[1;32m    593\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mget_key_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpresent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/megatron/model/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, layer_past, get_key_value)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0;31m# Layer norm at the begining of the transformer layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m         \u001b[0mlayernorm_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m         \u001b[0;31m# Self attention.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0mattention_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_bias\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/apex/normalization/fused_layer_norm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalized_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melementwise_affine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfused_layer_norm_affine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalized_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfused_layer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalized_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/apex/normalization/fused_layer_norm.py\u001b[0m in \u001b[0;36mfused_layer_norm_affine\u001b[0;34m(input, weight, bias, normalized_shape, eps)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfused_layer_norm_affine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_cast_if_autocast_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mFusedLayerNormAffineFunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/apex/_autocast_utils.py\u001b[0m in \u001b[0;36m_cast_if_autocast_enabled\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast_mode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_autocast_gpu_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'get_autocast_gpu_dtype'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hD8GYRpQ1tWh"
      },
      "source": [
        "### Validation the Model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80UTNApxczK8"
      },
      "source": [
        "#import gc\n",
        "\n",
        "#gc.collect()\n",
        "\n",
        "#torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdGkcuJMdAsI"
      },
      "source": [
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "    process = psutil.Process(os.getpid())\n",
        "    print(\"Gen RAM Free: \" + humanize.naturalsize(psutil.virtual_memory().available), \" |     Proc size: \" + humanize.naturalsize(process.memory_info().rss))\n",
        "    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total     {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSyFUeY9gjJb"
      },
      "source": [
        "#from glob import glob\n",
        "#LOG_CHECKPOINT_DIR = '/content/LOG_CHECKPOINT_DIR/TextClassification/2021-07-15_13-28-29/'\n",
        "#checkpoint_dir = os.path.join(LOG_CHECKPOINT_DIR, 'checkpoints')\n",
        "#checkpoint_paths = list(glob(os.path.join(checkpoint_dir, \"*.ckpt\")))\n",
        "#checkpoint_paths"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXX027GNhPCo"
      },
      "source": [
        "#final_checkpoint = list(filter(lambda x: \"-last.ckpt\" in x, checkpoint_paths))[0]\n",
        "#print(final_checkpoint)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SMBRg7NzT_B"
      },
      "source": [
        "#checkpoint_path = final_checkpoint\n",
        "# Create an evaluation model and load the checkpoint\n",
        "#eval_model = nemo_nlp.models.TextClassificationModel.load_from_checkpoint(checkpoint_path=checkpoint_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GW0pVfUcjdq8"
      },
      "source": [
        "#import pytorch_lightning as ptl\n",
        "#from nemo.core import ModelPT\n",
        "#from omegaconf import OmegaConf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqH2FPUdm5hh"
      },
      "source": [
        "#heckpoint_path = trainer.checkpoint_callback.best_model_path\n",
        "# Create an evaluation model and load the checkpoint\n",
        "#eval_model = nemo_nlp.models.TextClassificationModel.load_from_checkpoint(checkpoint_path=checkpoint_path)\n",
        "\n",
        "# create a dataloader config for evaluation, the same data file provided in validation_ds is used here\n",
        "# file_path can get updated with any file\n",
        "#eval_config = OmegaConf.create({'file_path': '/content/DATA_DIR/RE/dev.tsv', 'batch_size': 8, 'shuffle': False, 'num_samples': -1})\n",
        "#eval_model.setup_test_data(test_data_config=eval_config)\n",
        "#eval_dataloader = eval_model._create_dataloader_from_config(cfg=eval_config, mode='test')\n",
        "\n",
        "# a new trainer is created to show how to evaluate a checkpoint from an already trained model\n",
        "# create a copy of the trainer config and update it to be used for final evaluation\n",
        "#eval_trainer_cfg = config.trainer.copy()\n",
        "#eval_trainer_cfg.gpus = 1 if torch.cuda.is_available() else 0 # it is safer to perform evaluation on single GPU as PT is buggy with the last batch on multi-GPUs\n",
        "#eval_trainer_cfg.accelerator = None # 'ddp' is buggy with test process in the current PT, it looks like it has been fixed in the latest master\n",
        "\n",
        "#val_trainer = pl.Trainer(**eval_trainer_cfg)\n",
        "\n",
        "#eval_trainer.test(model=eval_model, verbose=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUzKcukqPBvu"
      },
      "source": [
        "#eval_trainer = pl.Trainer(gpus=1)\n",
        "#eval_model.set_trainer(eval_trainer)\n",
        "#eval_trainer.test(model=eval_model, verbose=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}