{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "embeded RepVGG layer in other model.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "78c1a343bcb2401094d9c8c9a71ea1fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b26493f2cc39487d860fd3f90c9b6092",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_eb87aaae6f90410e83b5bcb0ea215031",
              "IPY_MODEL_9eaa880181ee4c09b7de2d2633ab1451",
              "IPY_MODEL_ca758a550e544dfdbf0997d27d6f014d"
            ]
          }
        },
        "b26493f2cc39487d860fd3f90c9b6092": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eb87aaae6f90410e83b5bcb0ea215031": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ba64ab846a814e10aad6e2fd6e6aaf59",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0de34261c20e410e8842d5abf8a12afd"
          }
        },
        "9eaa880181ee4c09b7de2d2633ab1451": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0cc7c858f6344972b4a3c471167901b0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_16da2533862b46e1abdf493c3f3e1cc6"
          }
        },
        "ca758a550e544dfdbf0997d27d6f014d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e4e4d6184eec414694b832274a39c68f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:06&lt;00:00, 32020622.70it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ac1d3699b145431e96833212f717b503"
          }
        },
        "ba64ab846a814e10aad6e2fd6e6aaf59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0de34261c20e410e8842d5abf8a12afd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0cc7c858f6344972b4a3c471167901b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "16da2533862b46e1abdf493c3f3e1cc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e4e4d6184eec414694b832274a39c68f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ac1d3699b145431e96833212f717b503": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0619ad17caf54d65958cb1882e40205e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7ebf249b77f5481c8aa29f9f37eb7679",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_12a9a335577e417ab37ee1dc4185ccf0",
              "IPY_MODEL_11eddc37958244119d384d3aeb142f60",
              "IPY_MODEL_df3ef09503fd42a49bca57ad6c667384"
            ]
          }
        },
        "7ebf249b77f5481c8aa29f9f37eb7679": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "12a9a335577e417ab37ee1dc4185ccf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8ba76a2f5ef14ef2a3cfd2e614f6215a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4d2542e972e74645bf1958e1daa67ed0"
          }
        },
        "11eddc37958244119d384d3aeb142f60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_63c2c57a91734fc2a8daeba297686800",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 169001437,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 169001437,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dbc8a076426e4bbab953b06fb4cf7ac9"
          }
        },
        "df3ef09503fd42a49bca57ad6c667384": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f3d2584f1c10488fa5bb2d384c3eac91",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 169001984/? [00:04&lt;00:00, 47672686.33it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7881e881b6814cbc9495dcb11124618a"
          }
        },
        "8ba76a2f5ef14ef2a3cfd2e614f6215a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4d2542e972e74645bf1958e1daa67ed0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "63c2c57a91734fc2a8daeba297686800": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dbc8a076426e4bbab953b06fb4cf7ac9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f3d2584f1c10488fa5bb2d384c3eac91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7881e881b6814cbc9495dcb11124618a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8iq4TO4YkHp"
      },
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXEloVXxJpcq"
      },
      "source": [
        "#Import Necessary Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qa5nza3Q-gsI"
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "import pickle\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeKAzNvg-jBc"
      },
      "source": [
        "from torchsummary import summary\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from skimage.io import imread, imsave\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from skimage.transform import rotate\n",
        "from skimage.util import random_noise\n",
        "from skimage.filters import gaussian\n",
        "from scipy import ndimage\n",
        "import skimage as sk\n",
        "import random\n",
        "from sklearn.decomposition import  PCA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmC6P0NrjAV0"
      },
      "source": [
        "#Load CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "78c1a343bcb2401094d9c8c9a71ea1fb",
            "b26493f2cc39487d860fd3f90c9b6092",
            "eb87aaae6f90410e83b5bcb0ea215031",
            "9eaa880181ee4c09b7de2d2633ab1451",
            "ca758a550e544dfdbf0997d27d6f014d",
            "ba64ab846a814e10aad6e2fd6e6aaf59",
            "0de34261c20e410e8842d5abf8a12afd",
            "0cc7c858f6344972b4a3c471167901b0",
            "16da2533862b46e1abdf493c3f3e1cc6",
            "e4e4d6184eec414694b832274a39c68f",
            "ac1d3699b145431e96833212f717b503"
          ],
          "height": 120
        },
        "id": "d_hpqGbxkF7B",
        "outputId": "b822c93e-89d3-4553-81a9-6508f0c0a944"
      },
      "source": [
        "# Loading and normalizing CIFAR10\n",
        "\n",
        "transform = transforms.Compose(\n",
        "      [#transforms.Pad(4),\n",
        "      #transforms.RandomHorizontalFlip(),\n",
        "      #transforms.RandomCrop(32),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "78c1a343bcb2401094d9c8c9a71ea1fb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(trainset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAmu-z1qb1nq",
        "outputId": "053506b1-bf4e-4b78-e7cd-b1b2e43ce897"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtkYvHVGTan2",
        "outputId": "ae6d943a-2d00-4f2e-d8a4-4c9ad236d7c2"
      },
      "source": [
        "#deleteme\n",
        "type(trainset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torchvision.datasets.cifar.CIFAR10"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "qnier1_wEu1q",
        "outputId": "968311bb-31ac-4b7e-b794-7fae8ead09ba"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "print(images.shape)\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAK4AAAD8CAYAAADuSp8SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy8WZBl13Wm9+3hjHfMsTKzhqwqVAGFGSABiqTESZQoSmqLIXdbLcthKeyO6KcOP/jFevaL2xEOP7v7wR22Q7J7bqolWhZFDRQpgSMAogooVBWqsirn4c73nnEPfrgJEFQTkFoSosEQ/si8w7n7DPvc/6699tr/WsJ7zwf4AD9qkP+pL+ADfIC/Cj4g7gf4kcQHxP0AP5L4gLgf4EcSHxD3A/xI4gPifoAfSbxnxBVCfF4I8boQ4o4Q4tffq/N8gL+dEO9FHFcIoYBbwE8DO8C3gP/Se//q3/jJPsDfSrxXFvcjwB3v/V3vfQX8P8AX3qNzfYC/hdDv0XHPAttve78D/Ng7NU7T1Hc6HYQQzEcAD0L8YCP/5sPpdvH97eK07Z/f5S8D/+ajF6fHEW/+/ZC28/O/02m8929dy18Vzrm39ePN+/Hmu9M7cNrg3UbLv+5IKqQ4vY7v9+etr+Dt7d7W3R84p3/7Pv5tG+f3+c0+OOfe2k9w2jc///6HoxFZlv3QG/peEfcvhBDiHwL/EKDdbvPoR67SXVzltZuvIGzJwnKTxTMpSZISSkl/UDLsHbG62sFaT6udYmrLbOZYXdzg4atPsvqsRAQCRETgArQzOOmI0IRAXRdYD7mzeGuZ+AmTynI8GRD2Fnio+xHWLl0mFJY4DhBCoDxgLdZaCmMQQiIFdFst0iRBIjB1TVVVfO1Pvs6VDz3MweyQfFgwHo8Jk4RGs8VoNEQJSRxFzGY5nU6D8WSE1hErK22O+0POra7xxjdv0wwrvJYIG5HnFeN8SCtt0mmt0R8MSFrLSDz9kz2k9ATJAlEY46ZH9EY9ZhW89J1vEycBVWmwHhQWrTWVzPAmIQxTjLHU9QTnK9JOgqsDbG44d36TJ37uGuKcZqnVJIhiqtKzN8oY51MCUrQXKJWz0AhI4ohxb0A2rTCFIz3TwN2Enckiuwf7THr7ZKM+Rf8m55Y2+Zmf/gWuXLnCzsEOv/Gb/yev375BIjyf0E0+pgJuVTUvRQF33oU/7xVxd4Hzb3t/7nTbW/De/1PgnwKsr6/5k942ewe7VLZECcfh4TG1WeCRhze4fPEhZtn3SBoRUdQmTRdYXuqwffCAYtpnMp3hpKCKFV3dYjVc4N7rR2wdnPC5TzxBZScIoRjYgLwsiWTMd7/6Gjp1PPvcw6y1lujlFo+jtCWuLnBTh/cO68F5j/ce6yxCgK0t/cMj5JsjxOnnRVHw2p3v8cUv/9/M7o7QQjOtDXG7TVVWqFMr0+uf0GzG5FmJ04K1ywv0j8Z88uOf5WLjMtPMsNDtgBaoVkJVTZDCg3BgcybHdwiVRiNIumfxpiZtNYgWHmFa3WBWjzC2pq7AGENZGyIlMcbgQo+vLWFgcd5SWw+6wgBgqI0HHM1GQNSVCGmYVmO8Ae0LOgnE2lDmU9rNJq0kJC8LRg9OGP7BMYPpIct//2G69SpKQRKHZHET0z/m7Pp5fu2X/hs2z20yy3LqLMdLibOOVQuP+JA/qWd8oyiobIj37+zJvlfE/RZwVQhxiTlhfxn4lXduLlhaWSTvebaP90lixbNPP42UIWmQ0js8IPAFly9eIFRNVrsPEeiIrFNR5IKgTpAiIFJLrMbLrEYJL/Vu840/e5lrV85wfrNLrUO8EQyKGcJVNJopvZ0Jt763w+XHFmjGESYvKYYjvC0R1gFQCUHpHM5ZEq1xzmGtQyqN9WCdOx1WBd6D15LU1FzqNriwfo47+336mSHtrrB8do3bt29jhMRNM3TpKKSjmI7RwlFkJaIJq2eWQDSZ5TlKGuIgwPmAB3u7mNkBzcSRF4ooXiZ2hiD0TE/uMbaWgLmr5QVUxuKdx1mHihSg8F4gtUcp0B6kAFMptEioXT2f9QgwpqQhBS0Vs7gf0tmPeOjsM0yXC05aUyYiRwrovX7A/rd26b1wwFOLjyLPr9CLNZUQOBR57fBIPvMTn+Ynn32CbqfLrMjJipJ0cZG/87O/yE9eepxw+z5fu/4i33IzvBJoLPpdpmDvCXG990YI8Y+A/w9QwP/uvb/xTu2FEFxdf57Wmub6vdfRMudcukKdNlmJMh578hLfe3nG5aeexriYbqvB9oNDWuU51lsNkmYDax22MviWZ2hLOucXSBYatM+epbmyjPMVQdGkEXbovXHA/UnB+UfarF1q0UzazIQhNxWuKjDOYKxFaYVzAmccWivwYK3FeY+p6rd8M+89SmnwnrouWW82WXQVo4O7rDYWkNZwphtyaSllU18k31xmVtTUQnFrb4/jfEprKYVIIYTEeUiaHY6nFctNTaJX2H6wg5aGbiei023S6w1pJBJsjtEp3dVNpLQc7O3gBg5TWnQEYSCoaqgqQxiBjnO0b5HEAbaqUaXHeUuzI3FRk5NyjJCCovTk93PSN1LMazlbgxHhlSmdRLF5+RzlWoeT4wO+9L/8Pt+++QpLy6v8zN/9KN2HF7mzfszJkcaV4IMWnYbjU88+xepyB+8UhQwJIsFGEHJ+6SzhM88wmw146Td+g+a3X2A8HaECCfU7c+w983G9918CvvSXbEt+cMDqox/i6bVH6CQlh0dHvPDHf8Av/92fpZM+AvUuS81zGBGhEdzffgOrY3TaYHm5g9Qhq4trRGlCRzV44jHBret3eem7N2j/1I+xnDQIRczLX/02w8mIz33+M0SxZ+vBfeJml1BOKYRHaUcoAwrjKOsS6SVBGKCVINKa8bBHu90hTCKstVTCI7SirCq88GhgNW0xGOwx0RXXFhtcWF8hCRUrUcFDlxbITZOt3QM63SUun1vgX7/wEmkasra+AIVgmmX4aouWqFnorOPlMtX9+1x76DKjyQ5eZjSamkgpqmpKe2GVhaU1qmJAmoQIIQi1xHqPMf6tSW9VV3jviBqCRiNkanJWlloMZwZwFHmJdx4dCZxN2P3GNk+pTU5mfUwxZTIZgW0xfW0H+0pNUdSshYucSVoIai5srlCGD9juHaHqVYzJ8cWApXZCHGiMlfiixM+maCW4+8ZdlldXiJspd7a2OX/2IqPBiN7oHlaUnOy8M3P/k03O/jxGWcbxzl308gXsoMfuzVdph5Kd7TfoxI5W4pGV5uz6JpEzdJtdfNgkEI6HL1zj9TvXmdzKOHNtgeZyg26k+emPPcv/9c9/D1XDz3/+U5Szkv7uAT/9s59jOp3x3W/e5uIjq0ibo2yJUgkeizEW4QxaeCItibRCCIHW4KVDKY/0hjBQaOHxUmC9QUlBqJscTgoG2pLHipkwnG01MeWU8fiYuo6xVpGPhtR5jg08VT2jZRRpQ+NyuHVQc24xQGYnREnO2c2nSVOFsTO08pS5IQxS4qhFZzGmkhnDyTFxsEgULQO7OO/wCJwDhKPTaVDWlsprysojQkG3HRNJyOoErUO8yAljhVKCwXhKuTeF5SFhqElWukBB5dv4PKeqCvLc0G2v8vi5JxjXI165v8NR8x439ra4bBvYPMDOTmh01hF1zvjrr9C6epFmEGMDyfrGGQ6PTrj5jReYZDM8NUnSIBg1Odod4v070/N9QVwhBFc//AkOi4D9G9/g+UDQtZo8bXPz9gl3tk4QxtAfCp55ap84mKHlmOZyiDQ148ku496A73zpAbO7l3niQ4/xnZsvcv3V64Q+YPfmLi91bjA8HvLGvV3y3/kyKpF8/LlnWD+zgPcZh3qXqNlm+dxFfF6i8Hjv8NYiBQRBQFkbZvaAtYUllJLUdY0WEpwj8RIhehT1jKPqBKs9QmlGtuDwYJuAimo2RUjJNPOIQKGLiknbkS6klEODq3OE8GyutgnDgNIsIFTN/vY9lPTsbL9OI4Eo7tLrH5DGks3uQwwPD8nLY6Ta48Kly3BzHnhqNiJsbYhlgA7AeglSIzyEiaYY5fRKw3Q6pb3SIo4lwjpCLRgc99l74y47M83ywlWsKalLgxAxVWXI85rJpKC7uogIAqrdW3zlD36L+pmIUVzhFh3ldEI9G5IG61TWEnXaVHFMkKSAoNmGP/zqH/HCCy/w+LNPcnB0TF5UTGcVZekJgnfmzPuGuB//sY/ylddOkKMei3u3Od+vcM5ilrosdzeIqozkwYBgXGNFySPZgMn0Pvc6gpe2PV11kQf3t7DGsrPb52Qy4mtfvU5elVzY3OTOGz3SQHH7wS0aaxH/7X/9X9CJFxGVw9oE7w5pLyyyvvkQuBovLd7MfVrrawSauHQ0j4aEnS6thQ7WK5z3gCXxDr19gBc1dQC6BmEcs3rGzsTQaDQ42htQlAUstWi1FklHJcVSQme1yXQnJ5AJSkgWU9AKJnFAmQvSuEkUjIiCJlpP8OS0mimzUUHvYAelaiIR8NRTzzGu5vFXFQhU6KjLGqUVH/7QZWItMAhazYTDvT6Hgym+IxFakjRi6mmJMTW1dURhk8ms5HB4TDaFSTEh1QUXz0I2njKZTCjrkrT7MO3FlIXxAhsNz1dHJ/iwgXOSWf+Q/u5d7qiSZ598kvZjj6K8nUc6ioLh6ISqnrG43GY0PqGuM46PDzk8OkAr9a6ced8Qd7ndpRmNqMKAUaeJOz5gIysJ7vbolhVrjQRZTHBVRZa26fhl9r4748X6LmUYs/T4FRbWz7Jy/jKDQR/j4bEnn+be1gNevXGTdqfFxz/xHP/T//zrPPXYQxS2orSOrB6DEWS1IxYghERIDUKhtMQKqKmxXiJ8SSPQBDogSDpoJNZbPAIlFEIFLDbbXGwtI/MaKQW+sJRkHB72eebZp2i1WiSdlO39Prcf3CRpdnj+8gVePXnA2fYa/QkEaZfJZEhRjxDCUuKpiyPSVGONR0qLBJpNxXFvzJlzF3j00atktSAv/TySLx0ygsAomu0mZ9fadLsNitKhVMD91w/o5xmt5SZRpDBWUJUwmRYY69F1TZVXvL6zTbPe4v5oyMqFBfIA9GCGNyBUSJGNmQzuI0zGwsUVhABXjsB7bDZGlTPOLy2grKWqKxpRSCigri1ZOeOpDz3N2tk17t7bYjaZUZcZVZ2jVMJ8Xv/D8b4grvee46M9vDcIZXnpYJe1bMKdacZzocYfb5MkjxDLNvk4ozctmU2GXM8z+tLSXu8gdcTKxUfYfPQJ4sNdJrdeIW2lrCy1EfoqJ5MZK2fXuXLtSUpVUThH6WtyICsrKjzOOWprEN6DczgKfOkoqimVd+A8o/EAdZhSGcFCQ6FDRa1TaiK8h7X2Ej/75I8RWI8MQ168fotkXTMYj/joh54hUSFSCCKTUlwoqQU0bMRqp00nCBgpx+raQyj7BvV4m3w6ZnGjheYctekRRR2sq3E2QOsWRT0gTSUH/W2O+jPa7Q10IGh1YoSw6EASUXPn+gOmWcVwkNPtJry+c4RoQVbkSBswHGRMJyVhrLEW7LSgLgqGIuChjYscFRmrD1/kZPUys5uvQC+jHgyY+YpQhBxNj5i0WkhSgtEEXxrIhjS0ZzbpcePlF/jxT/1nqDjBYBFSsrFxnvFkynRSEscJAOPxGIHAOYd6F0HC+4K4ACdHe5gioBU4FtZX2ZtMqGvHBpK6suzuH7BY1YxtwdHKGkqFjNdbNIOCZqNJbQ23bt/m+s1XuXL5EtcefZK7W7fIqwmLK4uIB0NGVcm371xntbOIShX92YzF1grNpqbTmGK9p/YOTM3N66+ST6aETjDu76KFZ1JLCCKKcc72yV3CbMzKmSU6585RhREehzOWdtIgcB4rBGVmeHjzEqDRKkYKjxAapODiuTWWl5Y4Ou7x8MWzLDRbbNkee/du0m61yOsCmx1RlDGljZn0D2gvrDKd9JDxAml8TBTlZJMDArmKlDO2H7xMHGmWOyG1zIja84WKG3cOsb6CQHGyO8O3DS2tkUahGxqTF3Q7CoQg0oKgEyNTTTaomJY5Km7RPreJTzdY+YVLVKVh+OCIYHdI1Dtg2kgZtS1iViMaApVEEEHYCtg5eoDXIbPJEKUUFkdWzN2S8XjMZDJmMp4wm80oywprPbzL4gO8X4jrPdPJkNn+kJaoOH9uHSUFveMxu3uHQI1WAVvdNuM4Zu0nPsVLr3yNw3IbvQBBu8Wwd8Lvf/HfcPbSZT79mU+zutJm7cxTtDuf4tW72+z89h8zOCpp6xXCYJnBtIc2DWSdcpQNyJ0hxWOsw1vBvfsnXH/pBkhFGnmUrTHWMqprli8VlJVicH8bbR0y0jz8zKOcPfXL5poFiTE13XbK6lKTXj8kzyxpOwQ0RV6yvrFCkgQMJwHXHjqPOI0Fa5vhadJsnGV7b5fuksUDZWkoioLJ2NNtgBAOjyZpnifrexrxRVwroyrvki47vJJIbcmygnQtJFCa1nLE9NjgwwjlJFFDY6WjrgVRLHHe0Iwduq0JG4rx0YxtM8OkCavXrrKxfIX2esobRzu4oCLrH3F37zbTn9kgDDz5UZ920iBKY3To6Z+MkUBR3uK4t0tlSmZFzs7OFpPpBCkk2zvbFGXJyUmPuq4RCIT4USAuEEh4aKVBoNp44YmjBM8237j5OqkQNFpNyqKPtZKVF7/CZNrHR5ZENYjjhOWlM1y6dpXdB/f51qtf4+Mf+wiX1x9iWjpWzm/ymc9+lDgOGE8qJqaH8BIlE45NwdbxPv29fa5eXcIh8dLz/I8/z5MfegJjLHlR4Jwlz3IODg6I4hQdJJjLZzHeEUYRZ9bOMH71Jeq6xOQ5mYCDgyE6ChkWM4JGxAsvvsSj1y6ipOJw2Ke10sTWkt3jExaXmzQWzuI8WBEQaUUzbpCkZ5gMQcqMstSYQUatErSK6fUGtBcu4xwM+vcRcQMRRQjp6Cw7vAyoXEnSDlFrGqkFQsPicoqvLVEscNYjvQehiKIQ7w22DNkfjbFFSfNsRPzkMtXegJk+5FhL7h4eMKsy1h7a4PaWZxfPSiKRYsz5RzdZaHeIJwHl1JIGMUEomJRD7tx7hQ89+0nyfMLdrdvce+Mezz71IVxlODw45Pj4CK0kYRDQSDS5eWe+vD+IKyCKQsI4QiLwQiCVYvPCWaYffpLRSZ+yKpGRptVs0Wo3WN84g3eWvJyiqoi1h8/xhV/6JX7/t/41TismtcJELZY7bQbTKc9+ZA2lJM5keAH39g+YFHtMZkO2H9wmmdRcvvL4fO3eQ5QmxI0U7x3Onlo8a2muLJLEMXEcAXMdg1QKIWB0wzEzjtFgAN6wtbNPGMccvtqnMhaj4frBDvm0oj+ZMrhVoBDEzZibh9ustzcAT17OeP3WEVEQc+HyE1RlwWw8oNtJOTjaw0nD0YMJg5MpwdWcWO8SiJxsWqHNIkEg0A2FxZIqhZSOQHl0oLC+RnqojAMEulRg5hoKLQ1SQeU1YurotFqE6wq9FkMpuXXzdc48UZBEAmMKBm6XjD7p1QYLa21G4wkzc8zJ0V2uJB8hNxVB4pGBJwoDXr75p+R1zsee/xz5zFLkJZcvXebF73yX3vF9Lp5rE0URykjCMODGvd47Uub9QVwESs39qyROQCrCKERrTevDDSbZjOlkSlXVJGmTNGkQBAqhNTjIiykSeP7Dz6JnPWYypSFj8smQyAqyXg+0oz8akcYhy6uriFCTqoj9/ZJWuMjKRoxzULu5eNB5i5YKh8Or+ZeshKKRpgRhgNQagcB7i/Xg3Vz0qNMmLG9QFDmrTywhlKaoKhbjhCgIqOoZRZaxHICzIXEYEChQVrLYXeZk94BRv890nLOwtExtJpja0Govo7CsOsl0MgLj8bVktD8gDNaoWGI6PKG1WOMjh5kWCCnwOJAO6y0ynqviamsgEBQlCOfBO7SWWOGxucVUNY2VRTZ+6nFmeYZYbrC+vMJs3Ofeva35j8BrrHcMj05weJyB5aVzVHmFMBIshK2IYf8QOREgJWM74pFLntV2i7XlNuNJSiOBz/7kp/nKl3+bpgYrLDpuEkUp8L4nrqe2DqXUXBgiHM55pFQkcYLSAZ1Wh7qu8AiCIEJrjReCuq5BNHFVRWA8CyvneeN7r7G0cobDsubQbIMKCYOQ4f4eY+kY7mwzrg0IWFQBst1CFzX5aEx/exshLOIt4ak7/ZdgBcYYaqVAKjzgvJurxwBTVXTCmLNP/zhFWaGVwCMoq5ooDAkDjTEVs6Ki9pZUJ2g5V2NVBqQE/AFZWVG6giANcWjKKiPvD0giTRCntOMUPOReMZhOqfZ7NFtNSmNRlUXpkKpaQSLxDpxwhFpTl2DsvDsi8NjaIgKJkhJbzclVVxZJk3picYUgtBHlgwyXgKZBK07nq3I1qMCx9uxFAhmh2yHeVxhd0ZALhNMGi51lUhXgqhqQSCkppjXfeOFrFPmYdivmK1/9PZxRJI0urUaKFQ5rPEEQv6PuGd6j1J3/WGxsbPh/9N/9939OhO3fos73pdtzIfJbn8wVhThnqcqMmpBOdwEp5i0bSUgzDpFSkJc1ZVnQbjbQpyqvWZ6TZRnWObwx2HJMqC2hVkghUPL7ssX5ESXWWaQUGGM57s8YjKbEcUAzTRFhgwrN3D7/QFd+oFff79cPthF4tICtrXt454ijCClBy7lkSykJQhJpTRgEpy6KojIGKSWmrvBA0mqQ1ROsM3OhtxcoGRJHCZUtEAKkU4RhRGdhiaquiOOUxc4iSkgGgz5FUZM22nOluJ8r36x3c42yFCghkNIjBBSVIy8NAk9V5ZRlhXAVxBlx0kVJRVWPsT7HuApvIwIVgnAIJfC2REqNEjFxuITzMCsO+Cf/6z9jb2/v/SUkfzuEEPP1bKXmJBXzGzQfft2pIF7O9a+40ywBiXMegaQqZlgkuVxAL29ydnWB6SxnbbnJxbUuDoF1nqoqaUSaNEnQSjPJMrJsShSF3Hv9Jvu3/5iEQ1pJgzAMkMLgnAWrmE1qev2CldWEMHCMyhm1LBFhhjOWehQTLT1C36aU/HBSgsB69xaxJXMX481GynoWleeLv/XvcNaysrxEIC3NJKYZhaAChI7opgndRoMkTljsLlNUBudh2Dsk94bNJx7jzsn3UMoQRhprHI2oSVA3OBn2CAPBRbdO3ghone3w4Sc+zuaFKyymCygh+NY3/4yj4xGXrj5JEIRYa5lLIiEKFGEgcM6A90RKUVpPb1zgTc1k0ud4OOF451VmnSNWNi6y0FnloPcy0/KAqq4p85B20qLd6ZDGIccnO4RJi3a8wVLzWfZGL+FHkx+ehnKK9wVx5/ZMILxAaoWzAufeSqqZPzuBkwIp5+k13s0twZsib+ccItDoQHI8ybn72itcLwb8yi//PUb9A8ajMZeuPIpHUJQlWhviMKCRLIJ3WOfoH41ouil1u0CHChVItFYI4ZhUnpkriawjQOJlwJmliG4rpTeYcefumPUuKO/R/gevHTH3371w8z4ydyH83Ds8teVvjizzvXQYzpdelachDE8vxtybOSrhwBmGkzHGOhY7SzSiiMFkzKzIqJRGSMAV1KVhOoYgiSjNkCo7xtWSeKHFxUaEW25xlB0yGvfp9wYcHxxT1TMmswmBljTigCCQ4AWBDlBSIbCU1jHLHYGUhHGAqyoWW5ooiKi7IUuLXfL+XYzqkkrPYHiPLC+wPqUqC8ajnLWlc0gb0r83ph5o0jRBpCX3x7/LZLk/Fwq/C94XxIW5INsBzjqwIKU8tbTzS7TeIixI5jesrOeE9adiGBWErJ/bROmAo8EIq2P+8Lf/HVEUUPYf8MnP/yK3dw5xeB7fXKfXm1BXBe1GzGKnibWWpJUQ2BAdBwSBxvqAvPIY76mFxOia3KZMCoO2NT6bUhtPZR1xI0IHGlGDmCeGfT8fSwqU91CXXLu8waSo2T4eY92p6yPA4ZFi7uMIKSjrkqZIWO22aPqS3anFuLkRql1NXjsEgp3jI5qNFr3+MVlRErYihHMUowKhJFESUZiaOEhQIaRhxGOXHqPrmzz/ief5k+vf5Kt/+q9I0jam9kjpSMUSTzz0UbQSKAmBFAR6nkERaE3tHIGSKAzDScZoUqCDgNpIAgShmhuS9eYKT124xu/e+Cqv796nzsdMS1hoNjjambHhDOIkpylC3GjG2N6D2KCWLPZdlnvhfUVci/RgaoeS8i0rCiDmTMBYB/Z0oiTUW66EtfOEu9Eso3aSKIxYWdvgmeee5V/+s/+NX/nVX+XqQxfJiprxrETgmRQ5ofRkeQYYsjzHBG3Kzhn2Zx5Xw6xWlJWhdhbnYTJtk1ZNvHdoCQKHd466zqnVmKYNETiUONULnNpRj0NhmQ56PHbhWRrdDv/qyy+QFe70h+dPEwVPbbSQRGHAwxcvMBsPmNWSyM4nWO1I4zwcjCcMi5LGeEQoFY1A040idBhiKourBVpFCBTC1PiyohE3acuQ1WbC2Wcfow5qLqkm38lm7J6cEOgAoSSyGYKY++NVbRFaMJ0MqGqDUmru6gSaaWGQSPKsoNEQ5MZjVcBoOsN5x2v3r3NveJ17kykoiwpi8t0Za1lEK8xpNhxnFhocDCbcvr9DO4rppDFV01B0JP9BZubb8NcirhBiC5gAFjDe++eEEIvAPwcuAlvAL3nvB3/RsbzzOBzOOnSk3iJtkReUlaHdTufugDRznaaX81yv+XVgHZwMpmSzGVBxri1x+QAhAp5+8iniKGGSl0zynPEsY5IXnF1IGReGw9GEk8mMAcscTUPycUZVlvNsB+vxQoDweNGkyAUehfMgnJwTt1CYieXcGihq3OkkRqj5NToHgZQ0Yo30kEhFAChh3vLh1dxZAhQ6UFw9d44qn2KNIdQBoVYkYYjWAQ4Iw5BJXhAFmlRJ8IYkbNKIA4RSaJ1gM8HJGwM2Ni6wsNaiYkr/ZMLgqM/w8D62yhhOC0QsSIKA4WFGXVliN50nhxYFWWmIA0UahVSzjOEso93ukE8yVBCRBJ7FTszx8QGt9hJ7/SmVqfHOc3I0RkwzZnI+mugy4qJeJB2XLJxvorVna+sI0e6yvNSmnYQkSQqBJDyVPr4T/iYs7me89ydve//rwOw+ri8AACAASURBVFe89//4tILNrwP/w194FO+RSqB1yFtJ494Th4Jup0VROXQASaCxXjCcVcjTma47Tacpipw48JxZ6PLo5ioriePe1j794YjeKOdkXNIKNeO8xFiIwpDVpQV6gxHDRsqtrX32ZjXeB+A86jRsIcXcC1dKzhckkEgh537YmwsQOjr102ukrTmzvMSzj19jf3+f2/d3WFxcolTz6EUsJI+cW2Wc5UQKauu4vb2LRCBlwub6KrGGwWhCJwmRUpIEiiRQBEoyLA1CSorasN8bsnp+jaVmkzQKKYwhlpKismS9inFvRp29QX7SYfOhdcpKctCrsC9uk3SX2S8tu/0pcRjOdbB5zUrLz7M7qhqhFM478qqgNAYVBBT5jGw0ZPPSeVZXO0jh2Ty/QlVB/3u3KIoC5zyXHj5Pr54wuHtIo5uwXEYUJyN0JNndPqLbaJCmMd1uik8XORyMGMox0eoFmo3VdykE8N64Cl8APn36+v8A/oi/iLinuVycqoLerE9gTI0zE84sh3SaMZ1uk1B5jk+GTLMKYwSchqy8d3RaHdqNkE48z15dv3SNc+c3uPvGHZ587qM8vnmGsixZqSuG4xmBVpi6ZjSdMs0y6tpQZQYh6tMIxny9XHo3nys4QZJEzIoax9yaWjO/bi81znuEraGuiISjnE25+2CfN+7ugHFsnllgurOF7Tb5mU88wf29AcqW9IYT7t7bAgQ6abLQiDg8PqGdRICgdp70NAyVGce0tiDniyFFURIEEesLC4zyAuMccZxw8exFru/fIAjmP7KdvT1cPuTS+U3GfcuDcczf+wf/FXr7NY63t4mVJl4MMKWgETdOvweHLXOkdExnGVv3t+j1TugdHnJ4uM+v/tqvsbzUZpIXnByfMB4OKbMpWjbx3jMbT1npLFD3B1RHE2Qg0Dg2Vs6QZaO5Si4SeJuzu9fnxr1tuushlzopwqq3BQ7/Q/x1ieuB3xNz5+yfnKacn/He759+fgCc+WE7vr2uQqfToSxLwnA+KXvTTfBAIDTj40M2zl+gyDN2jg85GY6IowbZLCNK23PCIJBC0B9OUA1DN5ZI1SVttPjd3/l/ub+9x2OPXmN9Y41ZljGZjHAOHnv2eYytSaJwnvHgHRpQUpyG3cSpvzd3EQKpMK5E2gLhADnPPfNi7pf7yuDrmrt3d3n91jbGWqaTnCsbZ3kom3H7X34J8ZkxH/r7n0f4ijgU4C2hFBgzHz32T4ZEp7HkrLa02108jqKyTAwU9XwYL4qKKIrwMmA+z1OESrPYXeD5534BMzF860+/ycbGBiMFYRTRarVQYQVBRT4zLLuKK2oRY0Ke+NjjqDjhwYNjBoMebN2hLAuy8YBhr0ezmfLg7us02x06i0scHPcYffM77B8d8mBri8O9PYIo5rmPfhbnHWMrye/3KSY5C+0mkXS0F5oEEjrNNs12zCzLuP7GPg/u79FIPB0nCI5G+Ip3c3H/2sT9Ce/9rhBiFfiyEOLm2z/03nvx1ozjB/H2ugobG2e9Uuo0BPYmaR1UQ6xMqB5ss9sfcqc0NENDkrZIgpQJU15+6VUefuRJlDaEFBCEhFFMEEYMxlNW1s/yhV9o881vv8YX/81NqrLgsUcvsb29w503dvjc3/l5PvvzP0dR11hjcKbCybklljoE4VFqHsO8em6VQAkOx1OUlCghsG6+RPpm+M7aucJ/MJgwnUw5Pj4GIoSE5cub9C9usnHtAmGSstRt48uMyXR6OjFzb/nslXXI2mK8YJZPcIFmpZGQe0NRVuRFQV0bWmkMSnM4K95alADmUREpSNOEn/rU83znxZeY9EdEgcCZgp37r/H1P/4zHkkOSYXl1ZuvUhUTPvaTnyZSknFZMxiOeOnllzk52CUKBB/92MfxQmGc52TQ42tf/ypJFNLrHbG7t0MQRjx87UnG02PquoTRMfQcrThioRHTbYYIAWWZ0Wq1sFhQIUfDEY1uh4cvLbGx0sI5w/Bk8q7E+2sR13u/e/p8JIT4t8xrhh0KIda99/tCiHXg6C9zLONACX/qMlgkBef0LQ7qi7CyTKkUl9ZbSOc5OTrhhde+w4PtA85ffAQhNeV0i+HxK6xd+0WaScRkOmGaGZrLG6yoI8bDIVJAWdW8/MrrmNrgnePLv/PvWVnq8Ojjj8ObeWZ+vjyphZ1PAOsaKSXbt17h2sNXiClJo4S8KN+KcWZ5Oe9HVZCNhkyHY2Z5ThAoFjpt+oN97nUDml/4JFWrwas3r7OyuoK3jsksYziegocwhiQKKEpHYT2xVmghWWykXF7u0i8MbxwcU9c1SZJwcXWZdhKTRCHOOaQOqCtLkVU88cgFNpoB1x67ypd//w8ZDqZMphn19ITewYDu6JiD3n3K3dcRQnPn3hbPTI6QGG6++honvQNMMcOVOVaFfP0rv0Mcx7xxs8dgPKKuDY00odlIibTk0YcvsrIQEleHWCRrqSQfGaJmC1MVIDRFWXLvwQHtzhQhBY8+foX//AufRBjH/v42SSNFIhhNa96TqIIQogFI7/3k9PXngP8R+C3g14B/fPr8xb/U8aSn1dBMh3sc7Nyn3Yop4gOmZYJrLRBHAeP+CVsP9rh+/SY6SLh05RE+/enPcH9rG5xEVge4kz+iN1DUxhKlXSIhufn6PY5PeigVYGpDoxlTlSXeG6SAV15+kc3Ll05rGswr1uA8QV2w2G7gvGc8HqK1J+vv8/HHLlBUlv3eiL3eDOvkXCQEXDm/yo3RgKooMVWFFILhcMCgP2PjE5uEap7jVVpDVTuEVHTaKavNkMk4RwKBlhSVQAmJVvNownq3w1J3iRuv3aUoDUEQ8ui5szx/6QL9rEQpiXEeF0Q4ZzDlkCefuMzsoQ2sMnTbTfYOjvjWazc53woIPMiyz+7ggNuvb9HttvBxTBo6qlQx7ve5uLzC0098Cm9KnKuRSiOkojRmPiGVAlMZijwnz3OiMCAQEi1ChHAUo5oIia8qXtvdYaNcpN/rk5UlKxe7dLsxYWAx0z7WGaJQMDo5YXFxgWa7wXsVVTgD/NtTfYEGftN7/7tCiG8B/0II8Q+A+8Av/WUOppVkeSEh0U3KrIESMLAbHB4PccdjxpMpw9GYLK8xRpI0WiTpEvce7GPrGh1ooihmZ+s6+awkKw1VJVlf65KNasbjCUrq04UBS11NCQJLHMDxwQN2t24iSdEEWFMjcBzsbrH22Dmc8/zsZ57Du5KqKnn1xitc3LzAxaWA4TRkMhqCmotuvvu9O7z84s3TxYXTWLQWfOnLX2U8m/Jzn/8MszKnN+yz2Flgpdtg1DthNhxxdDTm/MI5jPU4L9BKEQYBZxc7LLXntSOsB6UVj1/c5OL6GrnziNNzC6XJywqNpWmHxLVgtRPTbqf83Oc+wp07W6SNBBuFPP/kKtcuwXbc5fXrms9+8jlefH2LlUYXJWF9fY3VToLzFQiHF5LaOqS1KBw4hxKKINI0wg623cJ4g7MOW2dYoziztMqoHuLR6KbAqBlL6ymPLK5y9vIGgZSMTo5ZP3seWztUEOEbltl0hlLRu4ps/srE9d7fBZ7+Idt7wGf/I4/GZJpxbyuj2xLc3+5xcHREXVuMcSwvrVCUDusDVBiTtDokjQVK47h374AzSw0agcH7CYF0DEtHkVv29wb0elO67Yg4nIeIwDMe5QTKIHG00oRzZ1uYaoBzMXVVEsUhzlmsiLl1d49EVVy5vEaRTShrj/GWveMDvNLUuktjoUNx6ipMplNKLymrDO3neouqsJwMJvzmv/gdvvfKTVZXuywtd1lbW0SpmC9//RVGo4xEh2w84imMwwsIA835lWXWFxcQUpHXNQ9fOEcFPHLu/NziKY1zNUppjHGUpiYJNOutJkkSEugIheLDT17hoasb/OSP/xhVlZMPZ/zcJ59mMJnx6o0bXNm8wJ0HByAkKtAsdVtEgWMyniBOJ54wXyRx3n2/yqIHKeZ1J5z384pC1mOjBs00ZSgHZD7nwpkW59eXUUrOS0DpmCSNyQcnZLais7BKUOY04ibDXo/RNHv/axVA0O10UFhuvHaDwaRmMDasLJ6hu7BMnMYM+lNkYPBScXwyZJQNMc5zZnkBcNS1osgDiuKENFV4F4IH5R2joaHbSfDWcNyfkISOrHRE2tNspSSpQuuaalaCcBhjEEKweHYT6im+6nM8yGg2GjSbLWy0Qu0Mk8rgdYQIFKKoUFJyMMjxKqCRLmDLjKquCIGVxTaNRkwnFIhyxuSkxBYz4iilE4dkkwrpBQJBGoXkJax2OpxdWqCRpHPrqwMeSlM6cYQKY8I4BR1QVhXGOSbHx8RhiNaKJJ7Hw503YASpTnj2iUcwteWZa1f58h99E+ssnWaT5YUF7j44YCGNkLbEGYe1hto7rHR/TrU3j7x45gX1nPPzRZq3ylGB9wKtE6azgk4kaOqAZjuh2W4hpcRqQSAl1s61nJPRkG5nmdlsRDaZoFVAdCrUfye8T4jLPCQUJ6StM+i+Y21jiSgMKA3094cUeUEcRwRa0G030GHAQqdJq5nO08Ctp8hqoijFuZq4C3KzSWUFRSFohAnnzqScTDrUtubWrWNMXtLuJnRabUwZobVESIdSc5+1cjU6aCCDmL2hIi0tacsxmsytipEh3oEWGq3n5eaipEWYWJQQ6DhGVjVaOdY3FlnqzjMnVBggAo2rPePSMKtqSucwp+G3M4stxrOCxU4bGcYEaYsoDIijkEiHmDDHIuh0ungBo/GUUZaxur6G0CHee0zlsNYipUWpeaRmpb1AVhrWOm1mhWE0KUkiz5XLmwRa8uzVTTrNJse9Yl77ADevbyD82+oQz0X2c2XeqcbktLCe8x5jDCBJm47RJIMsJ4o8lUmoqWi1OlgRMhkNCJREBJo0iimnGXEYMxz0CMKQspDvaTjsbwiebHhMBmhR/v/UvWesbOt53/d7yyrTZ3bf++zT++2VzSRFUaYp07RkSYkTJ4itAPngwEaUBEj8IQgC5EOQgiAw4iCB7ciOFERK5KgwIlWoUJYokZfk7f3e03fv01d9Sz6suedelnvFWBJw9QIz58yambXXrHlmvc/7PP/C6dUGwlfTkpQST7161exXLWUVWFIKlCxQSiBkjYWl6wQBKAXewdKyI4g0ZeFxtqrFttMC5xzrpwqKwtDp1Gk2I4KghSaiFqqqZy8k1jvAgwMlJXGk0VpQb2rysmpRS+mqdnU9oh5IHrh2mbwoZjiv6kokBcRRQKBmmFpZUZO8g8hYouYCZ0uHFII4jrn8wONY6wl1SBAElGEIOqDAVwLU7RjvPWNR5bY02ywuLlFvt8myjNFkyHfuVuUkKSTWTRBeMJVdCm149t6EhdOXee72CUGgaCyfYzKZkjXbPHtnxCAp0XETcNh3RLPfc/+O+LarHlQdP+9x3ldgIiGQOkDpRQrdxgaQaoXJNMNCIbWmzFtIAdbXGSagRmUFaDddfFrl+B+EFP9QBK73nq9/43fJyxRbuPttVG8rbr0OIpZC+OKjXZ7fS3l+K8GWvsLbaFhYXOBjTz7FmfOXCHSEKTLKskDpGK00jXqIyE5wQYMkE2xt3eHg5Jh8lOOiEFdvoJVgc2fEvaMBaIWSGillJRAiPN56RJFj8wG4kievnmG5E6OVR2I5HqVYt8BJ7QojrRHazVgSGikETnikCqr9CnAywHuFlDNwo3cEGFbFbfaGBmtc1cGTCqUDlJQgQClFmlZg7XOXryKE4OT4GBgxv+BRwmMmfb7z/ItIEdJb6VJEglAJgtCSjjO+9uIxpy61OdhsUo4KwqDFeDzkzoZDxDG9UxdxhalE7rxDyop1K1B4wQwAVV1x70PgvPiu73N+foHd/RPSNEVKWS2KAa0VWWHZ2a9EW4QzNEJHt1bNZP1Jjp91Kj+I5PChCdyXXnkV40qCWQtXzFBVTa35ifMNfuZKwBNX9jk97zk+zHhpI2NnmKNqEanJ+NHo45xfiJE6xgfLTJMEqSNAcrJ/l4M3n+Xpjz7F7b19kv2XiVtt2s0utXoNIR3SWE7GCbf2+ohQI2WAVhqlFWCxThBnGZ+53OXwZIuJOcZPck7VG9RrLV7b36W12GLPddnzbZRXCFep4kgEQkLoHcgYofRMbMZjqaRMvTOEIucad9g/GuDdDJiiA3RQAeyNsUgtGQ6GxM0mRgZMJwn9cUIQhizGbcpsQppNeePmG1xc6lJfSCi0IJFTOosBt18/4a2XRiS1LuIEfuYTH8GYKTdOdhhMcgZKUdQbtEydfv+oYmVohdYBeF39yJy7392UsmopC6FmrXowxtLtdhkMh4zGkypwASkFURhycDzm9r09VCAprSeUjnOLAa1GB2M9m3tHzEXVQvr9xocicIFKFjO195kOCM+8lvzb59r87JOKhYWC/l7I6Ujy3/1cl//l11P+8Ze3sM4hvcDnGZO7xwRL65ShpigKrCx46+0b7B5us9xuYCZjYjOhtTBP2ujiTUgQaHQYEKQaoSRCq4qJISVSV9MaXmAlBDVYiCXXLqzQWG1ibUZ+mDKdFkz3M1pdAzoEFyKUQMrqCqmkRDlHeft5Fi5eZRqvsSgmzE13uBmeZ+IlDot4B+0GWFsFhy0KVD2i267TbdbYOJxgTMH8wjwCR55OEMLRaNTRSmK8I88tdzZGmERw9ewaZwQUPqJM4bOPPclDvZ1Kmbwe0IxjnNCgQ7aOBmxNMubXDU6Atb6i6UhJqDVCKErrMPjZIswTR5JuO2IwrtR/3pNEIKQAWaVM930rpKfXa/CZU48icbx6a5ujfkYum6wvr5PKMQsu4spynWdfev594+VDE7jWGGxhIJcEUciFVsg/eKDDZ5clMnbkOuabG02KmuX8oueZl/pIXeWJ3nlcXjAox9zYe57xeEBgDa3FZVRQ44HrV1G+xBSGQIdkPqIedFhr12loSz2AoZ95PmgFWqKkQmk9K/MoAmc526vRapbo5gIXrn6OND3kxvBfErmS02fniZp1fMKM8QDWliA1SIXwkmYoWCu22Tm+x+pyC9GYp8gq7K7FE6DBgzEl1lqU9zx8vsdTD61xfHSCDGNikYFtMNfrorEoM6UeSLrNGsomaJ8ThopWL2anP+X/+OpLPHbtFI9eWuWi7bHUa/LI2hNMTvZBhaxfe4zNfs5v/KMvMZqknHnkLCqQ+HIWnFSNkFDrqulgLRTgvcV7T68l6dRTbBGTFBUf0Dkx46aBFBYlJEpIpBQU+ZSHLqzzY08/wvbuPmdPr/Nrv/dt+qnklVtjrAOhWmwM/oIwILwSCC3wBTSV4O+eWuCv9Bz5ukMKQ7DmeKo+5aWkw3/+P27w1n5ZTSRSopRkmKfc7t/CW0U2HCFMjtSaztw8QT5lsTuHimOUjFjIC7LjLaJ2g7OrS4hRwiSLWOkGKFlDBQF6dvMeXFlCIVhbWKR95hTd9hLj3CHCBRaufZzD2y9S+B0oDcYYvLc4I3BFQZTniHJIEbaQq49g9B6X1A3eunNMev48uQNfpkhfztISjykNpiw4t9Lixx5bZnG5w3Qy4ubdbVom5tOXu/QWSxYXofHINfY3dzF2ghYjEi15NQk4d3WFk5MpPizZi0YsdNo8Ul8ksBnzvVUuri2xsbPH23f2+We/8tvUl1osXpynsRBX1J/ZFfUdpF4ViBKNwIgqjem0Opxa6uLUgP2+vf86Kasr7tH2Jru7OwgKQl1JtS4tLmHGLZ577iWCOGKp1uLScoOXN04QQhIGdYSq4aOQP2887p/JkMahHIhY8sko4Atdgb9oCNYLGERkG4ovv2b5X79xi/3UYXyBEQKhNdZYjsgYxiWtfk6r0+XUqSVGwyGNSOHLEekEBv2SZDLiaPMOR8MB93TMZJLxxNL8DOg8JhzvEOgAHSlUECAIiIOA649cY2X9IpPEMJz0OdjdIm43qNWbnL7wUQ62fxuBJA4dYXGE8JKGcizvfIf04G2yaI7W+acYFyOOjrYZn/4kOm7QNCkqKCmKFOVyvLek0xE2T7j8WA8VKI6OB8RaooVjNBkSNwLOXF2kXve0FzvIdMR0PMV6QZE6kBpTag52BjzwmQ7nH24gyjFJOmUyHPLYR54kLTSv3X2FL33tq9w5OuSRT14ly3IcAnwFKvKugjwZ/56KDp5AeebjBuunT9Fst3n7TkFhxvcJoWK2EDvujzg6HiKdozO3SDku+Phjp6m35vj221v8zF//HH56zLVTXTZOEqZlRppM8UITmZi/EDmucIJYhHxqucm/EdWpny6Ir6T4niSdt8gAXvqDhBMcPnRVkAS6yiVVNd0u1hr44wGnzp6jt7CEKd4gHY04TPo0Wx3KIqNMUra2tsnyFKUUr04nPPKFz0Im2NkZ8urLWyilETpEBJLFluevffGv86lP/gR7h4e0WhJvLEWSIgNFoOvEseL0mUX2E3Ao0DFKa1Yn2zzYHJPKiNxmrERbbI37fMtHdM8/QilqOGtQSqNkhPQZPofR4Ii6drTbdb711i7SWU6fOcXZi+e5+dIrhIEEpSi9YDoaMxyNSaYZ1lpGqSVLDeN0wOLpFo1OnV7Hc3Iv5Zm3b9P0JVffepWgtYbJp5TFhKVeTCgsshmSFhasrRZdsqrhVt0wi1IV4Gd+fh7tyyqAew0ucIb+y6/d1/t6p4pg0ZQESOk5HqfUA2g26pgy5+L5M5wcHVIXKb2apiYd/cKBsxhb4lzx4S+HAQij+eKlBv/ZA4t0d0vCpRRvLHKqKE8k4pxmraM506lznJdMcQgl8d4QhIq5uMnC3Fn6PiYpJbde2KAtR1BmDEeHqBVHkiSMjsfs754Q1yKctKTFGGMlgQqpt+rML88hCAiCgGYr4PNPX+CRJ55gnBZkuSGOQlrNBjSr2rJz0D/YIB+PQNch7yNdh5gavjiuTFOiBnGtS7s3z+7tTXT3AQwCJXLA4YJWVdQvNN5DlkyZX+oQxjHtYki91SZozrF/5w5aFcx1F8nSAicNo8kB+/tHOOcpjKUQIVIJ4o4hrgfEyjCdOmo24vEHLkCW4QswyZRWI2C118S4kmXjGJc5gYgIpUILRVyLZiUsgQOKvKQeaESZcuHaFVZXV3BS8frtbaIopiICWARVI8WJACfCWQkN5rpNtJLMdzuM05Lp4Iio5gl8QU07TFniZ7Vza/+C5LhXliL+gy8uor9TEi2UCGEQOxFv7ob8k2+m/PRP1fjbn63x+Ok2//vzx3xnp4+R1crdWstie45LZ1Z5u9D8n//31xmfTPixj5wlnfTZ3T1meDwhTTPG04JWa556q83G9m1W1pvkXmFRZEnKpD8iCGrYIGSl56k3G2QuZnpygrWW0hiGwyHgK3n9bMru2y8zOejjl1cQKkAojVWWPoKd4wntVgjphKPbW7x64226H7lMqLKKhi9KfHGIsBbtyqr8FIT05rskecmTTz3C/iAnj1oUTtCox3R7XYx17G7tzqSrFKUrcEKighDnUgqXE0hBemwYovnU6lVW60u8+dYNRtMJw90d9g9z4lix0pujWaszl+fsT1JkVKIbmnotrgD6SmJMTpomnF6/wKmlOeJajY3tbUaTjOFwShhUU7sxBu+qlrlEIFEzkI4nyTLyZERrvk17ZZWT4RHbGzcwXpAUeQWGd5ZaACj9QaY7H57APRobfukrJ/x7cy3EmRwXlOwdtPiv/njCc9tTzr9S59rnQ7751gmvH04JtCaug7GyKqUZwzT17O8dMToacv50l0uXL/DmG2POX7iKEYrBZMJSt80nPvEZsvGU5Ld+nbnFHtMwwvo6URRQb0RcunSF+U6bThMac+eRQuFE5S7pnMJZQ55nWOcwecKN115HlI5owYHQ4KqaZxh3GamAweExSwsrfOOlb9HPPatzp1Be4H2I1wJrswrIYi0AvYU5rj2k8LWY3UGOQzNJCjbubfHweoso0Awzw8FRn26vSxTF2NLiZnVfoXKM8KycbRGUJdlexqkr62ilOBoM6Q8Ddo7GvHFrRFlazjx6DqxBCsG80xynMbVWawbSCciyjJ29Lc6ePUfUaHOSOrYO7hAEIUKFdBfmKmUaoCzLqoznBEWRkWUTpHBILYl0i4OjY06vnWJ1fpnl9YvcECF3771NkhYUzrEw3+DRa+fZ3Dli++T94+VDE7gnecHrRw6/0MQEEttq8PNfT/nW7pQS+PprY7745BxfeNrznT7sJwprDS73RAjGoxFlGnH12kUevLVHnmXoTptmb475dofLDz+OCSMMlk5rkWya0Og0sUVKGYcUos6lC6e4en4JZwW3b97j9IWnmT99mXpUIyuK+4goZyv9SyUljXaTMxfOMByNKLRE5wOUsahGj1zUENEZhG3w0MMP8dY4YnQ4RPROk2cAKUKEeCIcBYGqymFhWJKHAa9uDXn11pRzZ1a4dfNlbrzxNj/60CdxHo5PBmSFAamZpBnjJEUpTS2sptreiqY5lyAmhrAdUiYTmkvzLK/0qDXavPjN2xyMPbVAoYOIRqOOtY52vY0dSjrzCyzM97DeMRwOWT+9Rqfdua/7kLY6aK2JazFCCgI5Q4g5hzGWrZ1DPK5idgjPhTOrdELP3jDhMFdcml/HGsf65cd47fYtprll/dwiVz77FNONXVbPn2Pn9VffN14+NIGrpeeLF9vMnzHYkcUYz/HU4IIAJSyvDDP+p6+M+bmfafD3fjTkV79dMEwcY5Hy09frHCnN7sExYRgSxRqt2zTaPeqtLkfDMWpri4XVJcrSUKYljXqdMAxJpiMmyYjcxCyvneXC+XMEOuDKtQ12tjYZHR8g5lfvH2e9XqdIPXEcY0xlKaVlk8HJXWqNJcpwidLVsaIJjQ5l7QQRL/Jrrx2Rn/oozWgbREj5jpCeSfGy6qT5siQIJZce7tI/nPDGK7cZ9xW3VxaI7JSf/sxDrMw1OJkWGBWxdnaZIKoxPT4hN55Q+NkULYmpkY0do4njHiLW5AAAIABJREFUmp5nb3uL+V6LfZuy82bCK1sJC70GKojY2N5lpdsAQBaGNKvTsiVFPsUJTxQrptOM4egEY6rF5ObmLkLA+vpaRZ2PArz3lGU1M1lTIoSa1bQVq/M9XDZmNE1IsoKbb79JGMZsbt6jtFA6x7mlGq3BITVrmeZ/SuqOEOLngS8CB977h2bbfqB2gqjaI/8Q+AKQAD/rvX//9sd7RuYE/+LGlEcaPS4vxYRzJf/Op2rc+bLn9aEjV5Iv304YfElz7UzAA6dqHOxarl9QfOIJwf+15TnsD6H07GzvMTffY3t3h8J60CElcHi4h/KaLNsliiJWV1fZ25lyfHyICuoop+ifHFDXJXHsydIBt19/jrVz1+gsniLLcuIonLVANWVRYNIRycEJelpZeBof44ixyQRtchq2z7QQiKhBnk6xUZPJRGDrZaXSUziESxHOYfIRvuvIhmOC3HO2HXOQTljUY/7ypx5m7dQKdw5OEEJRby8iJSTjAZMkYzDN6XVCrPVoLRnt56hQVpRzKbiXjVg4lTKdhjz72gY+CBEKkIrhJCGfDul1OuSjDNmIOO4fs7t7l7nFeabTFOsK6rUG+/v7dLpzWJtijWXQP0FJQZ6N0VrTbs2TJlMyo2aViUrjzZTgrcQ7xXg85uatNzClYzgakpUp5eQENV2gvANz189zgZBn/zSBC/xz4B8Bv/Cebe+nnfBXgcuz20eB/3n27584VCR5zXv+y5tT/o7p8kgecO6K4O9/pMU/fWHEi0d9ilDy8sTw7PMj5qTgP3x6js99xLItiwoxFoRYDJ1uDSUNg6NDbJFgypLB/j5FmRPMumFSeJrtNvq4RjIx6GDKfBSy+9odzHibbjMkjs+Ryi5HR31S48FroiAmigNcnlOkI0KR0JwLCMI5ppEmzo4IfARCYqcH9A9vUXqBNyWZF7juWYr0kMDXQddAhpSmBDMh8g4hFGu9B+m2FgniBmAZHW8zES3ujuvYWhcpAt56fYu7O7vUdMLlU02ypOC13Q1arSad88t0V2rUAhhLx3N393ni9DUO8yYvvnbM3Z0pK/MNirxkvtekKB1lWXI4OGTroM+1h5tcWT5Hu9OkVqshRES/v4cQnuXFJVARtbiBs5ZWrcYkSXBeYoqMIAgwYURamvsNDA9Mi5JAh/QHY6zz3NrYZjKZMh4NOXdulTSZcjDK+MlHHuUknuMD/VB/mMD13v+hEOLc92x+P+2EnwR+wVfV6meEEN13iJN/4t+h8sF9M4z4b7eOubIf8jfjFuOypK0UV7sdDsKcOBB0U8G/udrl8ysQeY8xIULIyhwEw5WrlytZOVV1c5IkRRU1rLEID9ZVUkKBh9w4To77dDodNkcRezsZ51aWqEUWYwvK0rB5MmVZaGpxTFJMaHYXUEbQXuzSbaxxeWmBPE/5+lt7+JvPI5McpSAWAiMmZKYkdIIsm6JURruI8GUbpTRlmVUILDMm9Dlybg4ap+mLgKXeMs89822mScJHnvgoF64/ybPf/iNe+cbvc/7MVQ4mGc1Gg+luwPmrT7J2sc10tINlj0ROyTNF5iy653lr4wSnt7m7tU+RVwZ7MQKtI46P9jFlweG4ZPt4yMrZKZPJhCjSM0tVRxDWmUwSamFMklaKQYHWCOeRShLoGoqAyXhMYQ2Id931hBBkZUFqHDtH/YqpkeXc2z4gTSacWl/hI08+zWOPPcokjDk+HBAM9v9c0GHvp51wCth8z+u2Ztv+xMCVTpIXJTYtGQl4blBw52snKAG7ecFcR3Op2eJJ73lkocc172EnJyHE6HqFUxUBeE8YRkghMN5hCocOLVJq4jiozOucJitLtnYOCOImlXWoJyXAtNa4NUnZKyGdTphOb1NYyVFh6HSa7A4mLB8NSaxnNM6ZnhzRzDaJ3RC5eAUfLVQlISkRKiIK6ohin2ajQZYdMB4MKUcD5NwcxkPpZbVAkyEEHqkdly6eJq61KJ3g1KXLvPLsMxwMdhg8Dy99849YP/sYNw/ucvbCdZ786I9wPJ6wPLfCXKfH3e1bDPZ+GxkFjPcceR6glePuwSY3b98hLx1SC/LSItqVNoXEMy0ck9zhvKIwnul4zMHukLgWEwYB02RMs9EgTzKK0pAkCfV6A9GMKApDvz8kCjURI0a5odldoVGvEQYah6Db7VaecGqf0hikt0zSjCCsceHcRazQ9DpdpBOsBprprAP3fuOHEnaeXXF/8z057sB7333P833vfU8I8ZvAf+29/6PZ9v8X+Afe++9LV75HEOTJn/3Zvw2ADlSFxbQeY95BG0EQKmIhaKqqPohn5q0LxmtSFVFJmL2z/xmN5F0RU955xAz07P27apZCVCbJxlZCdO/AtN4LoH5nv2KmsFjhqR0Kh/AWHcbkXlO66oUSiXAW76tOlLO2krRXGqErlZp3z75ACqjLnDjSyJniuTGWLE0qMWovMGVBHNXJypxAKaKoVjm9S4mQktIYTJlSigxnPL5Ce+MtWOPe+VMIT8X0kBK8w8/017z3hEFIFEbVZ63uKozsDJ7oXcWElqKSYX0Hn0sFBsP5yhsjy0vyLMc6R6Neu398tTjCWUtpqu+rUa9hrUMHleuQtZXs6z/9J//4z1zY+f20E7aB0+953fps2/eN7xYEWfV7u3/A6mrMU49cQyvY2Dzhl37lTayH1VMdHntqneOJ4USEdHsdwihGyIpO7osAMbWEzRMCF6OVohnGFMqT2IKyKGn6Fl5YXGzJ3RjvFE3dorA50pWkSY29Owl7e3v/iqcELl++zKWn/yrfvpsSmD6quYRxkjgQFDSrjpIUCKWQUiFmAJYKjC2Q3hAd/x7/1scVgfKVwrj3QIwTYAqPKQKcze57ZhgzxVmHKS1ZbtgbGm6XK5w9d57S5GRJis1zTJmTFRlZMiGbjkmmOVrVaDY6bO1uc/7ahcpAJohIc8GDDz7Nxz72sR/4Ocuy5OC4z9HxMa1Gg4X5Ho16/X5gCyH4lV/5FcJonhs3bvPSqy/ysU98gk/+yCdodFuM+kPqtZgsSRFCMB2O8XlJ3IiJ6hEvfPtZTg5O/ly0w95PO+FLwN8XQvwy1aJs+MPktwCLSxHr63V6HYjjgOFIMhoPeODyHD/1Nx9G1Tts7/Z55fnbjHZ2eexHPlaZlyAwiSTJHInO0CZFS03mFbqo40ZzyMSTW19dKZTFNxTNjmZSjio9B1UjD4KZ0Fvxr3hKwDlHMdhg85u/y+X1BRbPXCZJCj76xCNkUZNX96scuyDAIWdBK2fqNRLpTfV50gxjcsSsvOVNiZMCU4CSGl8aTJFXjFwpZwYkUA8EzTjAFzNhE2c5ORhx7tQFDvbuUhYpxmSY0uAKw6OPPIAtLelkgDM5Rgm0rFb+0Uyu6d3ZWtyfrfr9IZsb29y8dZswDDh/4RwXzp1lvtel0agCWGvNSy+9zNbOHkf9Y1589mW2bt+h2+tQpBm1OMa4qh7ubCW+EoeKlfklXn3hObKi/NNphwkhfolqIbYghNgC/guqgP1B2glfoSqF3aQqh/27P+yXvr62wJWLy0StNsiQwfgAypKN2wfce+0Wp6+c45n/5+vcudPn0iOX6LbqeBViHRQOUpKZbkJJ7ktiE+GSOfxEo3yBlpWCeTZKKU4yZOypz7eRiSAQMZGu/bCH+l1Qv/dC/wC+9lu/wcnGBkkvZvvGC8RRi1MLf4m1012urZds9h2v7FompUeiK8cSIQgDibMCay2vv36XQFYqzrUwot2MCUNFXjqUdERagldY57CuwBpLljmct+RFpShpiowiz2m36/R0hCHglRv7NFZP4cIlxuKIUeYQPsUG1WIJJBKJMfCuYuYs7Zo9KEvDm2/d4Fvf+hb7+/tIIdnZ3ubF51+m0WjwyMMP8OijD+Kc4/bGTY5PBuT5hN3DTQ6OFOsrSxVlx4tK8ooqNZDK02vUObi3UYGg1J+SuuO9/1vv89T3aSfMqgl/70/a5w8axgoORx7VCJESimTEQlcw3wJ/+CaT7BaPL2VMDuHJx1dZ6NWZlpLSCnxREQ0jL/EyZGgyWlmbcmCw+YR6XNU340ARRYLcQaYExiagPPXA48sPVsD+3tFut2m32+zs7Mxko6qRZinTyYRnnvkjlhYXePDBx9GBJlCS1W7EfNPTrpe8sVcwKCTGgRMKrQVhCF5KegvzaErSNAMP09wymabkpa+ALnGAcRXp0pc5tijJirLCJdsQHyyTT1OKIseWlq2br/P88y/x4vYh5dtHpMkELT0nw5I0GbO78QaXzq1y5fpFEBLnJds7G7z40jMVdUgFKF0JruztHfM7v/NVdnd3yfOcOI7pH/fZ2txlMJzwrWee51OffpzDwx2yfEqWT3DGkCZTAh0xTabEYURpzH0vjCRJ0N5R67R4/ebbNOcX6TXr8P6Nsw9H50wIQViv0e71MARYJ2jML7C6GPLm3QznCmJVstIRXLjSYun8aaSOCKQAC0VgZmRcx5Apyjfp74yYnExxxZh2e464FlNoRVEmZGVJmXm6OiIIakxtji+DH3hs70xXgsqLzbkZ7dtZVleWmU6n9Pv9dwUzkEyTKY1miJCehYVeZQNV9UqJtePqkmKtXeOtY8fGsCJOLjYklxcj/vANQZoaAmHRMiQOQ0pfkvs6xnuMnXJ7r48O6vQ6MZEU6CikHlYq4mFZKZJP0glFkVKmJc++scs3Xt3A+ALrjxkPB5RZxtqZ89Tm1zl85TXu/P63yazgwYcuEgeCmzdf4vadb6BlxXxQOkSImI27Ew6PJgRasbi4wIWLF4njGs89+xzj0Yi337rJaLTD1asXUL7i1dV0QC+u0Qrq9KImc80Wb9y5wanT5zg+2icUnkvrp3l94zZ7wz7nFpdY7nQ+MGY+FIELEIQRWe4hCiiQdM9epbl6i9Ebd7hzrKiHHtoNPv4jn6G+dJ4cRaAhCsAECuEqeaAoDvAZjEcpJs9weclITGZ6V550mjItDctnWhgrKE1JoBX2+0yP36GuVLlro15nZWWFO3fucLC/T2N/D9PpVC7fSs30BODHPvfjKFHSaNVoNbsURcF9xynh8UKC8DRrnkdWBKdaFqegU9dIqn0YIVCBRsYxiTFkhWY0yTk6zjHphGanSa/XIZAe5yEvy0pbwluc0BjrGE4ykmnMyM0xbSxy9cGIo51N2r0GOzv3uHXrFrFNcdMJUkd4EfLmjT3CheusLyhW57voYA5bFtiyxBjIC8+rr95mOJpy+eJZnn76SdZPnybLMg73dtm6cYu1Xo21UzXimqIe1ujUWoR48nTMyBl8onn5zluMphNsGJMmI7yplHiOxlNK55kM+kTrq3zQ+NAE7sKps9RqAU5qtFSVCo2sEEdHJ4ZWS3NtbomV89cJogjnBYWvXG6EcBTOMUgSvAGZCpQOCKMaSEdaWk4mR9QbkqgmmY4Lin6T+rwnUp660xQ6vH8sfnYnncMXJaYsmVrHuDFmfn6eufl5xid9Dmds19u3b7OysgLAZDpleXGJucU5vP+e9MN/93JDSpirCYpySjIeYUpbAVQOJrTqglClxLGi3QgZCsOv/vbv8/iVs5yvrXF785Ao0FgM9SAkNUWFE5A1ivoZssbHyMoamZNM9BvMzfW4fm6d5557hovLC1y59iAPPfAgz7+xRWkMC502n/vEJ7jjzzPKDR+/cIYr164gfZWDl1bwa7/6m7z2+hvU4joPXD+P1ooojEimUxaWepxaamLLlPm5ZfCCWAeoZotsOiGIG6ysrPLszbcZJ1Ocs7y1eROBQHjYHQ2rOhqeIks5vbx4v0rxg8aHJnCdCsmRSF9xm4Z7ewx3tzizLJkU0GppptMpg/6Q1UbrPj3EeDBOIFDURRsvJEGtje0oysgQyRpv3LiHCx0lcO7p08yPLbt3jqgP5wi6EH2vhK/3tMuCx0vLPaW4VeQEWpH2BzTm5lhYXKB/csIf/NEfMxqNWFtbIwiqVMOakrBWo15vUZYGzzuK++69u7+/2IFKqj/AkmZTpID1pRYBOc6UKOGQRrC9ccDO/piNzRd5eHfM4uIytTAiLROeemCeqxeWmSY5oyLkMG2Qxqdx8wY1zZkc7/Pc17/C3/rX/gb/6X/8H9EOcv75r/9LMqs56e+QjScsLfUI4jl00cb7ETvbLzEZfwchKn0JVINpepvF+YBsMCbQgq3tDc6fv4hWiqIoOH/9QV548TXC45z5uYhWu4UPM+4cH/LRh5/k0oXz3D3Ypz8dV4rvrtKTEFQaGe8kWxbBYX/44ddVgHdaBBLvBdZ6JsfHDPsJB30PqpJGWjIZwuUYZ2fiFDPKMyCUQASCNM9gWKMma3hlQAgyk7FyfgmhClJbUOvGzJ1uU2QQFpKhKzBlfv9YlLE8ahz1KGLZGlYXFzkWgntlyc1bN/jGN7/ByckJ8/PzXLt2jTiO7793MDhkJpWBcxbnHKUpKoESpe5XIpyrivTOWfAOAQSqusKMpoZ6pMBB4Dwxno89dIZbmwf8wm8+z1kraFpHOh4zGI/42jOH/N2zH6feVriJR2QCFUYIFZDkoJo9UILf/MqX6bS6HO1v8tobN/A3Nri3dY/W2kUWH/4Cd9watbkW9dDj3TbOTivSpBT4csCFs5rx0xfYe22L+W6XVrPLnbubNFsNrlx/gHt37tLeOGBzc4t2u85h/5goK8FXMk1Hewd0ak0Ensvr5wijgM3DXYxxlEVJaQzogKUzXaxOPjBePjSB66zHOlc1FfKco81NAuVZaAsmuWeu4ajJnCxJZg7nFoREQKWq4iEUmlhLRskU6UsWWjF7WUJzrk4UQGOphbcSU0IU1RgejAlbsoIVvntBJC1Lnu2fsOAhd45NW3JjOGI0neK9p9vtcv369Vmd87tbk3v7O8RBRFl2q9Wy1njnmU6nNBqN9wSux1iL85XdlTUOYyu3Rm0zKKF0oIUiTacECP7y05fYPBhyPOpzN03Ii6wypOrWOTjOER6mREgt0RLGxwXjkeHhi2vUH73GvbubXLp+jYX1Jd7e3OT8hTPEzS6ts1/Ezi0ThCGtQBLRrxajAow11UVFSgItKKziWDZx0nHnzh0Gg9fp9dqgSqbjCWDAG7x3zEc19g6PaDRbJHmKpcB4RxxpWisxUTPkoUuXqdXrHB31ufHcLXQ7ZOFal7yRfWC8fGgC13uPtR6cpcwSrC2QgaKJp14XNCJBGGmQmtJU5nTe2YqUZx0ey6QYoYnY2TtGNRssr6yxnReEEXhXEqgIaRWZSdHGUaYlWklWz5wjPRZs3R4BENRijn2XW4MB0yytzPuaTRZXVmi1WsRxPJPX//6pbDKasDPcYW6ux3DUp91qI7yjFoc4Z77LCdNaO5Per25FmlSLQaVJS4vWmmFWcbiU90gh+YnPPcHvfP1NXn3jDmdPz6NFZTR9d3eAEpag3sbXPLbwFaHRphwdHfH5jz3FzXNnuXT5HG++mfLTX/gc1x++wv/w819l7sw6qWoQxDGCEpPFlT9yUQAC4xxIS5p6jo4nRGHAC8/+MckkZTDIqNcbzC126M3P47ymNEOkdDhfMJQ5uqG5Jw4JbMzm8JDe+gJ6GcIWKA1BmLLYDNl8K6C22KY/yJAy/L5z+97xoQlcay3Wl4yOD+jv3CNJE4JIMckNxjlqdY0Ia6BCytxUKikzc2RTmipdROGtAhwnJ2PWThsKAyJSJL7E9IeEwuOkIBIhtXoTbyxWHlJrLt0/FgE0Gg0ajcZ7dGHfK/j2bhPi+z9HzjSZsLO9R5YlWOsY9I9QAqJ6VdIqy5I8z0nTlMlkwnA4YjQcc9I/QXrPxmCA9xaNAakIAkmWZ4QyQMqQU4tzlFnJj/+liwih+RdffRFRlrSbmtSU4AST1JFriGPBg4uLXF3w/PrvfoP//r/5Z4ynx5xdrVOWU46PjojElJXVZWQuyDMNXmO9JSsynLN4AaWxCCIEGSdHI5qx5+7de4xGCaEO2dtu0F5YYGlllctX2mgtOHEpRV3jsIxths8yEpvT7LYZp4bSG4JAoxQVSCoQNOdDwFDk+fed2/eOD0XgemB0fEA2PeFkf4c8TZkmliRzOKERCpwXtNbOETa6GGN51/VWVO7nTpAkBaEXtOYa2MOCUksKB7oWo3WlXVWLK4xD6UvCUFFMJK99a4te490KwHsD8nuD84MQS1ClIGmS8fJLr2JsSbfb4su/9RXazTaTacJwmjAZTzg6PmI4HDGZjCkLQ7PZIggVX/j852lHDmcsgfDgSjpRnaDVRAlBVgLLTeYbmrm6pjAlV053WeyFNCMos+qHF+uoahMHJQ9fP00+8tQv/zh5UGNZF/zkX1lnY3vI1Y9fYe7cRUQzwuWGJo5sQ2ISA7bCxFpTUdOtzVlaDXjhhW02xzlJkhAGAXGjwZnzF1k9fZrFxRYLSxO8NyTWUpmbCvIsweKIajW0gFpcq+T/S4u3lka9TmuuQyOuEdUC3Ky8+H7jQxG4eM/e7bexJqmslxyIUKGDgNUza5WWmDMsXahMpO39D1VxnMrCo6WkLkOkCFm6cJGkNuDs2Yc4tf44x5Mjdo5vUfqcSEdIIQmCkHxUUNqSlutA9v+vc/Z+Q7iIbm8RcGzcu8dJv8+9jS3CMKJWq1Gv11FKMRwOmU6nSCmJoogwjOj1upUwiTcE2lMUJd7DIE051e1SkyASw3w3pFmnqmOHEU9dX6YTa5S3zDfrHArBYldyWNRYnS954Fqbb71WZ+2jD3LlsuKnrsRs7p6wM41Zv9DCaIWxlddElDt8KHFTj7HmvmWWKx06iFg51eCRJ+a5+doJ8QCkDDl74TIrZ87Q7rRYXukh1BTh37H9mi1UrSeMY2q9BsrkeCMAiTSe0pUMsjFR1GA6yZkmU5x5t/nzg8aHI3CBPMtx3t6HtY1OEtLCU7OOMk2YW50nCCNcWRlneO8pi4IkmWCmAi1aLNTmMT5gudejsbxCq1snmUzxJyMW5trISGCcJckyTJ4T1sKqVSwiXPFncypMmVFMhgipabfbeO8rnlpREIaVM06apjjnZgEb0ul06HQ6tFptQNAfZwTS0qxF1IIK4hgLAd4ghKVdV9g4us80jpUjSxK0lBTC4kJF0NSczhQPLsWVKnutzpOPKX70fJNG6Lgj54nOxbQCSWE9qTOkWYgJDOJEUVqDJ8c4g7MlCEnoCoQ0PPzYOsvLc9x6fcB4KKk32yipieOIuNamKOvV4rOwuMyTF4YgjhBSMNfpcni8S7pxhA7UDOVW5fplGqATgQwMQfAXRJFc6B5KWKQQKOdZOrvChccXaHY7HG3tVLlWqihyB7Ja3KTThGQ8weaCxeYcc90lsrKkPzzgyDricUSoQxpzLYRuM5z0GU3HBFGNlooxRiBFSWonlbBbGNJsNv+VP4NSilq9ztmlFXRcoxCe/YND4lpMludEUXhf3zYMK/RVs9kkDCvb0yAI0Fpzem2tsmEVEuEtcRxR2alYnIYg1JgsJ1B1tPNoKcjKysQkKzTeFnTDASel4Vt3jtnYzxnVl7FHU+6mkt0pjHSbtnakicIbgXECXVi6oWBQjsEHmDIizx3GVbhb4QWSGq4UdNoBl64ukqd1rAElwVlLnhu0msOhqEcV60RpidCagLByYneaLM1JbYGUGkRVFpRCUeBQ2mNE/kEKTD8ckPzPe6ytrfl//+f+k+rB+6WQ/j3P3f//DJ1lS8p0SJpOUFrPpDEVgdb3a6fV2yrJ9yzPKo6arPJjYx1KBgjZwPtKkUUpUdUVZ769YcCs9lrtSeCJogDhPUpp4lgxSQaMJgOMs/e7DPenu/tls6px4rz7blE5INAhtaiG1DG1UDGeZkgtK/l9WXXphLeMxn1wGh3EeF8SaTMrDQocgvHEsr+//12nryIuVu6VHxgRVE6fZ8+epdPqgPDkWcbw5ARrSpqdDo3ZzPDOV3G/I3i/M+g5Pj7mYGAxs1a6QNKua7SwTMd9LBodd3FeIKW4T6p85ys2tuSX/7d/+GcOJP+zHULQOPUwXiqQ7ruf+gHnuBJ+roDU3nmK8TGjm1/n1r2XCcKAZq1Gp95godejETUqZXEpZ1q38MabtwkCTa0ekqQpw0lCPV6m1nwM61YpCkNYCxj0k0rQ2PZpdwSOBlleofS9LWm16rTbDVQUcvnKHHfvPsert15ilIzBukondkaVqJgPFatBS1Who3zFGtBS4UpLvdbi0WuPc+bSA6z3ajz34its7x3zwIUOZ9Y7DCcZaToGBmSpwJQlWldWWxV7wWGtYHd3l1/8xV9893wheOjqWR57+CK/8VvfZDxN73MvpBQ04xrjNL1fMfn0pz/NX/vCF3n6iSc43N3h21/7Kvt3bhBIz5nFh/n45z9LUO9VPzznZ0Ip7rtuv/O7v82XXhhxOKlERU71Qv7O5y5QU55kOiIrJSbokOeW3Dj2k5Dt46I6Lu/oH+7g/fsvhD8cgcs7FJEf+MQseGcn2kNFEKm2O0CJCrkVxzGlLd9Di3Yz2U9Prd5geWmV46NDtNeUWYlSlXOMKUtc6LAOjC9ptDTOGqIwIU/2GR69ydsv7rN26gq9+UukpiJZTpKYewc1ms0GXpRoW1bYUuu5fuE0l86t8MKbtznYG2C9pnAG4fxMFl+Su5JAKcJAYYUkLdKKIpOM2RudoJ3n6avnCIsJh3e2mZATNwRRJ6M3d4pi7JkkhlFqqwWrtwj5/YtMAVy/vM6//jc+ycHhEb/3h6/MvCkEj107y0eevMIvf+mPGQyn73lXRc8Z7e9y8MYL5OMdZKvGyebrbL1+gTOPfRrhwTh7XxSvCuDKyd55x9xcm9XTa7QixU984v+j7k2DLDvP+77fe/Zz7n57757unp4NGMwMMNhIggA3keIili0niiSrLDmWFMepkitRxR/i+FOqLFf5Q2KXog924lLKEmWRli0psigSJAhRXAAQnAEGGMy+9fS+3H07+3vefDj+R53HAAAgAElEQVS3GwMuIENVUvD7pbtv3z739jnPfc/7Ps/z//1nOL1YIugblCYrRGlGSooib3hvdSXfutzk3vaAJIqJ/IB3uzO8JwI3v4GmOWfqgfd6oBYD0B8I3oNbNeTYS20sibEcGyPVsE0T0zTIFOiGjWmaTE5OUS7X0YWBeQbu3LlJHAd5xSpVKATdXotEBlQXZwiiNobap1DIOD17nNJjp9hr7rO9exHL8ViYW8QqlLiyFpJEJrfv7jNbHSFQ1GsFnnv0Ec4+8hBL04v82//7eeIkQBMamVAkaYIYt4ylMkWSl4ANzURlGcNOn94wAEun1++QyhGpihCGi0rqlAvTxKFkEAf4SYaUMUqlWNbYjPodI38gSSQT9Tp/86ef4PJbq7T6PvWyzS/8zFMUKzWqxUv0+nmZVYj87OqWiVMpY1bLFGSHQtEhJWXt6iXs6iyV+UWEMpEy5wInaYLM0sNZN+o3aO62+LmPLvPMo2cYDtLcodMWDEOfSKWMwj66puF5ZZ47X2cQSTY3A4JB811j5icFgvwvwN8HGuOn/ROl1JfGv/ufgV8nVy7+90qpr/yo14CD4H3gdKuDkJW51Pxw9aQdKiEFB80rufeAYWlkwhj3CCh0w2ZuZoFOq4HfH4FsMBj02N9r0GgMQOTwiwNR5PSEia1JsmgdW5MoUqIgoBV0WH74FJaV2/l4RZfjJxe4u+VjWw5xHNPr+dQKCYYOx2oVLMMiTDKqpTLVgkevNUDXDUzLRKmMKImQmUKlQJLkhBgt9w0bhimpJii7OgNfkiYCpzhHpTaHUCmhFHRHPeLUABKEENhuJW9xDEYH143DD7pQNBptVBwzW6/w67/8Sa7fWmO+YvHYQ0dp9FNcSx+LKN++CnEQ8t1XXmV1ewcVxyhNJ/EDBt0Br126xtkn38fZZz6EW88JQXESk6bp4ew7d+Rhnpsv8Jn3T2KZBrpIiJMBV966y/3798k0l0GUMgxjbNPCcVyEUaVge0TpX79X4d/y/UAQgH+plPpf3xF8QjwC/G3gDDAPfE0IcUopJfmR46BpdXws8uDVkOR6JzlW14p8tuLt2fjAY8AwBAqdJMrxP3EkuXL1Fqv37uF6BeI0pdvtMhgOiaOEqSmPhbKHYQg0XWCJFBnmpnqm6ZBmuVPj4vwkk5NTqHaLSrXC/PwChm6Tpj02NrfIKFKv11AKVqYmmfZsekFEo9Vn0O5iWiaaka/JhZ43E1nCRhc6Ms19g3VNH3ulKRLp43gucSrQ7CrFok6xUKRQqZNKBUmKl4LteMg0Io0jdNPB94fIQfv7CigKGAyGNLa3CMOQZ588xkTVwoxGlIsF2o1dRqPg+1Zq3XabtVvX6Pc6zM+UcGxB0gtxXA8Zdbnw9S9z4eVX+Owv/10ml1cIo1yYmiS5FUDSucWn/sanqFYtULkj0P17t3n+61+jOnUSr1KmFxlsbPYIwi5T87PMLyj6jetk6V8TwfRDgCA/bPws8AWlVASsCiHukDuqv/Ij/zJLQB+Hosrl6XEc5g6Dwsg7xwDGgsJcYAj5evfg+9xmKAoTdnZaxHGTra0GYRwjhCIII6IoxjJNDEMwbU5hOh5GGqDrAplFZCqgVDIplScw/ZR0PyWVEgyNQqGEYbTIMPDDhKE/ZOQPME2HOE4AgREnvNlssGDaHD9+gr3NbaRM0BRUSyXmp6exhUFnOKQ57NIfjUikRFegj70jMqEjMXBsm1q5hGm76KaDEDoyHGLIBFcX6IUqmtCI4whd07F0IHZpt955aoUCXROMhn1OPbSCkoqHVxbZXlvDsky02D8E+R1e90zR63SRaU6SHA5jZJRioKFninKxgC+GdAdNLn75eT78d36ZVCmCMMiNYzJJq9cFka95VSbzvukkIIwlhfI0U0dWKMmMYZgSNzvgFFFujb3Gq3hTi7Tu/H+zOfuHQoi/C1wE/pFSqkMO//jOA885AIJ83/gerkK+Ux+7tqDAH/QxNQmmIEljUiSZlOjkzcvC1A+dX1Q2nnGFQAiF6zhcu3EfP9SQqcoT9TLKyTFxRBJHuJ7HYJihhIdpDAF4+MQkJxbmKLqCRr/KhbeamLrJaBTQD2JQOkeWVtjrDum0W9xa3cIyiqBl+fpOpqz3fXZ6fR6qVllcOU6WCuZ295mameX88ZM0dva4ceMOli6Y1F1CAqSmxl1ueXujYZq4toVlGijdQneKuI7L3StX2An6KNPC6A45ceYRqvVJojgiTVKkUnR7LQ52B4dDExyZr2N7BYQmqJRyR87+/i7NZguhKyrVItudEYeVrizDdjxMr0qhNmTQH5Bg4FgGmrCoThSQWcKEZRIFPfx2m6xUIIojwjAkk5JzZ89QKpcRJJDld8+ZqSrLCxPc37rF7iBEN0zSaIBBxO7GPRrNBqN+yNKjK2y+S/D9pIH7r4B/Oj47/xT434Bf+39zgHdwFRYWVJTEIPRx5Uxy8bWLGGOfhzhK0ZQgiiOiOOWZDz5LfXoKJRRKCpIkRhM56lKmkmLJYWp2kp29lNGgl+dyNQNDNw83DgIYDocM+yGaoSOlojgmeIsMFGmOHjJM+oMBrf6Q7v4eJ44e541Ll6lOzLPTjMkcgZIJYThC0yz8NMXSdZaOLFGuz3LitMfc4jK3r15hfXOLm3dWGYxGSKUwLZsSDnM1j2q9TqvXRRMaupB5bloInCzDNAzMeMQHdq+Qzswy2t1kv9mlMz/F7Pw8mi7wswDDtDGtgwLKQeAKhIBKpcTmdoM0U3zoQ09z7/YdDFMQJCnm5ARKaIcQFQApU4qVCl51hlur9+g0u1imoFb1sKYtDM+mPj3BnTubhMNN1m9dZe7c+cM1rlKKMImIohBh5tARoTIePXeK2YVpfuff/CEbN/8KZIihaWhCx84y6BlMTJ5mdn6ey+/SF/ITBa5S6jC7LYT4N8AXxz/+2ECQ7zkg165eIcvG3JksI81SwjSXaAtNoDKB47g4rmBrc52tva380mQKR1fMFBQiy9ePGhpTs4vsNNbxRyNs20SmikzG2JZFphSGkVdsOr0e5bKOhsopMFKSJBAGEabl4rgeN25c47Gz5/jwB59m1B7w/qee5oVXb9IcJJT03AnTsnMMfgakCCzTBDSKtQmSOKLd6bG9vYtQGl6hwMb2HoNhgyAKOXfqBNR1dlstJisLjEZdZJpgux5ZluvawnaL4doq2fo90qFPlmQMj58hTWPSJEOmCWmaHKyZHqDw5A+FYcTUVIVS0SUOIkajIcI0iccQ5ihOx/N0XhhJ0oRMZJx78imuXL1OmO4TJTGOpSOjGEsHs1igVimzP9rh+muvUDmygnAcxpgHQqmTpQpkmqcuM0kmU/rdLr/6i79Ef5SOrWoBBVLmXYKrQxNtuv6uIfMTBe73gOz+C94WEv8n4A+FEP+CfHN2EvjujzqeAvx+l2xcRVKAaWkYppUzVlFo2dsVnyAcoMLxzjlTaLaO8hjnMTU0s0Kn2afTaqBkShzmbZCe66IbBr7vI7McfjHs97EMG7tSBmFTdCWDQYqhMpRmUChNoQyL57/+Eo39U8gw4/J6m9WtLq7jjrMZFrqu5TIUXUdpOls7u/S7bWr1GdxSleOnTiF0nSyDIIngwuuUy2XWN7fw6hXubN4njPNWPpXFpKkk82M008WwXeJWk0t37uUmeFKyK0Hb2qK2scag38UfDRkNByRhvux5O2jzPt4rtzZ57pkzVAREwwFCGFiFEkXDYm27SRAnh55xAHEc4/sj5o7M8KGPfJhXvpVC2sG1NMIwpdcbcmxximLZY9hzcDTFoNmkurR0qEwJgyF/8dUXWakqTp89j2UaJHFGyTZJlZHDSyDHBMuEKJSMRjkBcmKy+C4cm58cCPJRIcT5cSTdB/4BgFLqqhDij4BrQAr8xo+XUQChaag0RaVRXnHSDYQwUOS3HSVAZLnjoaY5QAYqV0CQgWnoTNaLBKHiwus32NrcJ4kChJBoCmzTxrJ1hCZwPYtMZsgkxLUcKiUHz7EY+ZIkVoT+AC1TNFqCNNGp1+a4evUy3UBxZPkxOmnM5HSVIAixvBKT0/OEUYihDxFZhpQpd+6tcvPmDRYXfXzfJ8kkSyvLhHFMGEZ85GPP0et0qU5UWd/dYTQaoY8NxsIoJggkmRrS7nTpNjdptVq8MBgRhjGaANs0Wbh7gyTp4zrGIVTZPpQR5YAwoQlc1yVMFa2hZJqU0vQSi24lzyYMhsSJIgiit7VwQBhFDIYDdEPn1NnThKOIe9deQ2R9/GGfxv6IqmchDJ2dfsS8BTJKyZSGyPLJR0tjvvryZSrBKsdf/CaJnrE/SviVn/ub9PqCWBl0+l32ux3QNAqmS8GrEdmTFLuT7xovPykQ5Hff5fn/DPhnP+q43zc0PW+ekSC0MVlb0yHLaSdCM1BZCpo2rg6ZpDLCQEMqME2DiUqF0SglDtq4VoznmsjUIP/oZESBn693dT33xxV5f8D0RA2hO3R6CZ1gmlAUGUV92r0erWYCsaTValGbWqZQmuFU9Sj9bpP9/V3mFxZwvCLTzgS2dh/N0LF0nUxlbO5tEyQxURihlGAwGNDpdkilxB8NSaOQbq/PRnOPWKYYRl5A8IMYTRtD+rKYfhZh6Bkf/dhH8hShrpGkILQcMK0UyCzvmXjnEJimiWVbuMUSvVGKffY0yi5SsV2Uytja3OHmrXvfdzmC0Kfd62CZJpZucvZ951g6tsD6jes4hQJJImncvcaNO5sMY4/VnR7OvRuUFucPc+ynZkzCHUWjNSK0DWbqk1xdb/DShbc4PbfE9LFz7HdarJxYYmpmite+8wZLE9Osrq2xGob/eYgl84KBiRAqz9lqFgIdTeRwuEzPS5kH/AAhcqdCkY2pg7pBsViiXLH4xZ//JHGc0O32uPzmTdbW91EKdCOfmWSWoQFxltBs9xFiEde2SUWJa1tFBoOIMBFkKiOM90hGIaXKNF5ljlYnwHE0lHCZm12iVpvENjUSmXNudU0HXaNar1GpVslkhq4bdIdD+oFPzx8xDHx63S6aAD8OsG2LURLlzAUgSdLx/6ehGxaZyoPU9nRUluWNKUaWqz/SnASp60YuZXogmyCEhm6YKCXodLp866WLPPf+x3J6YqGA4zoooRHGkqWZKmEQ48f5DdIPBrS6e1iWg2VaOJpABj0WTy/jVmqYSUo4W4KZeS5dvMDe1g7tl14lKzhMLazkJtrDNZaqktWwz/1mTMEtgJZx8a1LLC2sYPl9ur02a9vrkEEY+CB1rt+9ym5j/x3K6O8d75nA1TTGwWWNO6ZMlIyRea0MTUmElXNwISNLQ3IzogwlQ2Rq4o9CTBNKBRvpGBRsC3VWIdOUzc0GMgXDzDdnaZpimBZ+ELG332dxoYTKIEgsElEiTEZowqRaN7GmZilMHWXi2CMkg4yiYRJHEVHok0YK0oxef8B0Nd/YCAWWbmCbFr7vM/JDhr4PCEzbwVSSRCiSKMYPQizLpOwViJMUTUDRs1AoTNM6TPmBIhOgNC0PZHKqjmEIhMjvHkkiMc23L2kuAc97nVOZoiUR3/zGt6jVHFYWF9hc3+LmrftkUrE0XydMYm6v5Ung/Y11WnurCMMiDGI8JH67Sy9VeLbD8arH2l6PncEAtIT6dI21+xt895vfZvnkLjPLp3CQzE9W+LX/8lm295tcvr2NH/iozOBf/uv/PX+TQpHIsWBUpsxOT6KZuUT93cZ7JnAzlSCEjRAmmUpAJch0mHeAGcV81o0jNH28cU7jQ3m3ZgiCMGZtfQ/XcXBsL+8LyBSe4/HYo2exzLvcvrtOkIRIAZqmoxuAytjcbjJRn2G6KrCMDGGUMZ0CaWbjyRpSJVBTVFaOM9rcw4rSsR5tkk6/xyiOQeUzo2NZaKJArVJB1zXmZ2fpD3oMV/ukcYxIE6LhCFKZg09E3lqp61pO7+OA2ZsrPUzLQAgt33VnOX0u38AqlBKkaX7HUVmGZhr5cXg72GWSUijlqcCVuRqLc3VMIem2dmju7WLZHobeR5CxcmSSVttHIOi3+6zfvYkSeVuoAdimgaFpFIoOq42UNAM7g36QEKcZs3NzxP6QYbNBfeYIYRSiZzEz5YwjU5PMThT52qt3eeW1ewgdbMtC0/O2zSQMiSPBmYePMVGrMvAjvvbyhR8aL++JwBXAdNEbR6QEcld03BKGYaLpVn7bUFmulM0UmlceFx8SLMMkUwI/KhBLg1Ek0LV8jawJC8Mu8NAjJYrVeYJwbF4tGKfEyGc2zSFJRwixh8x6ubLXSrGyHAJd0g1E8woq6mEKDdu0yRRM1hSTjkXY87F1RcmrIKVHtzlgTdvF1PXcGHAYkUmJISw8o0DqKNJM4hguQuSERVmQeenX8vIMhRC5KHSc29Ie6PHUtTyIDVORjpu186cKarU6H//4J8b7BI352Sq6gLnpOnPLR+kFBdr9mE5cIrNTKjMFNG8WFFSmH8IrT2AXCswePUXuKK9h6vp47ZobE8osQ88ySgiKKn+dOInz9zyGXMdSkkiTnUhDRGBqVU6crmAUFygUHGzbyScQLSdPRmFMsVjAdWyKEwIhfrh9yXsjcAX83AfLyN09tNmHsKpHSEddurdeZe3GTZRMmZkr0vVTirZFoxtSKLssP/1B1tZ2sAyDgVnn3GMfz5upFdxfvc/09BSe63KQhD9o5D5IFh0wDgDu37+PZVkcO3bsB75HpRT9Ucjlt7rMzU4wOzOFa9uHMxzAhQsXOHHicWq12g/8+ygKMYxcirOxfoet9XucefRpKtUJIAcmv/LKKyyfO4Jtm5iG4IB+LnQNXeQpPN0QCJX7iR2oJxgjVdrtPtdurPOBD78f07YZDvs4toFjubhOiciPeOP115ibX2Dm6FOsPOJy++YNmo0WxVKd2fk52p0WF159hXurq5hKsICgICApFPEeeQRPJHRv38VJMmaLFnGkIQyNsGxxL5JkQqMoMz7x058+PBeKvIc5SzuoaJvR1n2i4QjNMHArFezaCkb1BEIYh+fi3/2HP/mhMfPeCFzgiYc90pkikWFRO1Jj1IwZiWmCK9/AtVzivV3MQUKWxNCVLD+6wrmFIv3NiOb+OqXTyzzx5HmEEMgU1tfXOHZshZmZGSDHOum6Th7EbwfbgQohiiI8z+MDH/jAOzqrlIIoyWi0Y67dWOPl7/w+aRyyfHSJ84+f57Fz51g+ukilVOTGzZucOXOGpaWld3wolFKMRj3+9D9+nqLn8dTj72dwrYtWsHniyceZmpoDBEEQcOnS6zxy9gSeZ2MZ+UyrGwa6aWBoAtswydKIl772ZbbW7nPi4Ud46qM/hW07pGnM+voud1d3WFxeoFCtMhz0mKgVsDWNamWW/b0BL7z4Eq+/9RKOY7O0MEnUbzA9d5J6sczJkw9x684ttrc3uXDhArYQNNCpWBbO7ByT1RqnJlyy/R1sP+KR0/OsbTYZKUm8UGZ/IBlGKdV6jTNnzrC8vAxAGnTZf+OPGey9SWt7jcrIJ4gzhsOI+vI8VXfIwqnHsSfOIYROGIbvqqh+TwQuwGCtQW3KImnepiebWIWEQi1g8tHTNG63WFvfZ2HGplR0mFiqotmC+69fwpEJR45O0wIGgwHXr1+n0+7x2sXXWFtbQylFsVTi6Sef4rFHH8UY20XB2zPugZL1YOS72Rw00u4n7LdShqOUKBbEScCg3eLNdoNbN2/xp3/yZ8xMT/L000+TRsPD4z44skzy2sULNJpb3Om2GAyaZKMOuuZy+dVv89j7nmNiev5Q5iNURpKAaRtkKkFHYQsN09JBSb794vP8+b//Ar1Wm5e/+gJ3rt/gmY9+hFHkE4QZlqGjZxlpGGDrFn7XJzYybLPEF//iBW7eWss3ayguXXyFomszO38cQ+QZirwzL3/vmhBYps18sUp5Ypb725u03SWWT57BGHZYPD1P834XlSgSoRGGI3oDnyR5u2lHyZC7r36Bi3/2B4x6Q3ZbI6oFA9s2efjkHK6R0traJPqrz3Hs47+KXT31I+PlPRO4ZnUCIfpkjcsUZ9+PZZVI1AbHnj7Fxs2XyNCIjAKpYTNVsHDtmM76fUpzU9hHjtFqwd7eHi+99DI3b9zm1q1b+e0J6HQ6/Hd//x9w9syZ3H/2gcA9+PpgsEkFwyBlrxnSHcKVK6+RRDFzU4uojDyvLATLR48TxRl371yn02rz1JPngO+HhTSbTW7dvkLs+2RBwvbqbVKV4o8C1rbXOXrqLBPT84daOtMUIBL8IDfbg5RkOOL+y5ewbZtvfOVLdLpD2s0Bk57Bi5//PFe/8zJZrUBl8gjzS0/jeiZhu8Oo36M36NHpttlphly+tpUD/IYtRqpPrVbF0DVQkmZzlyxN0IQgb3fKMHWTklug5hYYxhGWUyKdWWThfU8z2NlmrbEBM4sMO7vojkPi75AMg8OsnFKKwfYl/vQPPk93r83ppQInVurc3hgxbA2ZLO8xbFs0QxPt/ibmhM6RJ/8bMB/sHPj+8d4IXAHeVA3RHUKUcX8Hyk6TimXi2Sa9XsTNjZg3A5tHP/EphlrIse7LTM1alI+WkaUyoi0YDkd86lOfZjjw2drawrJtRmFAtLfHm5ffpNfvjQ3n8hc9LOtrbwdZEEn22hH9gSLNBK39HW7dugwio+A6KJVRqlTRdYM4laCB0jNSJcccgXeOLMu4evUN4jhgau4IxdKQjdWbKM1gNAp55IkPMb94FKEYY6UUgR9RrjhIkaJkxv7OJldf/Q4vPf8XeMUiozih2ezS6wwom2VaHR/cPTRZZhAJ5pffh1v0KGo2dqLR3mpw/8Yqb964g9RcLNvBtTQsgxzLD2zvbkCmeCoKEAL0DEyhowmbpqFhGjBZmODkY48jKiZffeU7DBr7nDAN5k4cIVhX7LU6zKcOU0mMNS4dZ1nIzVefx8t8jAmHOx3F8nyFR89N8Scv3uAPv9XAyxJKBYsjx2s8Otgnar2FOT3zfefywfHeCFwgDbsk/R5da54/eHGLSWKm3JRSPWE3tkjqS8R6iUa3Q+WRMwRFm+JxHaPo8a1vX8NaOM/62iY3btxACEEcxwRRyNb2NoPBgCCOGAQ+9SxF5+B2qA79onLVLbS6Cc22JAh8er0eG1t3KVWrJGFEr9+BLGNyZoHJqSO4BY8gDLDcAu39nR8YuEkSMxh0EUJH6YK7m1vsN/o8/fQTKE0/tI2CfAMjZcK1668wPz2NpplsbKxy6dW/ZOPaOoNBwhHHypvC9/r4QYxBn+4wBdMnDny8muIDukGlVGIQD/HKBU4sr9Dq9Vjf2Ud3PJI0wzaLeK5FGIywdINg0EMYFq9feJnq5CyZLjA0nbqmcV53eZ83xYmFk0x+5tMMRj2++PyXaO83KRxZ4UY/4mhxhkll81A3YNjv0xn/T6P9K7z23ZfRCw6Xb3aJE8EwS/mVTy5w9qzP733pGqZMmPEzppcTRr0+ra23mKr8YMefg/HeCFwFjavXSEYhb64JVtdDbvciRJwiZZNAOnlbYhjRvPIWWb9BeGKOp058FmHodNUO0wKmp6f5rd/6LcrlMo1Gk1q9hje2MfJ9n8997nNM1CfwB4OxoFLnmQ8+g23bvHHpEs8880GGwyHbO/tEcYjjWiRJzOLCMjubWySxHK+JU1IZMhxGJGmGZdpA9g4viIN7ZbfbZWd3C9PUcC2DpbkaNUfHsW10y6FULuVZgXHWIwxDfu/3PseRmWkePn6M4dAnDKDVCNlu+kzMVOk0h/QGMcNIokjoB6B1IjKpUK7E0E0K3gR+J0RVy8x6Oo+GD5MZOtv7Dfb3m5i6QtMEluVQrVQwTJNOd8ALL77IwtJRCprBT3llfrm+wJOTC0yUp2BuEeGVSV5fZWIv5o1EZ1kppjb2eHZmjmy3zcXdXa44OsIQKBmwf/cvQYXca6YsHn+I9bv3SCOfJDP48FOLfOO7q2w1MgKp2GoF3LnXpTO6ibu4/wND5WC8JwJXKUXrTodXvnmHt0qPkWpldL1BWp1Ey0DEMZlQZJZHWvLo9nucs1wmpuYZpAEf+9gHuHpnB9d1mZqaIo5j5uZmKZaK6KbBcDik2WzywgsvMDc3x87WNuVSCZll7O3v4bpu7hMWJ/hRCrqJMFNsp4Cm6bimi0xTNCcjyxKGwyGOO8R2LFQmQOikaUiS5FZTh248ZLRaDfa291hcmkLTdJZOnCGJfJSU7DRaHC+VDqHQB8O2NYZxj7tbN/Bcg25vRLfnY9cceoOAwdCnslChs9Yh1W2EmYFpUimaRGE+66cyr7TphoUsWUz4MZPdBq1On4LnMRpmuK5DccLDK5UYdLoMBwOyTDIYDKh6Lr8wf5wPVSawHQ9sE19EON++hNhc5eh0mcWhQq1u82S7h2p1udfa4YpUfCOKOScz/PY1tq++ShCk3NnxOVbMkF6JOOwzDFImJlze99AMb6QbJFmCVBmtbsIw6vBIELxrzLwnAhegea+BNooozdZIq5Pgezi1WQzTZjgaEmUpqabh93vQHnHv6m3euPgGx88cxTTyPgY1LuUepKH6/T6dTgcpJaZp0u/36Xa7xHFMq9OmVCzxyiuv4Lou/9XP/Tz31tbppgUy5aBpklRGgOTOnbdotxtMTT9CmsXEic9w1KbTy4sZumYx7LYJ/JnD9wHQ7XT5ylefJ0xGBHGRVIGR5fnYKIjodjpM1qffgYw3TMFjH6yDyFAZ6IZg9Z5PP5Q88bEZti7tEoTw5E8t4acZ83WPYZCgZ4qz5+oMjVL+IQzjvLcWRSYUmqsxUa9QbhSRUUi9WsO2LRzXpT/sMDu7wOZem7jbJY5C5ss1vm61ud/p8NNHipSiHvYbrxMG32YYJux5OvV2Fz2KKeqKVClGqeJ6zWWomUihsXfvVbbW97i31mN1a8Cd3YA08nnu5CSbjZD2IMR0TDyRkbk6laKT0y27Q6Lgr6ny/f9r7HdTdF0jufQNpqVc4XYAACAASURBVM5/GDE3TXFqivvbDeIkIopDRBTTvXmVKB1RKy/xta+9iGN/GK+ct8DZtk2v1yMem3lomj7uK/Xp9/skSXK4/nUch5WVFQb9AUGYu37vbe9i2rO45TqWa+cUwYLDpUvXmZyYwrJsVAZpGiM0NW7usfIOy3fI5yGKIr7wR3/E62+8yez8BH6sUTR12q0W/UFurLI4N8vK8so7zkMqM966tQdajiQSuqDhx6SWhhAxaZyiaTq+5lOuW9i2pDJXIJMZvvLRjQK6BkLGGLqBRNEbBVSLBdAMbMejOjVJ2SsTh0N2dhrU63Xurm1QKpVotnbRNFhIBTN9n5e0DCFC/H6HlVRjeXufLxoZb/rwa77GOddFGTqBVNxCsG1ZaHYBTJPO/jZ7TZ92P8HUFXudJiVDQxOC+7tDwlGHNElINAPbg0KlhDIc0jgiGP5nELhCCFbOH+PmhRvUR3123nwRvX8aLU7orG/kkA8TmnsNFqarHD32GG6lRK+5RbfZwCpNAbkl6S/+4i/y27/zO4da/+npGUqlEo39fTKVlysPZrid3V2iOObs6dOYhkGhVKXb7WDaHpqdl3Qnphd49kOfplquMeh3QAmSOCEcRTkGH58oikilfFt1rBQXL13ixW98AxB0hileFSxXZxhI2v0Ag4z5haN4heLhOQBQGfRbCVIledHE0IhDieUZ9NohaZxAmrG/1cGy86pjrVxC6CntsIsdHZTGQ5xCkaHvMxglWJ6DUBkF2yaNYtbu3WZlrkpj+y5pGlMolnFMyfaWji4EA9fh4Qz+B3eSaChpJhaNpMcbwYCXj1QpLRxh494eZwsem1nGq4MeX5IBPeFSLNjohgFZRpxIUqBe8hiOYuY8HSVTgiBk5KeM/ACv6lCbLKI7ZUaRYuhLGtsb/LWAIEKIRXJp+sz4SP+nUuq3hRB14N8DR8mbyX9BKdUR+RX4bXKHSR/4e0qp13/U65SP1nhUm0W/DMH1XVTzTf7yxnXKC8cpuToiihm0fOKZFcpLp9jdWMWMB5TKJdKxNlDTND747LP8hz/5Y7a2tvAsm1MPnWJ7exvf96lUyjT2G2haDrhLkgTHsnjug89SLpfZ3F7jxs3v4BVKeUl0foGJyVnKpRqaYZLKGIUi8AdE/mC8JBg3bCtxiIva39/nP/7Jn2I4Xt5IYrrEUiPBoFKfwLRM+t0BO3v7BGFIsVB8oMoG/iBGylyGIwSMhinCVOw3ughdIJVk0A4wNJOCV2Jjo4nl6qRGipIxmq6jmQ6RArdUpBCH9MOU2aUjXL95DxllDLpt2iLAIcW1NKbnpuh09hkNhhSKFeTsLN+ZrbGxvslTfpWFaYuq6vI5McKdPc30/Cy91X3+IhzypqOzf3QGq/wQjxcLFItFigWP4TDCNBUyijCEzUzJxtNS2q0+hVIZiSBJIxwzQxc5B6PZaNFsdBiORj80Vn6swCVXMvwjpdTrQogS8JoQ4gXg7wEvKqX+uRDiHwP/GPifgM+QS3ZOkvv5/qvx1x8+hGDyoc8STG9ytn4Ne/INKJTo343YjjyKUxPsvfkaJU1nbn6Zuzfv0rrzGj/17ElmFubohQfdUor5+Tnm5+bY2NigXC8TxzH9fp9i0ePIkXlM0yAau3rPTE/z/qffx+OPnScIQhzHIY1TGr11djdWQdcplktMTswwM7eQY8BEnpQ3tbx8LKXMCTJSYYw3WW+9dZl7d+9Rm53CMnLeQyIVYSwh7OGYGSEJe9urvPjiC3zi45+kUChwELlh9DbkJNezCTAUqRSUiyZChyjK/9/inMf65jYit8RAKImuW5RL0+w0tihXq4iyx9D3maod56knO1y/dpujR+ZpN1rMLhynOjWJrgu2d7ZJkij/cOoau8dWeH11lbWgwae2y2wMO7yV6JRtCz+O+FYVpk89womHT/P05CTlYplMCAb9AY3dHe5v9pBBRsHT6TbDHPGaSFxH0PeHSAWWLfBsHU2DNElYPDLDaDAkCuW7Tbg/lgJiB9gZfz8QQlwnl5z/LLmkB+D3gL8aB+7PAr8/tkf9jhCi+j0atR/0Gnz90us8+tA5nGUduxPQ6XUxHJ3Z6hRrdy4zrzqUZ4u0ty4hvSqL81UW5udIFWRJj3QM+9jfb1AsFlFZfmFXV1eRUvLwwyf5+Cd+ihPHT+C6JWzbZnJikpLnYRsmb7x5mVarQX/QRShJEscgchnP5v07OF4Zr1DB0U0ClR2uk0ulCWYmZ0gVOF4RUPRa+4gkRGQpSEU8lCAFpsjQ5Qg/GuJqGSVL4/KlbzIcdPlbf+vn0bQcipfJjEwmmJqFpo37bk2LMI7pJAq3ZCLSmESm9EcRUik0dOIgwbPzrIIuNEgEnlXCMy0qXg/NLHDszHlK5SqrN+9y/BEP3S1jmho3rl5iZ3cvN7UGBp0esjzB4MzDfOXKZe4GDWKZsKZlPGpoHFla4pnnnmFuaoZyrUahXCWKEwJ/hFMo0Ou0aUWKcJRiO4JBFDMaSTQNXCWI+wFhFLAy75HEKakMsIsSmUnSJKPfaR6WwH+iwH1wjMEgjwOvAjMPBOMu+VKCcVBvPPBnB2yFd3FRF7jTU9y/9waTlSKJO4utT7AcrqHR5H3P1LEaXWZWlvnmhsX1nR3Of+QMxx45R6/VJ4h69Ho9XnnlZba3tymXS3zm059iYqKOyjIWl47yM5/9NLWJKp5loOtWrrDIe9KRaU5SjKMIJVPCyCfLMoqlMnEUo5RGJmwGocBJfDSZIEybQrmO65URkWRh5QSmmXtRzC0scv7x81gFh3DUR1cZ5UoRKWMCCZphMlE0OLayQmlqiaOnHsO27bfr+4nKubGZOuCdILIM1xQIS0NXYBgmcSzZa7TRdD3v7xUilxmTV+E0zUATOppewDA8lFLc2r5DfXKeh+wS/cThC7//e3hFl6C9ipQpUqZj/JXEMkye/sSnCJ94nO071+k1miwKweTEJOcfO8/s0hEKpolCJ/AjosAninyGvR5pmmBYFr1BTDgMcWyLIIgYhgk3N7uYmsaxOZOCZeAHMVEQkKg9Rn6BKalT3Om/ayz+2IErhCgCfwz8plKq/86mFKWE+EFA0Hc93juAINWJKfqjAZgljj40wUS9zmj/CHevXaTX7TNxYgklUrZXrzM3dYSVoyf40pe+jhYPeOzp07iOy8mTJzl79gyf/ezP4DgOlmVg6AaOUyC3I1WQjtA1UJpAjqUhYqzQRQhsyybLcgaWPxogVYamQxZHZIaiYOhopoU5tcjs0gly9ExG2w+pjz2n3v/Ms5x/4imEgFa7gSCjubvJaNDDcEvYlkmlVGV+cQXdsA43i3GcHDRckkqFZuQ9t45uYgktNx+0DITICyGWYZBlUKtPoRs5gqlSOkjJZTn9R6nDhhmFIIhi3rp2i5mZSRxD8vjpabZ3GrRGfaJEkqQS07LwLAPTgJqhMf/YE3z8wx9B03NRar1SxLYswjDMN19pRK/dYTjMMzSDwRCZpGQK0lSj008xdJOymxdqwlBiGYqioeE5JkGgkcQJmfJJ44yzeFj39991qfBjgZ2FECY5O+ErSql/MX7sJvBRpdSOEGIO+Cul1ENCiP9j/P3nv/d5P+z48/Pz6jf/x98kkykaYBpG3j+rFHEUMuj3sW0TQ4f+MMFyXGzHptXq4DomrucglYlXyKtkhq6/IzcqRO4VkY2b0fMPXQ7PE+Mm7dFwRL8/II7jcbbgbVjxAwdCFxqZUuiGNZbPH0i6FYauUa/XsCyLB4Ec6oCLplS+EB2/p4NmiYPys1KKRmOfbu/tVJA2bgbPockHzTvqcGOoFDiui66buRxp/EEtl8ukaZrr8h54rdEo99lwHAuhFEnoM/J9ojglGcM8HMfFtPOUhaEbeVvlGJAttBzEzJggpI2P+zZmNDu0wsqSEUkUkiRZ7vSe5drCTCk0DRxLx7J0ZDr2uBtfF1fomMBvf+4Pf3Kw8zhL8LvA9YOgHY//BPzXwD8ff/2zBx7/h0KIL5BvynrvFrSQS9Mff/ZnMS0bXR+3emviAagdKJUHX5pJyDLeeP2vuH31DaIwpFIqM1mZ5LsvXsS2PH7p53+Jz37yk9i2RRiEhJHPzRvX+fznf5dOpwtCUSxP8+GPfYaf/sxnKdgWb7x2gdfe+DJmISD0A+plF9Ow0XWBHzaZL+xwb1vSTitEyYCCVSIMEwpukf6wTRqnzFWf4s6tO0gVk2YJrufhug6d1ja91i4qzTCtGvX580wsP8vk1BF0rY/y+4R7qxSrk5imzSMPP0lFRYxaPU6dPsvS4+e4/OJLmFWN3mjIvUbA7c0OURgw6LZxHJ0k8akWbM6dnOXqzWv8+Z9/EU3oOE6R8tRRHv3gJ4kw8Ew73wB2dkmFQZRIttbvUqnPAhphv8XK0gR/5+ee46mnnkAhiICBUkTj62EoQUUTWOS8YiUgQBEqhSE0DOCrf/ZnbG9exCoEVJyMyZqJ45hsbEcYhsb0tEPB0SmWLSZn3k+hWCNNJaXCAo5TI4pifufffeGHxsyPs1R4FvgV4C0hxBvjx/7JOGD/SAjx68Aa8Avj332JPBV2hzwd9qs/xmtQKNexHRddz2UpQhtj7saft4MZKRl7PzQaDRQKP/QpFYsIoZBEDPyQte17CF3Hdmyu3HiTW/eucOb441iGTeSHxDLFc1MmanVqk1PUXItioQDCR4guphsQZxGeVWYUb4IVc6sjkQ6UrD5JKyFJIyQ+O60NZqdW2N/dI5Uxt+9coz9sols6tpXlOKU0RUmDSv0ok/Pvw509i9QMtnduYSQNVBhTmXuYXhaRppL+MEJkEZ0kwb9/n7A2wV6mca7o4AuL3a1dSvNV3NBkdXOTum4gNFC64tq9NeI4ptlooGkmju0TpAadZoMQndAA3TQZNXZJDAdheGRmBc0qI3QbMxWYXhXHK1KbmuVATGUBHfJeDDPnwed3RyUwEBjk1q1aTjlGNy3CNCCTIY6l0WxH1IsGhp5Rq5iEfka/nbBs1Xn5wjeZmptheXmF1B+hBxaV4tF3jZcfJ6vwbd4Go3zv+PgPeL4CfuNHHffBIeDQB0CMdxcaAl3kMvT9/T3CYMTS8lF0XcNwbRZmp3nzUojrunleVhPM1nS6/Zi7d1/j699+gdmZOV5//WUazV0efehpVk49zDDoYellpmcXqNUqEI7IXBOZKTQzxdIkW/ttZheKxPaIJAnwHIOKqNCLN9EtjampBSJ/RKVgkASCqQmBYSmcMMehQoJKI8I4RhcmXqFGde4k5ckzCHeScLSPlrRxXQ3LczHqC4z6+0TJCDOTZP09nJlJ0pHi+W9f4NXVNgszE9Rsj0vNDK9goKkUqRu8/9gRCsB13+fUyiyNRodo1Bk3x0vSJCLy2+ytXyXJBJaRe0GEgw6Z7pBkgv5gSHfzGrpuIeOQunMaXyla42qgzCSxZuR3QKHIyGckgzyITfL1sxIih8KOwSKWKYjSjCzRME1Bt6dIXRtMnU4vJI417E5Io+mz197n3tp1quUiR47McXT+3Zew74nKGTBeM0nGQtbc4zZf/fHtr3+dzt4mf/u//Q00w84ZA4YzXn5KosgnjFLW13osTHvoUY8vP/9/cXTxFPXKNPc2rvOti89TmrDRbY1PfuJv4EcjLr7+EsIQLCwsEgYhQlO4NQM3slnf3WBm2qJWtRkO+pi6ZNi2Mbwe0/UUQ7iYuqTu1QjiBroZYSmBqQmyOMgJ46ZJob5AdeYkZmEKKROy0UaO3k8d0qSIbtpoGCRmFa8wg2pfZ6ago8sISxeg67ilKpgeF3czOn6fmp0g45SB5RDpNpamMzld4d5Ol+bOPiULENq4ZGxiexUml89QcF0yAXLURXcfI5UZvX6PwsgHGed+Gv4I0zSIgZ5SKJXvDUSS5qkyTaApRaYBYxiLEJCGIWgC07ZJRL5DKNg6jtAoOoJUCXa6CiOIMYVFnEJvKGldG+AV8/XhsB2jqYCG1WLQ+857n6uglGJ99SaO62KZ1tubAXKH8TAIWDx6jDt37jC3sIxbrIJVxDJdWp1ddDQm6xM8cuoMO6t3KGUK2Q95fesiXt1hvzfgxb/8MoWCzUxtHkWIVAk3b7/J+sYVjs4fZX7hLKns0fbXsYsl4k4HGU+hScn+fkTRsXGsCdIswdSrhFTY29/ARIEWslB4GL9bJvZjYj/Dq1SoTC9RqMyRIUiDNkokOE4pFxcKE0u3iFONUA7xyjMU3Bq99g32A4EeSVKh56AUIWjvN+h0mnRae0Shj+mVsEol4iCkNzPDZGUKI0sZDANKdQuhGXCwKU1CRNDG1mzSTCPt/T/UvVmQZcd55/fLPPu5a9Wtfe0d6AYaBEAC4CJRHJkiRVvWyJ4Z2ROKsMP2OPzgCD/5xX5yxMT4yfZETNiesPTiUXjGGo1mtDBClkRaIgUSJECsjUYv1dVd3bVX3X09a2b64dwqgBwSUogzCjgRHY2+y7mnTn03T+b3/b/fv4nE4AgbV6fkZAihwdJIR+BYAkeAbwxJlnH/1i3Go5Rqrcba+iqDwYCZRg0nKNHv9vEdl60H96jXaly4eJFI5WRZRi2QeGWJ6zqMUkMpThHSIklSorFAG0M5BMs2TGLJZGQKHfWkTaky/LikwicjcLXW/G//8H8EUehmbcuampEELC4ucLB/SGOmTvn1V3nhpc/xzGe+yMzMLJXKDMcnh2SpwnYc1lZXaR0d0BomVCshg3iCzhXlSsigPSbLEsp2hXff+TPcUhmjc3r9DneGJ4zGOZnt4lgl4jRHq4CTg5hJzyL0K3T7PZbWhuTRZVyxjJQDDtt7lCwfx1/iycMetdkMI2zC+jzVuXVsv0QS9xFyjGt7KByMUfjhHH7QYDTsIoUmKC+QxwMSIzGYAnsqJO1+Tqm+SlUahGdDfZ40A2VFjHpNSpkCndF9PCI5PsC1BFqftSIVWQBtBFmuGeWCGaPIsoz2KMKnT9BYR3k20ipjmwypNUa1saRNv3XC9gfvkqUJ3/6D3wEcbMejXm8QJ5pwdpGrF9f54O23CEs12v0mnmW4sL7GabfNqN3l4ryDxCvosSKjXLER0qNaF+w+GcK02meMxeHuhDyzcD2NHxqu3vB/OujdX8cQQvDyCzc5Pjri1e/eIctSkiShVqkw6i6RJRlm0kPWXbbfyRkNeiRphu+HPHX1BuXALwTeCpI0o9/tkaYJlUaFYS8hNzmeIwqgnQmJVIXJSGC58ziiQprsMxj2sCuGw8en2HZIGifk2ia0Z1mem6dhzVPSPrXyRYyVI6tQLdWYrSiOWk36rTE3qzcLpVo+S6Y0Ju6g1QBb2gjPYbY+y8qFF7ly5TM0ZjyGgxZvvvtaYTBdD9DSRyKYC10m7hx/9tabzC4u0xxljMcRaQ4pAV6lhHB9jFJMhh1knhFrg2sLvFIVhEJaAZYtMdLBKs2TCo9RDsurc4yNxdFJl4VGSIyNshTKaGzXJZ3kKKfEnfff4vU3X8V1Q9rHe1jCwws8ht0jDGXGJxGPtx8w6TUpz18gHR8QyiEq2mUYRZT9JXLjsTbvkoiM9qHCDyTVRoXlRoUs1ewdTmi3U7q9nDyDMHQAhS09rqy/iBC/9xNj5hMRuMYYPnjvXbIsw7EtXCdACmjUSsxXQnZHTUYqYXlujc++8iKLK2tsbe2wsfQpBr0xk8kEbSLGkzHd/oj+aMwwiphRmuN2D8eXOJbN85/9Kpc/9SXWF6rkeWFR2m81OX74OrYlsV1DNbxINkmI4y4b84tcm12j5s8hbYeHB6e8+t632bjsYy8K1lcWSXhEOU1YXVnHUz7YHsnwGGlnpJMYg6Q2swTCZ212jVeef4lLly5TrtY5Pemw/fg+7TGk44hovIevMmwvpFafwfc90t4+Wmp29nooDUzzyFcurTO/sMIbb3YZDCfYTk655LG21ICkDxSG2NoKCqq55fDMi89x4+oa5vYJre9+l+rsPL7WaJUT2BLLDZmEAaWqIho/4eTwgFK5XFhqCQcHjTETLOkjhIt0wA7qZMImjrp4QUx/NCRRitBt8OwzmwyjhDvvPuSkWXiyif0O8eUKZX8W39PsdHN6w4RK4FKpSUolm0q5wuraDD85J/AJCVwArTMWl+YRsvBaaDQaGBVR8iQ3P/050BNuPn2V9c0VPrhzl5PDE1y/zTBRxKmiVg1I0gTXs3nuuVXSLOXhbo/FNZ+q7wErrK9fRaRjjvd6jIcDFpaW6Hb7DMYOG6uLjPVtolgxHnfwbMGyKLHzsEVmTVidrfFw94jcRLy5fUDQ8fDdMXkWM9MYs3l5l+z0OeKoTZq0IJG43gyuH5LrjKTXpntos/OdPyE9vEFl4xpvfeNfkNVm8IQm6e4glcLYmoNWn3E7Y30+4JXNNrWK4Xe/W+XRSc5g0KEaBHzt5z6N43ps3X2PqBeTZiNiE/B4u8WlzWWkmGZrBJgsYffWt/jqf/trLKxt8u7JI9afc3n89p8wHg1wHMnqxjWqM4vIPMY2glwnDIZ9kDZ+bZWwvES15hMlJ+RpiE5dhOvhlWbR2WNEPmQcKVwX4iQl93M+uHfK997cpl636bZzJlGOEDk723fI0hzLM9i2ReDZuK6N59ksrPr4ruDgcPuTT2sUQnDp4hqWbfMzn3+ZZ248w1xjlvd2HvDbf/hNfu3FGyzM12lUK9y5d4der4/OM7xMMe6fUg1CpAioVn3WNuZATXCly7VnNijPOsyVloAN5uoN9g9PiOKItZVlPKfMTEUw/9Q1PBtUVMKfPKbiVFBRhqcCblye5zvv3uF2t0VYrqJHcLqbsuwF1AJoNJbZ2X2IXxmw4I5RSUwyTLG9EtrOScZNxv0ReTfmBw+O2F/c54VODM0TOoN9HKdwg7SsACtro+UcH9zbYpgKAkeTrSVoI6mVXJaXZ7l+/SK9dpfrT13kyd4xOh6j4i4qndBsJnhri1hSUi0HGGEjbJfK8gYvfuoamxfX2R64WKUQy7Y53XtIHI2RMiesL6FwSYddGqFPveyRZgF4mzgzT2OCKnKmwozzNJ32ADGK8KpV4l5E0u8TjxxyaaiUJa5lYQkLxwsQBq491aB1ejhFQhWstExryqGHlIJK1SacUoHKVZ/VpWUurnweIf7RT4yZT0TggmEh66PcGhvLMwgTsb99n07nFGFb/P7v/S5/92/9EmXHQSmLr/7SL7N9+wOOd3bIUx8cSaNW54tf+Ay2LHCVjmVRqVX40+/dZr+lGceG0TilWirh2TZ5mrD/5CGd5gnLcyUq5RKdzpDLl9c4etzEr1hsPXzEV1aWmGt43N9/RL1mcf3qGkGQcG+3R63qUa5UIXU5uGdTv2ahc4l0LKSVkiURRufovFhDRmqC39/lYLSNPO5hlyok/Q6VUhWZ9RG60BZ0T/Y46Y155qUv8PYjhTEph52E0eiU5tEhcRTx6//HPyHNFSoeMD9X5+b1z/Pa915D5TlaF+o26Tg4QYWZpcvMXf0sdw8nTGwX4ZXotY8ZjsZonWMxYDBJ0I4mjSHOBa5dY3X9Jk51iUubVwjrVYQEnWuaJ20m7SO29x8w6XaYtB9xefMac5sLuFZK2c7JlUO9nFGuWFzYqNN+asLrb7YwOqFS8zFQbDQzjVUWxMYQeDbdoxxPDLHF1id/xsWAFQ9IjebO7bdZWtvkg3c+wAttrs+W+N6tWzRPmwyHMeXZeWaXl7iMzUDX8VoJnhmT5i2kYzM/t0jgObiOzWA0pj8YkY0HdA6bnD7S1Kp1nr5xjZW1VQb9PuWkyfd/8Caf/dwruLbH7s4hy/UlSkGVnjrl+3ffZZTG9KIB7Q+2+Ny1NWxTYuVCRlh3OWjtsra5hhqkoAWOBzLK0HnB8sIYhDA4ZYug5uLXZ4j9lIpbwnHmsTjEZEMQNu78NVQ0wvF8UjVi8+oVrjVCMLB3eMxv/+7X6fW6PL25Qr95wKP9AyrlEhsXN5lfXObS5WvsPdnGIMmMiyVcdKY53HvMG2+UuLY+z5e/UMZs2Px5dx8vDDE6R2gFaoIgJiwHuEGA63Rp1EZMkiEH9/tM0gyblE7fMI6HDDttkn6Taqh55toc62suIhiiVQx5jBTzRGnKwnJANIwolSXzCwGTcc7yss/mhQpRlBG4Nvv7EfONMtIxZFqxv3/KOOnzU3VA/HWNSZZTqjmkvSbfuXWHd+4+ZGG2hpIBJdeh3zrg3mGbL37tlzG5QuiMRjhgcUMSTeDeYU6uBUZY5NogcsWdu1u8+uprhKUy83PLeJ5HEsc82tnh/tY9slxxerRHr9el1enghwJiwf5xk/fef49GPaRzeEpjpkxiLEYjze985x6W6yJ8h/2dU37+l+s0qosc7cbkWqCyDJVkCFEk64UwCAts36JcDmksLuP5q5jcQqlTTNzF+DWcmUvkaY7AIIVDEsf88b/4Ld5u1FhaWMDzPVSeYEnDUafPeHiIkIZ6rcziwiJBGLC6sszh/s6UUA4ogc5yxv0uu3ff5/e/Mc+dQ01YqbL81GepLlxBWpJqfRbX97FsC1u6VJJHuGmf+apEK80ga4LOqPsW7eMh6XiCJfo8dbXB05eW8X2JQJFnaQHNli5GS/aP2jhOxtajFqdtzY1n19jZPmRxoYpWKcvLswSuphRWWVicwbY0D/f26Q/A/tfo6j88PjGBmymN1Ao5ipn3fF5++jJe2iHLEjJX0Np9gCN8TBzx/g9+gI5jZup14sGEwWSEVop2t0O1UiP0XXIB1XIJkY945we3+He+/O+yefUyv/V//yaHhweAwbIswrDMhYuX8FyPPIWdJyd85jOXmZtvEriGuWc3eeryBieHHd4d7dAdxaTjCCcxDIYTXvtmzM9+OefoicPa8tK5AYiwKNRnjkTamnLZo16exeQVkskQLYdg5zheGau8QjJqodKMsFKnOlMnmgzodU7Z33WwbQfLkjiuR+iHlEsVkrjgc9m2TZwqkHw+jQAAIABJREFUvKBMq9UpKpDGoFQOeYqZjCHJcavrdJOQ7YMJrg9S1jHlGmmW0p0IrMzF9Xxs18PVAeNYkMQOSmX0RhH9wZCkUUKTsbG6yGRSIc1SemMPOzkz/f6QwxYEFt12Vhgi+kU5f/fxEQJotjo4tsWTJ0+olB380Kc1aBE4Bse3WFqsFliojxmfnMCNIlSSMeg2ufjMp7F2txjGBksWSPlkOGFmtsrpk4dkJmXcOiV0A/one6RC0p9d4/72+1TDGh2dk0QjsiTmF37+Z9g/POI73/kW7773NqfHR6RJDAJcx2PQ7yFl4ZUQWIJyRSCVzdpalX57yNe++hlcYbHozdLcHZNKxVFzwGQY47kWR3spd97vsDy3MMX8myJ4ZaHzdT2LUiBwRUiSOORZk8wWBJ6NV1tB2FUGJ/cADdYCQRnKgcsLz17j8OiYTrfPKBqRZzlmyqE9PrJAGDzXJYnH6HQMRvNoZ5tCFq0xKkULF23ZzGw+x+LVV3AsBxsLSzpFtsECo22MUegsQ1suSigUhkms6Q1yDBaCGpVKhSQ3VGtlLC0p+TMYX9AZCRAaaQmMUkXfnTAsOAbfK1Ibvg+1GY8gdMlUAaou+5LT9phcFRT1yViTxQmml+J5OeVq+LHx8okJXLc2S4JNO5G43REj49POfbIsYyYM8I3N7t4eJ6enXHzqCkIpdh/dR+gEuzxDNaihJinf+Maf4FmSCxurLCwuMj+/wIXNTXb3jogmQyqVUgEKkRLLcSiXyqwsr+C6DmksWQhmGaeGWjCLqrq0ThIuL64zdtp87pXncB64SOeETjfF9iQzM2UWF+uUyoaqXSEMa6RphOUIgpIg9G2yVOLYNYwUuI4sPBWCOlK4xP0nIByEPUOW9MDUcVyHixsX2FhdYxJFDEcjRuMxUZIQxTFRFE9b8Au3+cODQ3rDmNWlBmurK0ziiLnZClglvLlrzF+6ykwVhBUTmA5WniAtB8dzUXLqlWwMOmuhJinGaRN4HpGdkQMSjTEaIxykEFgGtFSFQaLRQAGmFmIqN55yiF9+6SpBMESrosCQa8E41py2cq4/s8YLnkOaaMZjxWBkqNYcRqMxSZSjtPOx8fKXEpL/2x4rKyvmb/+Hv8IZyss+M2wWoshHyoJpe4atPTtjY6avsSyCsIIfVpDioxDnYuiP+iCdC8SnsOHp41kaY0mD53qFzcT0eXH+WQVbLMsVSZbDmbB6+jmuFKRxQrVS/giZZtoF/NEhfuiv81dBUfrudrsYkh+5QubH/+uHHhbTY0qUEqRpVDz2URKlVmRphuPaIO1zFoRlWVTKZWy70IlkWU6z2SSaTD56xShE8bqA833kHD681h9e51q9zuLSIo7rnl/n8bBDPBmhtUCiCqq5U6JUbSDtwvUzSxMEgiyN+d//13/0VxeS/3UMrTW/98//L/I8o+zb1GpVbM+mPBtSrrqEJRffcxHCQVoeSZKQjDU6t/H8En61yvWbP8tzn/0qZa/wKZDS+qFugbPGIiEKjKjWmlwpUqWJoojHW+/RqFpcu3btnJl7puTP8ozhKCpsniYZ280mdqWMdDykZaPzjIuVCg9uv8O/97Wvsba6Vtx+pxZvAgnTDANTukzx+FQkLwtZ4GQy4Z/85m+irCcIOW0rOtMInhMmxfmXTZgznbI4OwhKeYzaLgd7t4vNlm0XVcEsIu212drtcu3SAtbMYmEYojX1WpXPffpvML+wTmNhhZ0nLb7+9a+jsxyTpUTRiBSNtCSd3gm+W2IcJaRTp3TPCwj8AJ1njKd3h89+7mf4T//e32NlY4OcwvDvW3/4j3nne+9iCYkj+kSjCaXGC7zws/8Zfn0RrTV7O/cI3DIHD26dd238uPGJCFyAXCnyXDGODFr02LiyxPOfvU69XmUctXD8DJWVWFq5zIMH23SPhjhWCYyN53kA04Az52zXs3aT4jnNWQfN2a2s8F5Q3L59m37rgLna5o9l5+bK8O4H+0jbolHzyeMhwi1mDWEcUIosK5GmWRGwOkXp/FyWV/R+nYXpvz6Mmp7StAXoh0ehgeXstM/b1n94zjboaetIcQxtFJYWYDSeiimNDkkIuTBbxvc9bM/D6BzLZHiOPK9cObYNGOZmG6wuLGJpTa/TQlsCpGbnsaBWm2P3qE2a58Rx4Txfr9fRWtDr+dj9YuaeNkgRD3t899U/5nRvSJ5LYjEkT8fYwmI87rG7fZfVy4KgOksWR7hYqHT007WnfwwQ5H8A/kugOX3pf2+M+cPpe/474L+gEM//N8aYP/6LPkdr82EaxzIk+Zjt+/f50s99GdeDJD2hVp4nHyY83tpBWh6XN9dQORhVzESWlOc+ZoapG/l02TD9nRfPG0OWpsRpyv7hIacnJ9gmP/t5z8HMH9JlBFGkwTbM1gRz9QbjaEIyGaOlwLJtEqdMmqYYk6N1htY5oIoZVcvzG3khkRfTdiQzfQRAIJQ+P0emy5vxJCPLFGGpCKzzc5r+Vo348DjFMYtbuTM1IfQdwULawRMJuLPYJc1s3cP2U5LxgEGssGsNBBpLCKwpy0HlGVqliCnnVkpJmidTOwIYjsZYtoXjOKRZwnA0wvdCPN9nvVbDD3zeu3WHwWjCk8d3eO+dtwhkQGA59CY5uRQ4soHrhmzffp3e8T5zGxdJ4gmWzojiCT9tHvcnAUEA/qEx5n/66IuFEDeA/xh4hsLP95tCiGt/kTWqNoXSHmEI5yukrsvRaZ+3br/JtZs3eeH5v0X7tM3b732D2kIJ4wScnpwgs8Lz4cI1g1CK3EiM0EgpiqZJUzRECgxG6yJoVc723duM4pROp4PKUqbcvB+q1ojpDBYnQ/Z275IZkHqDxsIqjXqt6LLFFMbVqSbPc4qOwIKnYNBoBFIJBBohNBoLc0ZznH5UAe4HPcWUmimLbPdJh2//2Q6BN8Py8gxPPeuyvFLibJFxvgIXZ72YZ0FWQEgsCyp2Ti0aYkxCGIxYmi9xcQUinfBGX0M4g0bwgzfe5Ku/uHx+DbI0IUti0jxnkqc4js84zTG2R2qsojlSK4IgwLVLhQJO2oRln3q9hmM7xOOY9mmTW++8xsGTxywvrpFlGVkqiUVAY77BsNMkETGTzgEnRw8JZ+eo1ueYjM59zn/s+GmAID9p/E3gt4wxCbAjhNgGXga+97EfJIquB8sSzK43WL+2wbB1jLMsedy8TaOyTjfeRa6HzKYzTIYZW++/z/Awojo7xwvaEKUFOE9QsF+NXXQkFOcO3XaL8aiPziY8frRNpiFOE8bjhFq52FB9aFxSpHlAMR5lPH31MtrkBCSkJ3egukjiz1KqVMhyTb/XmyLpzwl4CCORCoRJijuAKLD455tD82Ez6Fkn8tm5JonmyUPFz7z8N/nKl36JUuDw2uu/h467SH/CGUChsDP7yLLBFLOj7/vYtkXDHlJyDZbrsb4SMDNT4eFxzK2DISsrc2hcjttNIt8nz1KMLjII9tSse9AfIEMPtCLHIlMSV9iUyiX6/T5eUMayivfmaYQyOSovg2PQ2QSVzWALQ7+9hydtqq7BUjbCKEw0JI8S8AtwniVh3G3jSo9ypfyx4fLTAEG+QNHN+58Ab1LMyl2KoP7+R952BgT50WOdcxWq1Qre9PpXFyqIPKa1f0xlpopbqqOTiO98/+u4JZuZxVXM2EENhszOhjT3BwRZRpyknLa7pEnKqF/wsOfnGpQCFyEFluOxf3DA7tZtTNyhG2k6vR5pnjMaRmxuLAE3PtwPiOKmrhUMBlHxhcgFu3uHLJdyAjFBD/eJ+3VOxwqhcmzUR2a+aQ9S2mE0OAC7jF9ZOncWN0ZgtHV+PaSU55kLLTSWLbh4xWdv5xG99jEHgxNEatN+UkO7UJqNCEpq+jHF0shM/yuceiws22YsQlTmc/PyErNLc1TLIaVJE6/jsPWkhTPbwPU9bNchOwtcrQsmrpQY2wUshNKUSmVIyhjbwvVs0ixlEClGSR/HpFStFFuUGA36+G7I6ckBRliUS2tkqeTw5AS7McswSmiP+sxaiiyK0YkmqZRxwwCVw9HBA4Ts8W+k5PtjgCD/GPj706P/feB/Bv7zv+zxjDG/Dvw6wNLSkklGQ0qNCi9/6Sb99j69J6d4iUWcCZRKGByfYgkb0Sra1huzMzz7hc8zHn6HSccwGA45eOtNjMqIJiOMNniug1v4yuF6LjpPUIMWro4ILRt8CU6ZxPFYbFTOftIi9YbmtNnjte++zre+/WphHp3mWNJhfaHOzStrRMLi0krOikiQluREeIXXrlKFI6NO6Zy+z/Bkh9SUWb70Im5lbroWnbISzmdLc85z0MYgpGZ5rUStUuHWrdeIUk25VKU3TBEEjHoVZuZy3EoTJ9DTTgIzbdaEM5TCWFvMlgLC2iydSU4rM3zv8ZiHh32enAwxjzosLM1x+coaaZad8ydc16Ec+HTHEyajMe1xn8W1dVzHZpJlRHFEnmUcnTQJZhbI0wRXK2wRFz+N1vT7Q7xggOXXCMvz9CZDavUNluYthFSUteGwtcPeaYeoNmTUbGG8CpNkRBimHxs/f6nAnQJB/iXwT40x/2oaeCcfef43KIAhAAfARy1T1qaPfezQEq4/d4mLa0vYC/M8ZJuTkybDkxNcI1BZgTcanYwol0s8tXmRzU9d52qvyfvfuo+wRAGk8ySyVMIVFo4QqCSm4gXE4wHlWpVMx9TLFUa9AV6qWL5Qo/1wTOh+mJkAw9HhMb/xG/8nd+9skaY5QWAzWyvhWg6e5yF86I0z7p8mdPb3+dWv/Q16vU6RIkAhtCGPugxOjhl1B7SGbdzyIvHpgFwVt/nNzUsFamna22x0sUE0WgMaJFRncoaHffYOTnHtwrUximPCUg2drVMaLuNVFIoRSdalXNFF67g0WJbANTm2ikDn5MLj/uNT/vTdA6KsSIVlSUaadwjCkDQttAZaK4QwdHsdOqOYdqeLSIrr16gGTOIhaZIU5te2h0YikLhBSJYmaF14GmdKMmi1WQgCPn/hOt7hEep0yFGakQ47ZMMxW4MJJ7ZFvHeMKzPqK6s4Iif9yB7gx42/MhDkR0B2/wFwe/r/fwD8MyHE/0KxObsKvPEXfU5YCdm8vITtSi6sXiQbDEkHEw4PmkxyyIwGaVhamKNWrxPMVEhDl/Kiix1aReHCNUiT49iS4cEuRAUsRA0GHOxs45dKMO5hLc1wvHfMoN9moWYxOjmktFpYrOZ5Trvd4Z//9r/i0fYOrmPRqJephB6ryw06w4jGXIOnnr6J/fiIXqyJxynl+QvIUVF6lUZjUCiVMIxjEmPYenTEg6MfsHPQpdfrMdeY41d+5Ze4em0TIWyMkh9uzowBUSwbUj2kvmLxdB6yWJsjjhIOTk+ITYJfO6Sy4JJEguO9McNRjytPLxI64FgS3xZkzQ53WymrqxFerYJOU569Ms9IVtAamicnlEKHubmQPMumKUWF0TkGRX15g8ediIovMFrhOZLxaEA+rdwFfoBB47qCcrlEr5uee2GsN7v4B4fM2y4yTRH3HvA2GX/qgVX2WPcqPGgdM3/5IqlwOe5PsOIJFc8g1cd1nP10QJC/K4R4nmKp8Bj4r6YX/QMhxG8DdygyEv/1X5RRAArzaCExoU24MMNcY4k9/QQpIDE5uTZcv/YUG5vrLD5zhepCg+O9R0x6ba5sroDJ8dI+nmUTKpeTrfuIUY9wYZkc6O7vkDNhY94jbruUGNNYiRBqRG47ZKIoOKRpxnvv3ubB1jblMMBzbaqVkJLnFARELK5cfZpXvvSLZH/yR4xuv8dXriwyl/bJ4wijUlApWknGE013LDg+6GOcMrfubnHcGjIcDtnd38OyFH/n7/xt5ufnAUGSphhjkDhAUSkUgFcDecmhdRrT7EQkUrNxLaQ27yCEwfY1G4GN1rN4joeKDHkaMx/kvPLSAg8eW7y9MwQ7I9Gaf/9Xf5XFixcpBTbf/OM/YffJLkrl06WCQasCc2qMpjWcUFspBE9J1kEYA1qdZzDSNMZzcsq+wLVtfN8/T9kFeYa9vkwyGuE/6SLmKizFY35NZIhGjUj4vHh1hQ+GE/r9GGsQY9wuyYLHtP/9rx64HwME+cOPec8/AP7BX3TsH3pPljPs9GFN0bS61C+vU956zIV6BWE0KMOLN5/ldNLhJG/Taw94dOs2WbfHjfVn0MJQtneoBiNGh4p5a5vaXIRtt8iynIuVjHpN4jFB9yxEnBP3M7aaKbJxiVwVbuwHB0e8/v03cW0HKRWh52BLgZASg0QIwYXVZcatY2R8wiuXFvlcGJCebmNpRZ6m5GlCkhjS2LC2dgMpylwIS1QXDlhY3+TBw12272+xur7Ozs4BR8dNLFuS5wqVKyzbR4iz2r9ACotqfZl+s49dGXPl2gKuL0jGgkFTo5RBaxtjDJFj44cp1qDJhUaVudoq858q86w1z1uPx7x56w5xLkkzw+HOFkpLDJCnOUmUoFTxBc5ygTYu3b0dqmubjHrHmIpDbmtybUAJTK4IZISlLVyngsHgee45dfKhozhNJlyrVZi7tMJKKaTaOsY5PuJwbokZZZgVJR7u3SeeqTBHQhTOUHMVKvvRsvcPj09M5SyLI073W0zKY4T3PpdXnuXFX/sVbJUx2toiPu1i0jGtw0MCHz7Y3aWze8oLV69Qr1XpK48kabD7wXcJ+5pKosiHKZNIkOYFMXw8EcRuFVEq467U8cOQSrmE8By0EMRRwt07D5mMR8Ut00CuFZk2JOMYaXuE5SoP7t5jdPgQzy8x6zdIu3s084xMuQx7bZomIs8VrVYLz/OoVwP8wKXjKi5ULJKqy7FQjLtNmjqhVCo6cs/FKqYoUggxzUzg4OkVfv6VlxiMOmwfvMUkG9JtDnlw64TADRhFMXmeMtOY5fr1JZadnEa1hO2G1GfnKVklfnbOZnnWoVrStJod/vzbb1OpB2RJwngwZjKOpmtcwySKcG0b10QcPngPX0c45WXiaEwaT9BKY1sWKosBG9ueKTaGQmHOijnzM5SGY3ZGEf/P1vtcm22wtrDCzJUyO0FIWcPKQkD5oElcqjEuz7A0X2N92cURfd7Yeu8nxssnJ3DTlMc7h5QnDs39E06Xm1y+/hwrC4s83j9CdboEnoupVnj1W2/ieYIvvPQ8Ny5fROUeva5G5yGjSYPxaAy5QkgfZ65GubGEW/FxSx62X8FGgWWjpIvWFnmekgmLDz64x/vv3yFLYsajUZFXlWWUTgjDEuVanUtPP8WfffsHLMxWuHHjKVYuXuO4Wmb33vukSFp3/4xEjAFNlqeM8xykJrIsKknC6ZtvUdKSzy2lePYQoQRiJJBCkGNzZJ6eFiQEGPFhYUKmLM7PIqSidrrKu7d+QLffY76+wML8EqVypbgtOhLPbTJX8/BLZaTjk+PgWxLQvHBtg0E64XBocfGpTdI4whLz1EslvMAlywviomWB48KVi6s8PjhARwnJZMCoY2PpHEsKkiQDKXEsCykFWuekaYTtOEgpeOWF56lXSrz57js4ocOTvT3uP9pi0Ovxxa98hbtb93jw2j4qCNh4foUAj2rJYnlhAVsqBLd+Yrx8YgI3CB0ylTJqKXpHYwZPJjy5/Yj5pVWev3ydxvoMj3ce0Gx1aTguN56/ytNXLuIKmwlFqdOWFgtXXkbohHjQROQxYXUGJ6hgOx6O5RR5T6lBg1AGKfMpNrOQB54cn1CphEjLIkkSskThBi6OLDZp1UqF5Y1VHty5x86TI3IlmF1a5FRViFUCwwMwbaQQeBRFBWlNq1l5TppmWCjKQhDgFQGqCyF2auyiGGwKFdbZEFhYQvL/fvuPef3d7xSajnHOxsIqi/UZonhCfbaB6/oossI302jGSY7l10AUrTy269AfdghtC5ENuXlzmTd+8IDuIIVoRBwnZFlh+lIqlSiHHsL0WWrU6bZz8jwjTS1qtRl6MUyi+NyVPooSPN/Gtj2CIMSybLQALQXPf+pTvPjCp5BSkOYpJ802rVaH++/HPMpTJsd9Xvv6MbZXJ6jUqNXnqNVr6J8mq/DXMQTg+za1eon1hQaD/pCVlQbS1uwdNrndf4/lxTrt7gmb66usraxSm6uhU8gtmzwzU82nwndruE6hDtPZCMv3kbaFNU2XGWOQU2KMVopcGfI8w1g2eZ7h2AVNJwxDKpUKOs+wLJ+l+QqXG4LxwT10v8VoMOb61TUqzoQ/2hqgHxxxYbWE9iSGon0oVwopCl6vVqBNUep1pANSoJiq2JCFPaqwIaewARAfOrpLoxGWYTjsMRz1UUohdECW5Xi2ZKZa5bh9QqU8C5amUhLkQjLOYZgLhlGfSTJC2sU1cEt1JkkKQpMkMZlWWAiSNCfOcjKluX37LntPnpBnKVEWk6QpttI4lgQpGMdpsZkEzFR26vvBOU/3c58tk2tFqlTxRdKaXINl+WyubbC5ssrNG9eJxmMGoxE7R0ccnXboDBKiWOM43seJwz4ZgYsQXH/2Rer1gMVGmVq1gtZFZ+zCesrRUYehSqmtXmd2bQXbrzOJNNpYeG5IlGZAQRzXlk2KBK+GdHyUFGgpyI08J3RPc/RoYZGpnFyDtG1WV5aYnanR7nRwXBfPcZEYSmEBi3vciViZn+WZq8tUKyU2lmewRM6sM8JcuohvjWiaBfqqNC0mTDH9WiKm3graMuegZmEEQhUyRcuWKGMVWgYTFMUJoChICPpxDzt0WVnfKADO0sWzA0YiYxAluOUSTqnQMSsroOteII2qjA4z8sSQZjm2A3muwZ9wEsEk6xBNbBy7iiVLDCPY2dmn2xtgEGQKhHTwfAvXLyM/IsJ1P1KR1cVDOI6L7wUgwHEcmq0uw+Fk2hlypv0o7gbTXzyWJZHSZX1pjeX5JVKlyfNinf3qNz7hskYpBV/55ZcplT1c18J362idMZmkjCcjbrx0Ca0Es5UrJNmEJO/i2BWGo4w0GYLMsFKBX3KQdvEjzdZWsaxip53lmlQVIupmq00YlJlp1GmnKcM0IfB8mEQ8e3Ge/f0DTo4PkTomyyyMFmSTAdoYWqew8/iU9dVVhoMer+3vYlHs/JVS1C9fIfjUlyiXy+cMASHkOUK1oKR/KHQ/U6GdjUkUsfPW27zxxoOpYKd4viiu3Tt/neUIbFvRicYcT8ANHGzVxYpPqZSrPLd8lWvXvsD+7n0enB7R7/exHQ+tDaPRhCQ7mYrwDY4QBH5IUCpx8eI6ndYRg96IL4Yh/1E1wIKiFmJAOy7J5UuktiQ4bmK/+CLqxvVCTfkj0+Pdu3f59vffYDTsY0sLYxR5fpZuK4oLwpwrLgoH+6mIQ0pwXPvHmnqfjU9E4AKsXMhZXPG4vH6Fsvcs2/uvs7d3zOG7hyhhmF9osLDk8ninzcLcPOubG+web3HaHJOZPmI4jxcK3NBFKcX6+gKu46G1ZpQkDKKEKErZ73bwKyHhXJV2qojSGOEHuC24eOkS7faA9977AFckVDwHk2hsW2IMxCrn6YuX+Zlf+Cq/84d/wPs/+D6OVWgC4iRhdmGBq1evsry8jG1bSGlhT6V/li2xZAHz+yjm/2wYY+h0Orz55lv8+fe+RxLFnDE8jfXDUku/bCOlJMsNli9ZWJnFDh3Gw5SLG5f4uRdf4hd+4cv0u0/TPNmjeXpCfbbO1v0P+NY3v8mkN+bosMnFSyt0xjlHJxOq9QpGDVleqBK4Acvzs7xw5w7O2hLi/kMsY4gdj+jpZ9BLDbwHTxikObcGbbLY4HgOpVLpPNi01ty6/S5OCWr1gHF3wpPtJ6SJOtdkFLLioo3fsi1W1tcY9IdkyXj6xQ5+Yrx8IgJXCMHm2mUS3eSkvQPzGZN4SLvZpX0y5tU/PSDOtvH920wmI+YbZV546SLXnlmiUi2D9umfGpJJD5sY45ammxtDnkac3HsD7ZbQlRV6UYu9/UP80k0IZguLpjP9KwK/XMWvzkHaw5ChRRGwRRuR4cLyEmUpKbsOAoUyglzlpFqhKXTFaZqhlMa29XlaTeZgTWfdsz9ns7HWhSQyiqJzZZkxU38FITjTvltSYgTkmUbrHOFaVKtlskwx6edIZRj1BoBBWIL63Bq1xhpXbyiazV3eeOM7rC4tgDmh3XaJYouD9oT+UFOphdy69YCDWYfLV15EP/08yRd/llwJ7LDwg7CQeI6N7fskN55Ct3pUg4A8sIjiwvBFCEEYhgRBgGNb1BccRv0+dskjTePChwMxFQcV19xQdCX7FZtnP/MiraMTHt3fJf4Yj75PROCC4PL65zjp36I7aBMlBtfxODmKeLh9QvO0S5wbtG4hkZwen9AftgjLn8byUvLYw3ZXcByL5OghxivTK5XxHI/O3j2ig8c4M8vk4QJ7pNy1UlYmI+pOmSzPsS1x3uwXBCFhpY5UDvmwg/ANqckp16rkvS62tFFpSq/bIVMK6YYYY5FPAz9OUsaTpAg0u+jAOOvEsESxsZGyeK3AkGeFPWgcxwyH/SmXgPP+ujOxjBAGaRmwrALNrw2O7+GVfKJRRBrnSCTOfKE4E+fdF4bT4x0OD7fptDr0+iM+9cJz9Eaare02g3FGmsUMJyHP3djEtTLGk4is1QFhSE5bqNkZrEiRVQO0bZNJST4YIhyPamMBaSSpKsDPtm1P2+MVM3NVqjOg0hyVT5VrhmmXxofiojORfzJOqJQcuo5ieWOFnbs/WZP7CQlcsIRPvbyAkVDyNtnuvMHBkxGdzoQoiskVxMkEIQVaabYfDNi6v8RTNxdQOsJyHRpXrrF//BjT2ueDo10qgUc9EKgsJUtTLKUwjk2uYgaDIZWwUVSK7LzolkBQCnzqlQqWVUXMrWAJQVoWRG6K15/F21zgUfcJadZmY6VOEi6AVYfM4HolHu4ectgaIi0Ly5JTfWwxq7i2RIocki54VaSBZJp+ynJFf9hD66JdO5pWzRAgraIt3A19kighjQs4sm2IV8Q0AAAgAElEQVRJbAyB50CiyJVCoM81F1prVJbQbh2zdX+Ly1ee4dPPf5ba7DwfbPV5sBPhuAmVmke1XiYoNfjFX/gi3371Ld4+OGCr1aQz6CMePwZtmG00iOOEUqmEkJJhFBMeHtKYazAejxmPxwyHQ1zXxXEcWidN/Jk6q2uL9NrjHwnaj7YjFV9jC0E19JlpVKnX3P9/BK6mR25a2CJn7+A+/Z5PGF7AknuE3gQvHdBWkEmJtgzCWOzvdrj2zALSKpLm4/GIg9M2aTTi5qU19vZPETNlVDYmHXYI4jGuAMvoovqTpdO0lXW+NvM9n0qlgrQKgzth59RLMTXX4FZtxOAuWpT58isXGMcZ91sx+33JeOJj2TZbd76Llg61xhIIg8410paoLMGyLcgzZnw46jepljaYpDHCAr9U4v7d92iEi9NlhEAYged7XLy8ysLyAsM0I41S2u0e0WSEY2saJYfRWINnEccKtGI0GfLB/Xf44P0tHj7cpdM6ZRJNuHThArP1hO/+sz/ipNnF9RziLOEzrzzPjZsXaHX22W1vE2cJaxtXeOGFF/jmN7+B43g8evSQSPaQQnA6HKKUYm5ujjRLkVJydHREmqZYlkW9Xi+ENtKgbI9Yi2K5LovwPHP9/LAbu9jIjkZDxtGQUujRPvg3ZND3b3cYWsP3SDJD8zjjwd2cR48F3W7E2upVDoykknv0Wy1yBEKD63kcHDSJxmsEoYvSit64y/Fpm5rMCbKIkg37Rycsz5QpiQj75C43hmNqRlPTE4zKyHNDZp8FrpliTkNcS1O2cuargo2VEjUjsK0SOjdILYjiCR42L27UcXaH/NGDB1y+tkY+fkJGQqXaxZIOJs+JkpiT01PmG4sszs4TpxHbT95nbfGQ2VoV118gk4JyLUPkZpoispGWYPPiGlc3lpibW+DxUZeHR6dcWN/k2sUaNy9UeXq9wmF7xBt3DxhHOTOziyTZhNsP3+Sf/tbXiQaKWq1OpVrm9q17jEcj4lwjxNnGUXLpwiYztSqN5adoHvTp9Ub84i8+y0svvcQzzzxDnivu3LmDMYZSEPBo+yG5LuAfXhiglOKVl1/hyuVLuL7H3Nw8v//7v49Rmsd3HnPz88+ysrlJtXYP25YMeoPCchaK2VsIoihmbq5Bq9Vka+uQdJJ/bMR8IgLXGMOjJ3vobJF7twSvv/YO40l/Wjq0yY1hd5zTi2MCP0Sbopo0Hk4YDQt+ABLccpnli5tEezscdyJefuWzdAcd8iTm0uWnebj1gNJpj2ccH1v1GY7a5HaZXNnoKboIAVWGbNRSrqw1IA3YWPeZDDvYlmScKEatPv1Bl7BUo1YK6Ta3ePzkMS9PRlz79ByWPyEMwbY0RsGdd0YcPY442HrIS1/IuH59g+eqawS+hYUC2SKP95lZ+P+oe9Ngyc7zvu/3nrX39e4zd5l9BjMYzAAgsQxIkABJiItIkXRELZYiuSSXbUUf4nIq8ZcklUoqUZUrFbvsJHQsy5RkicVQkiXuOwmCIHYMZl/uzNx97dt7n/1933w4fS8GEAmyRMUFvVVTfW9Pd5++5zzn3Z7/8/vHBOuC0IvI511OnznBsWOHyArF2MQkuUqFar2GCptM1aocmZ3gnkk4M1viqYcOIvKj7AxsvvP8FkWrSnvTI0lA0Gen0QKZEIYhpWoNrRMMw6CYzVHKV6mXJtFWzHYYEvlyz2E+zYoFHDt2jNWVZV545vt895vf4vLNW1TLoxSqFYQBs7NzbN8/oFwuMTLSwBv4IGB7aYPzYcKJ04d46LHT7DS3WJyHxuYOhmEwOlYlk7EplsqMT1R49tnzdLt9yqU8qUnVj25vi8AF8AJJMNhkkKxw74OS0HfZWOuwsrRF6A3w/AFaJ1iWiRAQxwFB4LO20mNqXxYnI7Ach+LEHNlskUEcstCLqI/sZ6xcoVipYi4sEEVRqu53DaLGAmZplsROe2xDCKqVEjMjMJGJGR+poUQekbEouQWi/g6m10T5LQylcIojOPkybiZPoVTHth0M10M5isiIwVTMX27y/NNreF7IoD9gZa3J5rv7nH6iDiiSQGKYEier0NokMgWliTwnjx/ig088ymitxL6xSXY6TdA2uWyBl68scnW5Qe9axK2mw5FJl1NTUDQ1bSMlliudEKuQfj9g4PVTja2WgEGYpKX7juNSLBYpFssUi2N0uw1kf0Axl8I51ta3ePr7L3H14i3a7Ra3b11g5fY1WjvbJGiEsPASiZvJE99aIY4dXMcil3ex7CTdpFWANhg/MMvs1H6Wr71GuVjk+lUHLRWzB8ap1fLsP3gPWpi88OJ1DDEAbb5lvLxtArff0UxMFNk3d5T9I/dSyU/gBwMu3XiGp7/5LM89fZXthgQdgxAUSiV8v082B7ZtEfoRq5fWefVbL3Ds4Awnjszx3CsvMlYpcOjgHBw4yMyxk7QaG3T7fTY3N4lixSlTsmMLTJUFNBkLut1NblxrsDIocHhmjEOVfbjZHEG3SRhI2tqib4+TDEyyeZOxiWk+8MEHqddLNLYvYxVDihWBVAatVYnnDdIyeg29ns/K1gZnnRGUElh5a0/OqLXGdkze8a7DWMrlh8+9ytn77qFerLK2usILL1zhgfvvxVAWt2/eojNa5co1iZYBv/LEUWYnPO4sexTyxzhx5H5MYeM4aS+bJDFSKWQi8Dyfaq1CpzvgwMFpZuam2LdvgnzT5pqMAcmt+QW++pWXWVjZIuMWKFeKnH7wSQ4ce5DGzgaRPyD0PKLII58vcvjQEZZXFriydAfLFrz78XNoKVBKsL22xbf/6ps8/r5zHDh4D1nnFuMz+4j7fdCauaP3ISyD73zjaTY3tjCAOH4LoQI/XQVEBngacIev/7zW+n8QQhwAPgvUgZeBX9NaR0IIl5TD8ACwA3xKa73wk47TbvXI5gPOHD7FWPEgtrGPrCM5frxDvhIhDMkzX79OdwDFQpUgjFP9Z9alUCrS2YbxUpkn33eOouswWs7z1LkHuXnxIpcvzTMIEkbyDrZrYvQ1y+vb3Fnp8Jjsc6RUwqydQAO2YVDM5LDGaniNZXaskMNzNZIoJd40+jEv7Qj82ORE4jEzVqFcn2BK78c0BvT8iJwTo6UkUQGPPnSQci3Ht758hSSJKFQyHDgxglKaOJZoKdEIlFYoI12oyMRkeWmbmbEZmq0Bm41tNjc2aXUHLK+12Or12draprWzTeDHJErzp3EPQ0fMTc1y9vQs7cYqSeTxsY9+mJdeeZXJiRG0UDSbbVAGjZ0WSmW4997j+F6X9fVFIt+nVi3R6kX84NnnWVnxKVar5MoJVlaDZTIyPoGbcZm/foFr116k3+lw9v53cmP+CvV6lV/79V/m2PHD3Lx5M01lm2n17vpig7/84y9z+t57ePiRBzl39kFWVxfwwgE/fPYFLr58gVazk2442Db8LdAaQ+AJrXV/WHv2jBDiK8A/JeUqfFYI8X+TAkD+r+FjS2t9WAjxS8DvAZ96qwNoDZ1OC8uVNJsV6oVlTATrnSvcWblMEO2wf2Y/+cI6fd+j3enRbnUxbYNE+igRIJXE9/rEvk+rtcPaZsJstUqSG2NpfYH2jSXKpQK1Uh13coLxSkLpWExz0GPr9hYTXoHDxx/AyRXw4iwy3sEsVClM7aPV2KRYKLPcjLiw7bDJDGE84JDhkKgEP+hh2inDrDqax8ka2LaJY1mEdpv3PHQ/2tM0+03mHigxNlkkShKkVgh06uIu0uRFEiuuvzYgjBMO7Mvx4stXeOX8VUydUB+b4PrNVa7P30GYBraVQxoGSge4OYHnSTwdsbGyxK1XnkF5Ps3lJVobW9x/eJqZuWkqlTJrG02+8b0f4tg2bpKwcOEqtm2BjAi7fWxhcWBulM2NF7j82quURyaZmZmlVKqileDmtdfY3ljk8KEDPPTQQxw7fpzj95zANE16vR75fB4pJY5t8an3lSnnXP7DlzfpexE3rs3z4Y98kD//wpe45+Q9YAmuXbxGa6ePEgbCAKEUMlZofnzw/jQVEBroD3+1h/808ATwK8PnPwP8j8PA/djwZ4DPA/9aCCH0W9L1NMKQKGXSH0Q0vZtU3B6Xr7/M+voylq3xBiWEVcAPu7Q7A4IgImeZBH5AY2sb15ghn82jnQwySdAyIXRscpMuD09NkcvlEFoRRiEKQakMNctGI1IeQ2wT+AFeBOtRifMvr/CxDx7CLU9ye3uDg0mfdTmDmj7KZBgT+w1y+QGrrduopI+dBUwT27IwbYEf+STKwbVMmoNFDp3KcogZ+m6fYOChLQGGQSxlylhQCj9QZFybf/grj2M7gl4/5LWgjePmaO40iXzJ6npqSFgt53GyDuveNmYy4OzZBzBsgUhc5JYk7PTJ2xaD7S1ygDHw2Lp6i20BO56PHAxILJOtW7fxs26a1VMKLQRRtsxDx6f4yNwnuHb1Ouf7PW5ubDB/7Tq5fI6Tp/Zz+Bce5/H3vJtjx44PS5o0ly5fZnH5NvvGJonjCLTGNkxcR2CKNNHgeR47rR1+/uOfIgy2+do3/hKrbJOPc5RGc+TzNq5lYxout883/+aBCyCEMEmnA4eBfwPcAtp6V+r+RnbCPmAZQGudCCE6pNOJBj+uCXAzFrlMlsCPiEPJYvM2G+vbdNsxpmHQ6wpkYpAkBmGYAoPzhSztnT4qdpgY1SSJRktNEoNSEA7LrYWAIE5JNmEQksnncBybJNb4UqKFIINgY72Bjou866FzHBrLUd9/lGvNDLFZoapuo8onyFEk8HqYiUW/1yIxKoyP1ogs2Ak0oe+TcdMKWowYFSaYSZvYlOSSDJ1WDykSLMcim0m9ECzLIIpSq1DXMnjkZBFNzCC0eODYg/i+otOL8YOYg9Nlev0YpTVekjBSG8W1LURUoVbIMjJR5ermJl6UUK6UKOQzuFk7dcIx5bDCQlLMZ1BxAkKhdLIn9SxkszhZk83V6wg3QFU7HDzoMnrfKH4/j+0qlOhSrjbY7F+m+cIiraVtejKm1dsgDFa4uBxgh4eINXzuOx1MAzpeanArlWJlvcGM12Sn1ePGzRV2Nnrksg65nEt9vEA262IIm9uv/YyBOyx2PCOEqAB/ARz/ad73Vu1uIEi5XCKKQrq9ALdpspVr02r3iCMLLU2iwGBjtU+j0aLf7xNF6YXLZB1MI4uSDlIqkkjh2iZSyKHOVWNbqTrfQKAME9NxUaS9nWmaGCpCI4bZprTnGyuZ6NkTLBizdGKJk7SJnDqmUcKMEpSWFFzN/tFJtLIxdUi0s4pwqiAM+p6H5bpYGCQoOvhgGMhsSMFJJY+xTlLMpmGkIA4hcKzUBtZWCstQFPMWhVwOtMVAJQRBxKnjFUJtAy4KmyQRYLjYdg7LcBj0A5TeoN8fUMwWkNrADyUdL8EmreKNtaQXRBgK+oMIHSWQnhUc2WditMB6FfRkHplouq01cr7BXGGOfGkUu+FRbVYYaYS8+OKLdCIILZv81jqT7WVix2P1wQlc1yKbcQFJKWdgCZMwllx8+RkWls/TbKZFklE/RPkx+ZKJ3xHk7QxO7m8Rpa+1bgshvgM8AlSEENaw172bnbDLVVgRQlhAmXSR9ubP2gOCTO2b1EppglDT64UsLK0QJopQmiTE9Ls2168tsrS6hudFSCURQlAbzaEE+H6EAJI4Bm2QdTMYhiDr2mTsIYbesukHIX3fS9OsSmCbBnGiiJMYoV3S/KzGx6FruEgri066ZHVEogsIJ0vi93FtODgxScWFMFEIOaAgA/zQJIwEibLwghjTSFBakctkAPCNmCSOcQyTRKXpXEsrQp2OBkGSUBWCYr5ELmOQqAhhGpgYFHGoFPNoqRhEIabpEETpToGTEZhOBkuYbBmpID7tHcDzBtQLeQZ+DwcwDRMtwLVMbMNEyhhsm6xrgTawjIickXBt4TYbV69jGwbVgebeOy6DoEGgY9rra6xUqwzWlrBabUxhEqIItKJvZzAPHWUiEHzs8HFKMwfwqpvYhiRjJQQ9j30jGb7VErzsh9jershG0+2EaKEIw5hcPvdWIJufDHYWQowC8TBos8DXSRdc/yXwZ3ctzi5orf9PIcTvAPdqrf/RcHH2Ca31L77VMaampvQ//Ce/ghACx7ZRKhnCldM928BTdFoDgiB8HUonoFB0se20yDCXqaBEiiKyzFR5tXeTKJUijhj6I6hUvWIIQSJlyizTJlk3l3pBSEkkBQkmSZzgGgmWodJkRZKgpaSYtRBDsbdWMVrGRFLjxR2kTt7AIDOGuwUanfpDiF1Jn9gFh+2p03JmgXrFGZYTDacc6Y2ObdmYQ0lkikgdClfQSC0whEGcwHajS+x76d+4x3V8U6n2LiiblBZpGqmaxzbAdmx2gog49gEwMTB6EUkcY2qNNE3skVH8Xg/pDV53vAcwLQrVOlnHxo4DLDSGq9BaYmiFawpsS7A5iNnxJEoqkliCFhiWQBhgOwaGMPh///Qvfyaw8yTwmeE81wA+p7X+ohDiCvBZIcT/DLxKCg1h+PhHQ9hdk5Tc+JZNCMH43Dv2dKppMOg96ZvQMMUb8Zq7omOtIfIH5IXkve99b1rWInYByHrv8W7RtgaUDOlsrVKsT+M4Ga5cuZiyts0c29sNrl2/yFajgecHtDstbNukUChimia1SpltmdDYadDudcjncshEcfTgYeYvnQcZYqKIwhBhGri2STmX49ihaaZnplIwiVZ78I0kSZBJCpluyAxPvP+j3Lj5KqZRQCvJkQM5lDFFsVT9a+cuSZKUjWakG/YbGxv8/r//fb7yta+8joEkvTdqhRJnTp4kWykyUR+l122SrY9x5dVXOX7sKN9/8SXuLCxw5r4z/Mav/wNOnjqdCoSGNxskeF4PYZjYtoNtuSlPV6T62/6gz+Ktm7z64vMEScjZJz9GtTbGXRfsDddc7HWamrvIqihSWuTnP/uFHxszP82uwgVS0N2bn79NSmF88/MB8F/8pM99c3OyaYHiHjrzrtKV3bYLcH8jD1ajtcTRMePj4z9SNb9b5r3bOzbWVmhde57Lr77IxNGzHDxxllw2S6M9oB91WV3fYGFxiW6/TxDFDHpdkihMh9h8lnh6P3EUsL6xQd/3sUwTRwgOTM/SajbotRrk7LRHFKZJxnE4dKrGRMlmtGhjZMyh2CRlIsQxJIkmjCWtUJB1NbevP8f8zQtsNwJ+6zenuXS9zrvf81s88MCDCAFJIllcuolOfFTS5+CRs5hWKuQ2Eexsb+MF4Z6+FwGNTCY12ZOSR+8/w/dffokPfehDzEyNcfX6PM+/8AJhGHJw7iC5QoFipYpAYJkWtmOxuXGbz33u39PudMllsxw7cZKHHnwE18lx9dJFzr/4HM3tTcrFPG55gkptlNGJ/Xs9vUClOmnDSCnB+vVORethrR0ptTMMg78DNWcMg1LodEBVb7o/9Rse3oDn1MOeC14vH9nrcYeAZ0SKtdzZXOeFb32RzduXGC+mPLJv/NVfMPvaRQ6eez9Xr1+nNQi4c+cWg16Hfr9HIhOEUqAlcawQlsnS8gpRHKKFQbU+Tru5Rdfvp69FY0YxiUpFMoZlM330fmZmqxw9OoufRIRxRC6bQ2vNndVN5heWiaMYqQWTx0bIZovcc/Q07zr3JEurHn/82T/l59834Llvf5piqUS5XEYM6euXXv0yf/hHX+TEsTne857HOHj0QUqFPKePHefqrQX6Xi+dS1smhWIhFb8rxa21JZbXN7l9fZ5SscCL518jDMO9k+zYFhnHwQsjoiAg6Ud8/7vf4NlnfsD8tUXGqyVe+sGLPPPVrzE+OkbGcSiXS0zdcwzLsdnsSdIuX6aAP5EG6PzyGgf2jWNbNrsORXBX8O52vW9V4svbKXCHQQugRSrb3J367ZmJ6N0ZQjqv400/7969w/9AxiEyidlcXaG/scitSy9y/eolGu0e3lidZ16Z58EHTnH2sUcJc3nWNldZ2twCA2YPHabV6RJEIWrIi42ljxe2MG1FziiQyxUAg+JIncgv4GTtFOShdWoSqFM80uSYy9RoiWK5zMbtGzS9gInRCfwg5HNfeoZkSI8JY8mHD72TYnmEJz706wRBh8roOluNh3np1e/S6fZ48cI/5szZSVToUynUGHT7hH7I8aNbPP29P2Rn8wZhpJmeqHPukXcihYltmRQyeWQouXnnCvv2zbGydoen3v0u7jlykh+8/ALrG6vDeXd69gyRVl5roQgjTWN7g6mJUXTi0O165A3BzTvrtHba/Oav30upWEind5q9C6V1ui2pVLoVZpjQ2NliolrGLJqI4YVNkcIKNex106v3dyRwZbqgT9vuoueu777Lfd2b26LfMGXYbcIwIQm4evE8/vpNiAJuXTtPv+/TbvdZWW8zN17GzuUp1+s88thjnHzkA1y49Brj4yPUJ0Z45JHHmZk9zNe/8wwvX7nEVquJlc0yWsmw05rHcgMsrfC3m4StBCkkbt3FsA0kgsi0sBwbRJrcuPDSy9TjA7TXV8iXslydX+Tzf/UDeoOQfhBj2SZJItNCT53exL6/w5/+0e9hyXmefa5FLhtTKVskW03uXBsw8CKymUW217tkHYvGVputjYDQX6Dl1/na959l3/UbVGo1ysUc46U83V5CP+hQNA3uqRcp53IYIuTMPfeRyRZpt9psd1vki8U0XSvS3ZhBr4vXblCv1/jEJz7K4vwtLAGuIWg2mly7co1Tp45jGeawLMkERDp/lymlXQhSbFMc0e12yGcyxFISy4TAjzCEIpvNw3A5mUj5lqH7tgncdMxIYbZK7850xbDcQ981TXhj77o7N8JIpwjd5havfPsLXHvxZWwr5PTJObSKuXBtEdeysZDsH61iT03x64+8i/sffR9ONgMYVPMlxvdPI2O4dOUmWgsc0yIOQhrdHjKs4hg15ibLlLMWcalLFHl4SYhyBK7tECSSTpSQNw1cxyGOY3p+SOwP6MkAVJk4Uuy0+rS6fbL5HDttjzCKyeVyaDSNrRVuXv4M3fY88/MBo3WXOArp+32qYy79bszO1gAnY2M7gtkxm298fcDUkbM8/PjP8YWvfJfuIKC7sIxYXKacz/AbT53jxNwoTa9A3lYUHRtRmmCrG1OqjnDEzBD4XTYaO+ybnSGJY5YWb3Lx/Cus3L6NY2nuOXOS++67h488dh/thatkpoq8th5w5cJFChmbqelpXNfFMjVaWzQam/R9j4ybpVobZXVznbVmj2bnMq+cfwGFRW2kQmdrg+3NNfLFKnMHDlMfHU+F6G8RuW+PwNWazUuvEZkOrjbIV6tkajXMjEvk+8ggANvCzmQQRorj7HU7AKgkRmhFKZ+j097k+1/6Apee+x7VQpbbdzZZXN4k49jYWlA0DTL5AuPTFTL1MlPHz2IVR9OvAAw8nx8+/yq5chnbyVOs1jk0e5B6sUqrsUNn0GN8ZJyyW2J5aZFSLs++0f2UXBMMRacbYojXzUiU0kipmKjkKeYcMrZFtV4jWWwgpSKTybC6scP0eI2R/WMYtoMhNBtrT7O18hJrmwFbDcG+cRvPttlp2cQR5FxFtpzlxq0evucTeDBZiXn49CHue+BRvvCV77K7GtUaOv2Qb740z8cfv59TR/dx++YCYWLSXN2mNjLOIPDpd5os3LyMISIaLlx49QUuPd/HttLEwfpagzCJePTxd/Hhj76f5neWMaTHRMXim7daXL5wAdtxGZ2YRDvpouvOjWfQpsB1clSro1y5ehuV34+UEct3rjI1d5xrt2/QWruD61jURj12dq6TL+SIwgit3+bl6VoIwlyWtTsLJHdWiBaWyRfLlPftJ/I8GtsbOPUahdPHqI2N0u3ssNPYIUokQikKuTxjD76Da898j6vPf5dCwWVzp0m77+FaIG2TXCaP6WocIbFNk0LWpjzkbe0u6pIkodNp88prr5Bx8zx87r0cOnKUJAixJyzyQQk/CLm2sMmVK/PoyKOSd3nnvSc4fmAKQcRMPsNoLZ9CjwFp2cxUipy87xTFao2NjQZ3ri+z1exSKBaxDJN8xmb/WBnbzWIaJu1OicvXoVIo8PBZn1fP7zCz32Y0b3DlepvJEYPpksnp99fp9yzWVhsMAsWt65c49/7+Xz+/wK31bXYGIePNBkuNJpUIatWDtJttYtMk6LcRRozrOBTyBWJvQL2UI5EJf/aFr3Dhyg0eeccZTt57D9UDJ+lemkNs3eCeSYvlnubq5g43rl4nky9QKhXR2kYh0E4VX0Uk20t40YBIbZHL58jkC+DmyJTqVC0byzJxXBfHyGC6ORzjLUp8eZsELlrT31rFtQXxSAm55dLd2sQvZhCVMqY1Try6gfr+ebIPP0B2eoIkSuj1+3S6fUwz1bL6YcLpB8+wNH+NnWab/dUsWS3YHoRE0YBjczPU8i4DP2LU0HS2F3HLYwjHAZH2kKO1GpcuvkZzc5tvtf8T8VNPMblvjpcuXmZ5fQO/P8DrDei3dhBxyKCledofUK08juNYOEOUvqE1KpHYhmC0XsHNupimwdZ2h5WNNqaAKI4plfI0Oh7hrQ3ymQxzpzUPP/oU9bEJ/uJzf8gr51+i70k2NzWbW12CWGFgsiFMWpeaxKGkXrYZn8wwdeQUrlsiLT00hrsJBvVqmY+ee4iPv/udXL92keZgkAaO8tCRIIxDuu1NdBLw6P0naSqXdrdDvVIgly8wUh/l3edqjI2OsLG+mfK9Tj3J+jcWMUXM2WmX9R5sb2zQ2NrAtC20m6XTHtBvNOlsb+N7IaXKKJH2iPws7Y11RBLQ7vRwK3VM08TrC/JZi25zA5u3Riq/PQIXSOKQOA6RLhj3HiTp+fg9D9pNLNvBGK2w1erTv3SF06Nlzpx9J9vNBq2dBpaWGJbNuY9+gvbybXpbLe45bJDNGNy6s05tdISjhyYYnyhjGhG+srlza42yX2Bk7n5MS4FKxdztndHjX64AACAASURBVCZJGCHQBF6XSxfPs7S8QmFsDC/y2Wk2iAYBSRiTdyySYMD2+ipXb9zg6OGDiDAg7g1IDAOZJFQzNp1mkxd+8DKFQpal9S4ohSkMYt8nW8gzlYdSJiZTyGAIgWW7nLn/XczOHOPK+W8xf+VplpYXkFrT3OnR7cWMVGwmq3mUlCxuheSLMRdf+T6zczOU8xk+/K6zlIt5jsyMc3JunANjowRBSKIkuVye1WaD9qBH1snRDA3uLN8hCmL+4EvfYPbwCe6/9xQrrR7Hxqfo+zEjY1W2W12++91nGR0fwZ06jBg9SrB2jYwJR0YzXNyIWV9aIgwllWmXuSNTYCi61RJPP/M8wslQLJXprC0SNrZIzAjZ6tFtbVAfHyWSAUnHYG7/fsZrI3839nHbPQ/L1limxrFMCtUaplHHsQy6/ZBeN4BqAUyHZhRhdHtkcwUsJ0vkpcOjbTuppjUKOXH0ENKEnUBQyti045hk0MexbA6ffojNxRU2b16mffgAxemjaJFufGeyGY4eO8b8/DylSonZmRm++7VvUJsap1gdwRip0Lc7eP2QOBhgkJAxNCNlB1PovcyP0un8Nghjrr5yg8VakdkDY7z00jxKawzLpDcI6IWS8XwVtASZ3JWGNaiPjHPuiU9x9pGP0G61+PoX/xXf/da32WiVqIyVWVha4eB+yFQNfu0XBMuNHi8//z2OzR7jd97/ixTzBbY3t0ApsuUindUuxrC6duD1GQQ+XtRhxwsxVAyO4NbKFhMzR1AKHMcmDFN9szYkBiZba+vcvHadhx9/N+LQO3j51hbraw2cTIGxCQPP6zFYXMKt7cNAYw/hKe+47wTdgYfn9TFlav6XcWyckSqLCwuY5SyObVLMZxkvZxktOfxonnja3jaB6zpD10RhYFoWCINCIUO5mKdYCpBjGoWV6ge0kW7i2zaO7SDczN7nFKsjDLTNK+dfI5fN4ADlUpHGzjbZyij3PPIBpo+eYv+RPmsXXiFO0qph1OtmGdVKmSOHD5JoGB+p029s09pYJV+pkskV6LRb5DMZtEpI4pjRfRNE0kIqge1a5LIp+UVmbKRShFIR+yGLq028WOE6NpmMQ6fbJ4wjVjeaqLxBvvT6PiaoFGkvwLEzrK1d5zs/eI1nXmrwv/2v/5yP/vwHuX7+23z9S3/Ap//kPN2Ww8PvqvGe9z/G8h3J/tOnSAZdtFui0+nR7rVY22gRhApLSUw7S6AMEjOhkstQcPI45Tp31ltooFotMzUzxbVrN2k0mqwtLxNryLk5rly4xvT+KX7wzW+ysNakH8IDJ4/QbW5xe3mV1qDJgfvSqZIihZPUyyUqxRTAYh+cxjLvQ+l0oX380D4QgiiWZHNZaqUC1o/AVN3d3jaBa2cLBHGSUg1Ni57UdNuSO80mcSKxHZdqOQcIcpkMtuumJ0UpjKGgRmtNplzjqU/9Gn/2R/8PK+vLBN0upk5I4oS5AyeZO56mTK1KliPv/jkYbr0ZxiKQ9kaWaVAul4hjxdbaGipJ0EnCoNnEa3XQQC8IhuIdjek4uLkShmliWBa2awFGWp6TKHyV0OmGrHdD8oagYgnIWIwUM8SJxDUF/URjqd0UTJqiXlu9xfLyFb729Zf4q7/8T3zkqTqnf/vjPPm+J8nmS+w//jBTt5Z4+J19trdbHD/5ixw48F4WF74N2QquWyLWm8hmh8WFFRY3tlhtNGl6PokU+EFAL/CIvQHVI0cplCoprxdBGMX85V98kcXFNY4eOQRxwNLaDoVSHj+RrG/7rLQkKjdGrmDSiW0o7efIO/Zx69o1lNJYpknOtShmM0Oij4GUCseyQSuU0AhhDG/Q101jhWGkVMm3aG+LwNXAajckGi5sBKnnglISjUEum6OSLxNJcGwby8mkPC6t9rS0kJrcSQ37Dh3lU7/9u9y+9CJL1y+hVYBSDpMHDmELkAwxReL147OnJkvJipZlg0q4fvkKjm0hdWpzipZ7LpCWZZLL5xkMBty+dZv8yeN0lUEnNjG1JkxfTqQNlIZISrAMhGVTchxmx0b2enqp9TBpkX4jpRQLi5f4k//4b/GDST7xyV/mqfc/xKnTD5LNpWKbJErw/RDHivjQRz7Jkz/3WzR2mpi2A9kyYd/HyBUJVcLmVpOF9W1WdtoM/ASJycDz2Gw2sd0Mlxc3Ca7cIQhTfUMQBJBIvEGftcijmHcxLYEQikgaZCoTPPXhj1OdmCCMEnZ2dvA9n6WlZawhkdISYKIx9VAVNxTlGAKEaWIy9Fs2xF6GV+tdbrHkrTZy3xaBCxArTZRIlBqysrQGUq5sGIcgIJvJks9mUFrR7fdx7TQ7FQc+9XxmT20lhGBieo7R8X2cOfdeuo11GsvL6f5gFCLszF7Pou86YezmyjExhMC0NPtmpsjlM2xubdLeaREFqRmflXHJ5/IUCiXyhTymaaOU5tD0OLruYjsmYRCnmtggoN9LBTv1aolSsYBjO9iuQ8dLiJIEpTVRpIejRyqFPHzkfv7pP/sX7N9/JCU+GuZd0z7N2voqS6tbfODDn+DnP/YPKBTK7Oy0QUmE1nT7MYaZJVOfRGQyeIGk2fXwY4kWBoMgoFCsYGeyLNxeRqYQBiAFrkzP7adYKjAY9Bl4Hp3BJoVCkcuXrxLqL3L14kU6vS5xFIOS5HMZXNsm51pYdurfhjDSmjrDIIniNBaH0D8pVaqtHhaL7v6OTr2d36q9bQI362QwRLrqNU17GIQapRVxFLOwupb2hKaTajuFQOk0B553bGZHavSHvg17WlitwMxRGD9AcWQGIQReGEP016WPURQhRJqjV3oIXxYGhXwex7GpjdQIvYDA84iSBMM2MQ0L07SxLAvLsjBNg9GpOnJg42ZdtFQgNO3OgJEkIgwTcrkMmayD0FAs5inFkjiSxBK8OO31e70ucZwhl6uRy9WIoogoeqPTYhzH3L69wCc+/imKxTJKQbfbZTAYEPkh27eX8ZRJp+9TLk0yc+I0V5c2EduN1FdNaUzTZnR8gm5/QCGf3xu5XNfFsizGR0cYHxlBSkkUhvSPDYiimFqtTJz0mJkZI0lq2JZFLuNQGFIacxmbXLlMLDVBkIrh0yyoGDIfZEqqFCJ1ut9L8WvUUHSjfoLI5icKyf9ztKmpKf1Lv/zLqUaVXUnC62C0NAk0TO/ePXwMf7Qti3w+TyQTcpZBvpBHIEFYeF5Ar+9hm+CYAqlASo1hCtyMnZooWy5hGBJGCablsOsuuSvgSZKEeGhep/VdB35TcxwLI/bRKiUnInbF4ntkt+H7xRvk3amPb/q3mW6WcqX2Oij5Ln2GAHaxowxv7Nc1zOnnJXFCr9siUeGeS/uuUk5KmQbE3hxJYxopazeKU481AbhOhkK+iO3Ye4qtvcc9JZfeG6XuvhZ7EhklCcLojce7a5dA8KbXk46ySqfwQQT88R9+5mcSkv//3rRWfPlLf04S+ENXQ4gUGEJjmRBHEj+WRJEcDiH6DUP77Ows5971br71wjP83EyBD3/yg4xUA3YGRf7iCy/w+S88zclRwSdO26y3FV+9EGNlDU4/eIhf/o3fYf/hB7l58xbPvnKT2sgRapUK3mBA7PfwOlusb62x2WyChljKveA1hUzxmVoj0Zw5Oo288QPMwQ6OlQEbDMPBtrMp0EWYRFoQSU3oJ/T7PhJBoVggCGI0cOyJp3jqY5/CdlJjk92RYXt9iUIhTyZfAmEN/SWGig5DIJNUkL69ucaf/dmneXHhe0Ntq97jG1imjSksTCt1xTETi+OzJ5kcGeO1W9fZ2FrCNAQHxo5z/wOf4Og9J0mkJojj1PMhjPCjOBW+R1E6UsTDGyJO98FlnH6PoLfGc69epNkJMEwXhLVb9oFhmEOBeoKhJEIFEEucJKahfDAL2ObrupQf1X4WIMh/AB4HOsOX/obW+vzQQvVfAh8CvOHzr7x14EIYBug4ZKygcbOw3VOsbEXYVro6Nw2BoRPKBRNLCFodhT+kv0gpMdCI3gCiEq47hmNsMX/5FZ557lVqtQpJ1GLE8dFZwXqQ0O2Cs5ieVMdxMAyDrc1lzl+7ykh1lGDQRScR6IREKUIFlUIW09Y0uwMMAY6ReiskMWhDobXi2eUY0fcYyYa0+orRksuDx1wa7ZA7DY/9ZYuRvMv81oBOx0fGCtRmWicmNIcffx+maWOa1l14+pRW/sorr/LEB57CstPpCTAUzov0OdtOWbwGWPbu0KtSPawhEIYGkRZmy8hk+dYOC/Mt5vaNMzZVJO+6RDJGiHRkChNJlMQEUUQUJcMeO3XfREqk0sRSEu4FcYxKFHGcYKi07EhKidQxwlBDH4x0F8FQgoyOyes+BZGQ0xInCvBUwsBxiH9CXP4sQBCA/0Zr/fk3vf6DpP69R4CHSFkLD73VAXbhxY6b4R335anQYKVvE0cpFMKyDIo5weyoy1jFQPZNnr0dc3Olx66kpVQs8eiZM4SDbbpxid76MjOzh5meuM7U9EHk1i2UvINEIIf0cNe1EMJK06MISrmEZnub5lY/pSWmKwkYTmAmRyoooNNupyUrOnU/10hsSyMMaAxMZuwc7xgz+arns9BVPGTbNAceN9e73DdWx2s2+eGtNkEkh/aj6RaQbcFTOqVz23cB35RUhFFELpfdK5UxDHPoR5Y+7qFJh4+GYaASNdS87i1FAcFgkLB0Y4P+VkSuXGD6kWlWGvP4nk82m0nZbElCfxDghyFBFCJIIXh5A1xTMPBCPN9LgzqO8YfIAJUoZKLI6deR+lrHoGOESl0yhbDQJmTNkKqOWOy3sLVmznLJhhCi6Hn9n03W+BZAkB/XPgb84fB9zwkhKm8yrP7RX8Sy6PY8otwJ7js4Rn5jm0j26Ptpj+LamvuOuIxYFiteHW9hDdP0SJLUTyBfKuHUSniFEb63tIbBCAdnJjj3IZsglNQPzeB2ClgDD9NdhDjAyTiYlsBI+2sc02es0GPgQz+0SMik+1lao4VAaokXxKk9qmAYdIqcm5DPOFiGQdaUTBYNxgua9027LAdp5ujUdI7jI+MURchmkiObDemGA7RKpx6pgtUYlsmnI8nu/NWyLUzDYGx0DKU1phA/chhNkgSt0jJzA0GiBFIOTVR0mgiII8HSYp+tzRCRaCIv4NnzFxifsDHt1GxFCEEUx/Q9nzhJt9xA02538P0UmR9IOUT6x3heSBimPbGS6d616yi0SpH/iLSK2ff7CKnJ5kcwHIFhK5IkwO97PHLyJLrRYj3sUC5k6HY3f3ZZ45uBIFrr54UQ/xj4X4QQ/z3wLeC/01qH3AUEGbZdWMj6mz5zj6tQKpUYr2Xwbc2VWwN+45c+xOaL36a6fgPbVGmPqEzMwhTH3vkAl7+3wnbjNm7GJekPAE2pXOZg5Qzfu9JG9DM4bp7NgWLm+DuQSnN4/ziZ+JPsD0M+afwpX/zqN6nXR7BMB6XDoR5Y44oIJ9fBtrO0Bxph5PEjScYSCG1w9NBBBn5EIZ+n2+vS6+5QzxlonQ6jE27CvnwWV8CY2aVeiCkM1pguF1jtdNjsRpSqdX7pPcf5429eRChB1jGQMi2vMQ2Rksi5W3sMzXabF577Ib9aqzE1PTsse1EonS4e0yAfiu3FrstP+t69HjgWNFY9/F6CYYBbdDl4fI73fuA9LN95hdb26vA0GERRTK/nEUYRYRgSBAFJHBNLTRRHBGGAlJpBr4PvRbi5ElJplDTTKYOlUEmMTsK0h9WS2B9gaE3g2Ezk65Rcg1Imj9zcpLZ/P+VSnWfmv852r494a1jj3wwIIoQ4BfxzYIMUYvpvgf8W+J9+ms8bfuYeV2FyckJnHMW9pwpsbW2hrRxJIjENTdkxkUKw3ojoDhJKk0e5eet5bCE5frzA9SsJIEikQXZklkxllUEroCPXcEQVPzYRVoWNjuK+uRr7Kwl//+//Ku849yRz+yYolbP0GkvIOCCOJVIYWJYmo33GSiZxmME2HUaqde6/7yyPnXuID77/KTLZLCvrq/z+Z34fv99AyTTQZu47RV22GKzcxMkZ1GtlTNtExBGJhiiW7CysM31E8KvvPkxFeDhaoaSBNFP3GUHae0LqF2YYBkEYc+PKRf71//57/PY/+V0OHDpKutMgSJIYx7HTqcJwWmCaJpaVJgIMI50vb6z2CD3BWLnEsbNnyOWzPPnUE2z32tzyvaFLZLrHGkcJ3sAnCCOiKKTZbNHptDFtGykTpIpRUhDLNLGQzvVjEhWTRAYqZ+APeni9Dk42h6kTSolHMVYUlKQ8UiGHImdbnDx1L6cff5y1L38X1zGJB146QxN/SwmIu4AgP6e1/hfDp0MhxB8A/2z4+y4QZLfdDQv5sW1uymFqv8PxiTqbNy6z3WhTqJUoEKEdl+3BgNbODrcvXqKW1Zw8WmFmWrCz7aabr1pRdDSN+R/y9z729zi0b5ZsxqaYTRctBiauqTB1SDGbJ1uexrUgiZqc/8G3uDi/g5m1UVG6v5m1BLYhcEp5fHecfL7IyfvPMMhW2fD7jFs5Dhw7yaOPvoevfvnP0Uk6pZmqj7PPcJG9RSq1DLVaiUEQ0GgNiA1Nvpyj77XZWlmlUq2j+y2kVriuicjmiNAYppkuaqTcs5eyTYNKMU+nuc2/+Vf/B7/zu/81++cOYJg2rpsZlsswNEqBtHLIQOoEU0h6LYO8PcLps7OcO/cI+8dGWV5ZpV6rsby1iEoCXNclY6U9dRQniL5PEPn4sQTDIl8opIvIocdwFCVpD5rItGI33sHr9ZCihq6WiIM+/c42zsBm3DQYjX0qSpOPYgaDNm69hpPN4QeSS8tbVHM5pmdmmb94ASUMbMf+mwfujwCCvB/4vd1563AX4ReAS8O3/BXwXwkhPku6KOv8pPmtIQQfeewEK2t32Oltc2d+m2oBXFdweHKGm0urHDpgImPF888+S9Q1mRvJofo9pqtZmp6RDvWxT+vmVT7z6X/J408+wbl3PkQxM0beEWSsdEjViSJBkMumAA3HrWPUDrDauMU9Z89QrE1iW4KsbZKxLVZ3fFqeycpmnz/5+ot8/OMfZiKnsbwN4sjmvsMzrB45Qavdx7EdPvmJjyGvfodt7zquKbm4EbAzCDhYdXjhdptGT3Kk4hL0YsL+BkU0tbKNCQwGAYZmz8jPsiyiKEJKyf59UxTyORzLYLvZ4LXzLzM1M4dh3j2l2E19C7KOwBSSbtuk2YzIOnUef+IBqvUJlhuLVOs53vfEk+z4bW7Nv4rjpKRE0xIIC+I4ws60ELIPoUYOQgadFoHfJgg8Ws0GnheRKWYpVWqYjkuz2UaqHGY2dYaMI4/Q75IYBqGbIUSjDRNLAVriWi5kHWTks3F7g2LgYdk2GjVMQPwMgcuPB4J8exjUAjgP/KPh679MuhU2T7od9ps/6QAaaPZiZqYPYBoL1GsJM/sOUxyZYGrfYSanFrl28xKtVo+t7SZFR6Kkw+y+MY5MGVxdNhgMeqimzQOPP8b3vvjnfObfzfPMa69w4sS9PHzPKd556hiVYhaEiWGpFNdkOpimwb2nztD3IrYDA+mUMbTE1wHzd65yc/42TjZP3rEwcpLvfOY6SoUUq6OU8zWmxkcYHZ3EzPjYpqS9dINk/gK+18fXisFAYBkW5XwOlUDBMWn3PKIwYbTk4EtIlKbTS3DL+bTCmTTlupsFlFIyOjHFoSPH8AYDRka73H/f6eH/KZSSe8YhSqVJhKAvmL/RQmBz7Pg+KjWHreYFXr3wLHOzR6hPnEObmu/88MtEooXlDguOhlc5iRO6HRehLDKWR6YQg98j9Hy2NlcIwpDBICRXtPC6bfqhg5WdAMcljBVqiA0QIqUp+Ci2tKYXJhx3cnQGPcLVZSabNg8cPUJvZ4NOc50by3cwTQPT+PEY/Z8qcN8CCPLEj3m9Bn7nJ33uG98DL99c54mHTvOBpz5GsWBQKhWws1WytcOUSqPURkfZ2Npm/tYV7n9wjn5fsbLa4M7aJp1Is7q8zBc//WlqkxPYhRJya4Hbzz7D9ede5AfTs9x/6n7e994nOH54hlohiy1sotintbaO19mmVCqyFXgoEeOYYCrJxtoSna01oijEzeUolwr0O5K8ZTCz7yC5UpWJ/TN0A0nz2jz/X3tvGiTZdZ7pPefcPffK2tfeG72gAXQTJEEClCCYDIubpNHMWJZHsn4oQoxxKGLGjrEth//YCjvCmggvctg/LI8mwpJpzYgS5aFlWRyS4gpiI4BGo/etqmvfct/ueo5/nKzqBheQMhlE97jeiOq8lZmVfU/ml+d+5zvv+35aQ+Py1+neukyQM02U83GNaimPGnQ5Vgq4vdqkLzTlnIfruUStAXGkSVRGc6fHWKa+S2ZvFldK2MwcPs6ZU4/x5f/7L7h7+xbj88eQtqlHOI7ZJkdAtxNz6a0NqiM+x05UCfwB6ystKhMBpRGLVn+dF1/+Cl9LNUsbV0AosEyqoaQx7UiTlDAeECUpKpJ4lkVldI7x6YzJ8TJ37txjaXmb3UZCrjyFXRgl05osjo27+tCYRQgBUpPYgigTbKoQy3aZ9Xw2W00a9YwosNB9qDc7pJ7LhQvvI87g6tUrPzBmHoqdM4Ak7rGytcnczBzSGSGnyogwI+o3iUOBbY0yUi5yaKFMf6Do9naRrs9OS7G00WLykGZnt0acJPzKZz5D1u1x59YV2q0d1jeX+erX1nnz+lucPPcMp05+iGMLM5wot/mTf/7f0Frd4sRTzxAsnCdTKdu1XaJuk9HxaUbHpugP+sRRgrRsZqanydsWC3PznD53nnw+oFIooNKEeysrNKIELQXtVguExC4FBGWfViNhtx1SjxVaQDlQRElKNIjpdDT5gs1o2R02bN7bOND7RX/LdsiVqiTY5CtjRHFsnrPXz2xoPQWmPv3EUxMEOY20InZ2I17+Zp1SRTJ7eIziWMSNxYvGP8zK0GpvX1nsq6zjNKWfGNf0JE5opikbrYScB+OlcZx8D5EXlEem0bgkSWYah2dmo8JwISS2bVGpFCgXSggpWd/dZi0DF5vMdelZDm9tNvFtB+EIsHycoID9KPSAEAIeWxhjYizPIEnZaXToJYK85+B0dpBakfQjdjs96u2UQavDzq7p02WLiFNHyghpIWyHXrvFrddf59N//9/hwoWz3Lx+kc3VVW4u3qUd9VlevImfH2d7c4nrrdd48RtX6HW7UF7g8dknjcOK69BHkAmHVCsqEzP0owGdKOJubZeRUpH42jXubG6S93NUR8p4+QApJHaQp2W57A56SCzm58bpZH2ur9VZ6yTUU0W1YFOqlkFpKgs+JBERoDJNAfY3E5IkwbZNM2adpczMzaM1LBw7Rb/doNNuUx4ZHTZ0uR/wlgWWTIhCC2mBsG2KFcnRmXlOnZhis7FLkkCShXi+QCk59HMwTiwqU6hMk6bGkC6KDPkpyzI6/YSNWh90ieJ4gSxRJHFGqu5/ybLMbM1bloXve+SDIsX8GJ7noAVIy8byfVQYY9kBlgUjlQJBEDAQFnZhBKH32mt+fzwUgQvg56Bc8CgELkql2AjAxhIu0vVJdA4naeH0IRYdpBRMjZcoFTKOT5ZZ7oKwHBQZ3/rWN7h96zZ/55d/kePHTrF4Y4n1pXVsx2GwsYJTX0R0+8yOOEzNVrl0vYuSNijFoN1jc6dmLOE9n3w+D46NKwHbOIhvtTpEsaLW6eBYNp5joZSDoxWu3adQzjNIMmq1NjvtHuWCywBJc5AQKcX4aMDJx+coFvIIoUiT2JTisAgtc+kHUwrbqyzYtk0+l2cwGBDk8nTbDaRtG7WIvp9eGDINdPqASBASpCU5fnaUcd8jiXocnx0ltm1urawTCoXWEVrJ/c2H1M3IMkUcKeI4IkkSksx0wEyHFEytNVlqyntpqkn3AjbT7+BHWJZlyOOOx+TkBN2wxvLyKoGX4/iRo+y2OqSZptWKQFSYP36Kpz/4LFJYvPz1v/6B8fJQBK4AypUCY2MjjJR9pAwYDAYkGnzHJVUhg36fLIqw0gidhhQKAZPjAZUxj0QpLNclmJ9HaIVMQrab2/yv/+x/4Wef+xn+zi/8Ek+cvcC3X/kG+VLAqy++QavWolI8xlNPnWW91iaOU2wp8SyHSqVCELjsbO9S63ZBZPiOg+95OI6N70h816dcKTA5OoqFZPHeNlpowjSl2e1hey7FcolEp9xZ67LVTeipjGpgU/Qd+sNZzLYthJQkaQy2BxjSkWVZ+3nuXvB6nmdm4rjA2PgkxfLI8N0T++R2DaSZots3Jn1Cgm1ZSOlwd2MTV7r83EfOMVMuk4YpS/UdBnFqCC9SDBd4kCnDQUiHfIUojoxVVKrQKkNpQZYZF/gszUiVsZEymxAmsG1LUMgFuLag26tz41YNx1ZMj43iOi5HjkzhbRq3nFKxiJ8r0qjXWb27SG23/uORbH5acHIlbH/E1DERxCrDliFRpFBKYiuFlXUg7VKqVqm4EmFnzE7NUGsprMyjcHiBsXKFnAPd5ibrV67wpS9+iauXr/Ibv/7r/MPP/AdsbG9y8vg5XvrGt/jAM+fpJylSumgl8Dwfyw2wPUmSFWn1+tR3dkiziHorxrEcXM8l8DyCIE+SwfTELEcPHSFOX2d34x63F9e59Oo9XNcm5wjGx8v0ehGDSFEpeNikhEnGrdub+IGD7VioTBkbJmzmjqh38ISlNDb7Wush59dC6zJZEpNmCsdxscQDfIUh5zVMhhZGQhi/YCfFKnpkiUUvhWnP49xjRwlWfd6+dYduZGRTjiPQCtIsJYpC0kyRJAlRnAxbFZh0QCnDpVWZEYWme2nCcCbWWmFLiSWNqVLYb5GiCYp5/JyH1po7N65jWRLteGx3OyY1QzIxMUWz0XgEAlcIcBfYanrYQuIFknpbU3QyhOohhWHLd3s9FB5YLgW3SJLA+JRHqLcp9D3Ozc9SyuXJ+R56Zp5j5QnWIhw+8QAAIABJREFUrt9EK8WXvvw39AchzzzzAWYm57nwxHm00Lx19W0W5g8zPjFGFg/Majrq0+sPCLRkplQyaxZlOBFiyJ0NewNW+wO6nVe5eu0WYT9CKMXAGiUrH2KAwsrZ1LSNyGlGj0jycUqaKSxbogQo3yURgiRO0UKgtEWaaZbu3DApAJClxnha7kuLzGwY9nvEaYptSaxhySzLMpqNXTwnYLZ6hD2DXEvaJmWQhlC0sxVTcRWODSVnnFPTDtvNNolWONIi7xSxpabgGSlU5jrkXMMYY4/4rfaI/uY406b2qrUxWvRdm5m5ecrdCoHn4bkOQmpynksUhvtcDMuyjJF2kpIoyLTi7p2rSPmDa7jwkBDJZ2dn9T/9b38fy5JDDuoek8nAcFLNsdZQr2+yun6PXi+h3mxhWQ4Lswt4pVEYul4bXZNxToyjhEGcIW1r2MFcYFkCx7aI4pR+lJCEA7Y316jXmvtcAbNIArQx1tBSGkmRYvic+3xZ6biMVopsr62RhcYz15EWShvCTMkPyFRGJ4oYaItMOgSeRy7nY1mCJEqI4pj5hVnGJhYA9nPJ++Ttd5K6zfuh35HfKpWQ6BRdncezBJZlOFFRkqC0RGhDJlfSHm4YK+M4A/uEfbu3SyHqUCrkwbJQUjJIUixASkUhF5ClKYNuk3jQGbLXUvpxRJqYdKFQGuHw/ILpQmRZ2I6z/wGqIS9ECDlUtdj3Ba9oEGYW/8f/5D9mbW3t4SWSCyF4/mOfwPe84ZsDYjhbyOHiQoihKiGD3do6n/2X/4y3b93k5tIGvh1w/PgpqnNHCTyPNIpIU0WS9LF0ykjVp9aLCZUgl3dxbUGxGJD3PCKVEUYp63fvsPjKy7z22psmYKUkH7g4lk2pXOZctcS9ZpvdOEWnGWqoXDALEBsrl+cDT55i5e23iWoNAtchsCzQKWMjFXQuT6u+TSdNWOlrLm62sIThJhgSmMKWms/8w88wf+QJEHLf5v8dCx91P1CzbO8223c2j8MWsQ7JznyUzFJI4SCFxFKKTEvC2i4JKU65SqYlrk5R0ibTcujVpZH3XmNi+yqHwxoiXyA88hTNdgffk7Q37yHSNq1mk36zRqO1Q3sQkoaKKM3IUolCs3DM58K5c1TLZRzbxvP9B75kikylQ1Gqi+/5BK43FHuYwA2jiP/wUagqyD1WrFT7ZBEpTXlGiD3RtpG8FItVbNtlZXOD3Xqb6XGPNNW0mgmhJwjjmDCKefnFr9FrbPF3P/0JbC8gCiGOjTFdq5MQeIJeoggsTG80rZCWRmqF1JqK6/Dh08ewLPj07CjfWRJ8fmmLzHYIkwSl2M9F06iPVorp0ghhkuFKgc5iCl6BudEqYRTSlhYVB5KcRKUNkmyPLm26tvuebS61mVG+7kuFtKmxSimGnsF633l979bkxcpcTYQwmjdLY2VGgCmEwFKCRmMHZWsq46NkCFxlhHZm1jUu6dqCpL5Ieu9lcqVZ/MfOM3P6EI3mLiP2BLXtTdZbddZ3d2lFCWkCWSIR2iLNwBIa1/VwHIdisWiYaUoRxzG2bdPr9+n22viuh+f4vHrtVZ5/4eeMbF0YFrS2HgF5OpgEXg4/FCMOlXsiUWD4wSiGCwNFLlem3hwwGCTEcUqqMrqpYrvToT+IWF9Z5OLFS/Qa23iOxSc++QsMYovtdo9Ea2ypmasG6EyTOBZZari1Wpi8rVIq8b4zJzk3WWVupsLRgkt9d51ZT7IUJniOQ5oqKuUCvu+xvlNDK0WlUKHdbiMy8wVxtGmlOlOtcme3h09ElqX7M48p/Jv+bFrbwLDTpBZkDC+rYu8rO1TjSWOCbcyvh81QDOEWhBlbOWdomBYZUmhT8eiFRDsrjExOMOIIlLBAK4Rlm+Ohzi50JDd3N7i7ssUR1aJ64jWe+PinWfDKhPMVRmYOMT19hNbqOpFKqfW63NnZ5l9/6StsrO0wPTbGmacu0O12aAc+juOSZRlJEpNpxWc/+79z69ZNnn3uWZ448ySHDh/GCQKE67DXdEZaj8AGBLDvJ2CEcmJIaROgzUJGK8Xm1g61WoOx8VHGR2eQQxmzVmAJSJOY/iBibX2be3fuEnaMecfrF98mtfLMP/YMkXD2e3ps1fosjHrkJYRyWHu0LTzX4fzpx+h3Gny5tsbvfugf4MR98oHkZw5XuHd5k8wWaFI8oZgql9mtt3BsmyjukPcckkFoPCCEplbfxnJcPnHhLPXtDf7l29dRaq+D0P0fwx41VlBCi/0vqbnvAWEiDPPDvRn/PrlGSIEtBaUhaU6KYQqggQhm52aojhcp5hSpSkmiFN91ECJDDkWddUuQeDbZ7DHqA8W9115jabfJqO0w96ELFMYmyZwAYQdUgNHKGIfOnmG33uQv7n6eOAkBzSDsE8WD4cJxuJWsUk6dPsVjp05y/Nhxjhw+Rj6XRyXZUO1izkHF7y7eeWgC12iT9hYZGWka0x+EtDpG0y+lZnN7l616k/yST9obMDE2xuaukaQ7UlLJW2zvdqltrtKpb5ClIUIYV5Q33nydiDyHTj6xv/hqxZLFesxCUZOXZvUNNkmsWFpaoVzMs9IK+fNXL/Oxs8eYfewMk90Oiz3Niys17EKO40cPU6939rufu5bAy/lgQxKF6HSAgyI3UuKZX/67XPrCn5K7vQTsNeUUmNW/RgzZ03siR6XVfsDeV58NfxegxfDqhFnMJnFMFIb4Oc2Y1FiWGKYckiSJ6A92qRSgZENJZSgpyByFZyVIIfYd4UOpGB+dRDiSTuiwWU+ob+3gnzqBUpLOVoN+GpHmPS4vLzJtTzOyq3nfiXO8Mvbq/jnmczkKhQJoSb8/QGhwhOTc6TNIIfA8j163i8oUbhTh+z7Sdc344+hd4+WhCdyd3R2Wt7dottr0+gP2ppedeh2B4OjCDI1mm916jU63g4pNwd6xLRzHFOsHvR53F+/RD2Oa7QaZNuYSQgPhgGtvfZOgkGP20HHKOZ8TIw6Vss9by1u0uj0jm4kTPOlSrE7ilSucnX+CF+8sEycZn/nURxncvcRHj43THCS0Es2n3vckf/KVb6O0WUgVcwHWkBFlSUHY7aFQfPBnPkJlqopfzPPz55/k0vo2tW73gR4dGmOXp0kwl3/j5aL325Vq1JBOkA3zfVAqJRoMiMOIKImxLRuLiIoMARDKMqpclVHOerSaG+QKARWhiNKYjAQrM0mI7xg5uqNTtnYG1DYbbEeSRPts3VllsxNxbX3b1GW7fZy4x73Lb2Arl3EnoDgzzvvOPcm95g5qaPqRpikqGzal0UaC7tr2viwpS1Oi0MzQSmWkyqidB+EjEriXrl3mrWu39pvneZ5R3t6+eRdLWqgopl6rUW/UiZMeldEJFg4dJo0iJNDuRVy6c5tONyQcNEn6PZSwhvxWsByLsVKOCbfP8/M+br/JvcvXeGlzk+tbbY4tzJuFSZoiPIuo3yNVGZ1mDaXh+vIab95e5oRIWSj7fOLoKJNHjlDKCbxCEZWZpsu2Y+MkDlFiOmAOlGClZ1bxJCFNv8yTx0qcnxrjW/ciBkkEeuheIyQPZrN71BetY9KhxitLEyzbiCXjMEFrgbRtitUAP00J+002Nu7wp5/7I7Y2txgfncD1PKbGp8lpher1WF++S7uxi5OvEGcax3Vpt1qMj44ThiHNZptMaWYWjuElgvpug05NMJXPMeJZ9MIubhZRbTQ4pyXCsRnoAen2GqpcYW6iii0EURQZk5YkMbo9MC2htMZ13SFJ3lRNVJZguTaQw8JGJI+AP67SmmvXr9Oot83iwnYZ9CSOZTFWHcG2PPqDyHhrqZTA97FsydGjR5ifnuTOzWt0wwErzR3mu002m7uQmtajxVLAwvwkH3j6Aqcff4wgX+Klf/V5ljZqrLfq3F3eJEk0o8UcIssQAgqlEl4uIAxjgsDGK46R9lv86Zf/ht/42Sc4c+gY2l5FeRZ/9e03WVzbptvvk6mMOEloNGo0O23COGa702JlkJBEMWLQ4/Gjs4S1Fh+cm2S50Wa3b9GJIvKuw9HqCJYwUkfT1EKTxSG3r11lfX2DqB8jpcRzLSamJqlMTDE2No7l2mQqQ2ozy4UpXFrt0dvpsL2bMDE+ziCUBGmPas4mrK1yY2OVtHyUlnbJXJ9BqvDdAJVmTMsOW5trjJUrzHoFilnIdCnH+0VK1XLIKhMUZ31aL9cJag0Sz8JKTW1YdNt0w5S1E4okTYceZHvbySbctNYkydCfIU2wbItcvgCWUWBbwnrAtfL740cO3CGR/DvAmtb6U0KII8C/wHRGfx34da11LITwgD8C3ofp4fsrWuuld3ttrRRXb7zFznaXIJdDKYXreriOTbO5S7MZ4gcFzpw9TYJFpxvS7O5Q360xVi1TyPsIDZUwZmrzKpuVOcqnDvHMhae48ORZmrUtvvP6i7x69TWayqd+awnPLuL5kizOKOVzTE6MsrW+guPZpimI7yGDKgiXSA8oBHmaaZOv3V1nanScu8LjL775OncbmlbYQRRdsAS3NzdZX16l0e/RT1PqYUQhlyMd9Ij6XdIwIup1OLVwiE9GGc1BNHTgsUiESS8Yqo6zTHHj2i2uvnWVIBdQqVYZqY6Qy+cZHR2lUK0OS02ms40c2hq5QYWpiTM05FW+83/9MZMTY5RHKlRyLs+9/ymCfJnJ6YwIizDx6DpFhB8YX1+nSxpnJolWMZV+gyBLcfsdyq+/QivwUeVxrLBFurNDgoRU0M4HhOUKvgMxmgxT/ootiUoTXMcBhJHza+NBEScJg37H8DUsSc62SeIE27FN85KfROAC/wi4BpSGv/8e8N/r+718fxPjofCbQENrfXzYy/f3gF/5YS9+7eYi2zt1skyRzxVxPWeYv0KnHWP3YvLLa7iBj2PbrK8uYduSjHmKXgCAcCp0F47z889/hCeOHWPp7k2+9JW/ZmNtl5W1VaI4JEw0aebSJiTnSrTUFEs+Y5Ui9ZoxouuHfcKwj+MIBvEGfl4hc+NMlgKWd7a5urrBZ1+9zmI3JkoihCMYry4gbYe3N3dYXN8kG1YMcp7D6fkFtOWx0x5Q31iDKGZ9+Taz5TLFoIAjjVuM9P391qb7tklaMz6/QKVSYqRSYmJykkKhYGyb1N4ibo+SKIa7XxmJ7CPclKizzXJ9FWE7eJbD1Te+w8T0DKVyjtFiiVq7jzc2hfQLNNs1lO6SK+YJcjbrm3ep6hLV1EV3jVpXacWVzVUuKIFXHsEtJNjS5tbYKNdKPhNac9wOUAKu37jB3NQkk+PjDKIIO9PDXskp4WDA6uYyrWaNyYkZhOWjtG2MRbyUKPkJVBWEEHPAJ4H/GviPhjqzF4B/b/iU/w34L4aB+4vDY4A/A/4nIYTQ77K3rIFGs4fRG0r6UYdBYvxVXddBaZt2q8bOd7ZNHmmZmqPrOSytrnDs8DRPnx5Deg5hMMpb336FL3/hL1nf2qbXj4e7OaZ2irTMRofQQ48EMxMIocGyUY5DIlOQESgLlXZAFVBCIFRCpmKubGyyq0Lcko+KNJlK6SVdwyHIMuK9RaEw9pmzJ57i4r0OzZ0bTLU2mKmOURqZIKhMU4gTdDKgHyv6gBL3N10C3+PChfN0uua1S+UiruMi1VASI4aEc2GZxZulzPZxklDfqqN7IVIIY9KHRqWKVpJw7lwFbJswTmjubpPrNfCLLuVynkIhT851yeXL5NwuXq+I7CTYI7NMjlRwU3jp7bepTlV5qlRERgN0omlkNtdvrpIVioxNuMRpymc/96eUcgHnzj1BvVaj3+3z93/5lxkfH+Hu4h1ev/QGaGi2Q/pRwtjYKJa0yOdLRij5EyDZ/A/AfwIUh7+PAk2t9V5NZ887AR7wVdBap0KI1vD5uw++4Hf7KjiVGMdNcVwX13X3tzbTDFKVIF0QtjAkZ23sKgdhApYiy8qAptnY4dqNNw0Fb2igh7aGgWkNNzgEp4/PURkp8Mob14wMfk+24mgSXxlVsKNJlEMWzBGMH0HKhH7rOhthRFZrMj1eZTPsM1Bgacs0p7OGXl4PlFzjLOPa4jL1Lly6+CWeHivysXN5/HwVpM38/DT9wYC19S1IYlNLFhpLmAZ5wrPw/er+jCqEQA7zP0MjNDpR08ldkViGFG5pifBL2LZPGHdNkOuEJO/y1p1rTDk+Od9htJzjxOmTZK5icWeZtbVljk2e4MSpBbIJl+6dkCZdHC24cWORXR0zNlphub6D12yTxBHbccRuvoLvW/TtjC0XXJXR7nS5ffM2d+7cI4wi4igilwu4cOEJ3rp4kdcvXqJYKLG6vsXWzhaH5ueQUjIzM0t1dOzHc7IRQnwK2NZavy6EeP6HPf9HxTt9FaZ1cTQgUzZxYiwt0xTD7VRySJiWpGmGkOA5Nlon5DyLJBXMThURaNqNOt0wNityPbS1FHu7TMalxbE0LzzzBJMzVS5fW6Td7eM49pDrakpNg0gT9mLygYU3sUAYdYjDBk4Y0+pHaBlyolSkFw1oCYFjOaZv73BvXcO+jMYWgsXFyzSaO4Rhj8WmYnG7zkRphMCPGRktkyQRSsV0unUCrbCQ2HvbtJbp1LhnpCSFQMv7BBuZSWSWYWlIheHxpr020eomg14LmxTPEQjfohLksKpFZg5Nc6RcpjoxQqQzljZW2KhtMkj6hu8wGqGyIko7dIsdtvop66sruElMlsQUCgGX44SbtqDd7dDu9cilKZXRIvmxKYrz0wjXRQ6Vl4MwQg1z1hdfepk3L12kPxiwU2syWo3oDnpmS7zVIfB9VJaSpD9+qvAs8AtCiE8APibH/X2gIoSwh7Pug94Je74Kq0IIGyhjFmk/OIiBsB/SDxOybM8bVaKVIaC4ZAiVgBA4XoqlBa7r8eTjeZaWmtR22sxUEsLODoE3dL4BkkySkWJhUciB7/qcODTJU2cX2Kp3qJYCkjimXPTwAw9LSFzLwVaSpBcSiz6NSy9hyZCRYgm0xYg9QlkEiK5FspVhO4LYC3GE8z380b1ZMgy73FtuYUuL5TRlsdHCwmJc5GnW6jh+Di/Io5sN834IQ/KxhSF2S9vMokaHtbfTNgxcoRFagSXR0kJYgoKTcWq0TVxMOPaRpxGpohF1OTw3h/Zs7KJLe2eT1+9cpNXrEg1bl4pM74sctRa0W102NtbY3t5hcWmJaqGIY0uybouFE4fJ5XJUKmWKhaLxyM0X8FwXITXNfmaIQlqThtFQMZHSXdswGyt7TmayyW69xsrqGo2FFocPzTNSyuO7PrzLnPujqHz/M4xrDcMZ959orf+BEOJzwN/DVBZ+A/hXwz/5wvD3l4aP/8275bd7SGJBEg9XnSjT29XVTE/nKOVztDsx/TCmNOJQq8VUyzaBA4fnC/i+T5ZGjBYTvEqBJEpBCAahRgG+5zBSdDh+aJbnnznP0+eOcOX6Co+fmCNwY2bGctiWqW6QZqgoIdIxrjPASSNsKYg7XULl4joutuPQzSImggLpIKPhKFM4/z7DVFrjWxZCWgyimE6SsbS7RU4nzE09ifTySNfHLdhEfgsfsIRCooZ13WxIPhJIjGvP/v+jTUphCOMmP3EtSblc4ejRw8aGiQypFT0ds7W5wZ2lRe7evEev3yK0E6TSpEOmmczkPok9CDwmHzvGzMw03W6XD3/oaQpegGMb/4VcPkCIoQQdTC1a22Z7Wdz/YmVZhhpaoGqt+G6f406nZ64sUnDlxi12Gy2kFtiW824p7o9Vx/1PgX8hhPivgDeBPxze/4fAHwshbgN14N/9YS8kheBjH/ow2bDLDJjFk+dIigWT70aJHpbJLAZhiu/ZBJ4h4ji2jU5zPPPUeSSaTCnDLNNmP19IU/geKRdY3hwQv3KLMAw5dfIEExNjuLZDlsLxucOMlUcgVbhCYrs+KMO4kpZAYKEBMwFKXMeiEsUklgIJpaDACy+8wGAwGI7B5KS2NGlLOvTWzTkOI4FPq1Cm77lYtkPoWiTZGBrF6q03hq6LJj0Qcq+xx94nubdJcT+I93wMjH4tpd7oYEkJOkOj6EV92u2IUmGUc7mRIZlI3d9K3g8SQSlXpj8wV78s00g7wPOt4Sa1BRriXvZdi6dseFbmipBmmueee45+v/+A3P7B5z9g8rzvDm9UHPkgILZz7xozDwWRfGZmRv/ar/3a9ziyfDfu+8XyjufZts3hw4f58Ic/TH13l2a7jZ8LmJ4Yw/EkprQM7DtrfS8uX75M2l3nyFwRlaYkqSLKIEkM+cWwsATSsgw5vR/z9sXLPPOR8+SCHFJKXr60AY0mvk5AmUBNtUKlhlNg2QJHgiXNpdjsmGVEUYplQ4qg4Y+gHlA7/P8Zf/AHf/BwO5ID+5zNvUvVj4IHAzmXy3H0yBGuXbqMUIJKscL6yj2On5jj8NHjWLZnpNE/wNZnY2ODbrbJaMljEFn04xQizfrSCqtrm5x9+ixu4JqZMFPcvbPE2somCMHEeB7PdfCubyPJyOsUKSyUpWm1W6xu7mBZCsdxGMmXKFbyWJZNkmDuVwqpFKmQNH8i7+a/+XhoAteUwN5JHn7HDKsfvNH3502x/w9Kaza3t+l2QsbGJlhdb3Dr9iIf+mCbc09dwA5K/CAIIQhjqHViBmlKFMbEvZi7l29zd3mV8tQko2OjhK0OzUadK5duUyrm2O1EjIYKf/hOWtLCQhL2B7Q7TVKVom2FijvUGwm7usH5x8+Ap7Eci3avj9YWOVdi/YCrwQG+Fw9V4H7PqvwB5ZkFaGmRZspI0OUe6fz+hy2FRZQKnHyOTr/HzPQ8V692+OJXX2Rrd4fnnv1ZSpVxhNwbth7+uXmNOFX04swYIqeClaUNGs02C+OjXH/pIsWpcXKuxaDXRSgzyyuliOIEpY3XlSVN/7EkS1BujrWNTXY2thi1MtJ4gO/47Ny7jV8sEIcp3W6DuUNVZDpF9A6l3QHeDQ9V4H4/2I6NdBzT6C6zWVldpl1fZ2J8jMnq2NBwwtQINZqR6ggvvvRNXnnpqyzMzfGB0+e5txRy7eIdOp0Gzz33s0zPHkNKd5iW3F8mZFqTKUmSJqzcXOWtl6+gVEo151OQkkGrR37Cx/M9iqUyuZEyTi5HlEI4NMrYqDepFMssbm+wc+8eKo0QAioTZfr1hM4g4t7KOp4n0KnGLxUYq4zgewnrnQHocQ4m3h+OhyJwxZBU/N3wfI/5owvUuwNcr0CrFdMFEjpMHJtn6+4mh2dmSFPTAyyfD/iVv/dL9Go7/OXn/4yXr98gXdzk3NQh7IEgrpb48l9/kbNPXuDck+fxvDxCWPdnOWE2KQa7PV7+m2/juwH9fpdBPmBkpMKbV++wvSGZnp1lY32b7WaNQycPI0aKZuUvBMvLa7y0/holz2ai4DHIbEYqOWbHcmQ+dDpdOolmYapIK7W51Yc/fvEmx6ZKrDU6HHrfPLb7Q+y4D/BwBC5874xr2zZe4JNJB+nY5P0ib778Nd64dBGpB5x7/Ak2dxuMj1Qp5EzQKwGLayt8683LrHZ6pGGfN7fXaVk+ut/j50pFqvPTfONLX2Z7d5MPPPMspfK48WkFQJNEA9586XUazQ5nT01hWbC6tsm99S1y+QJKKlaXV6ntNBEu7K5tsjBdQWgXgabg25ydzuFKh+1uRiokXs5nJB9QrPjILCSMIzZ7ileWmtyudTl9/DC5YgW1Fb7DP+EAPxgPTeA6roO0bAI3h+0HVEojeJ5Hqxsy6uaJen3u3lomH0zTbDX4i//zZQaDjDDe5PThcUZGRshSzY2byzz7/EepdZvcW1liZOYIWthsZDF3//UXKV94jplKjpUbK7S3/ooz557k+JnHh7VGQThIWLy7RH8woNFo0umFZJ7HY6cPI4QiiTLu3V6m16pTnarSbdZI4gi0qTuu1DoUVcp8VTBRskmdArYb0BcFpioW6BZrGzZfXdxgoCxeeP/T1Op1PvfFb1GsVDiC5iB0fzgemsCVlkujJVgLQwr5mGatx1urEb3aOqXApdVqM1A5bC+P7UscL8DzFe1Ol82tOqdPzjIYDPjqi99gc6uF1A5zUwuMZJpPvfAR6v0G6Z//Oc7RI/SSHtHKKv0oZTG/yMzho6aCoQXxIKG5WyPqhgghWF1b4fRT57BcSd6xKI2VsbWm2w85fnKBkdEKSlikqWET1DoR7UGXkldhdtQFKyNX8MiNTVGTNrdv1bmzNWBmco52v8tLr1/k7buLdAcRs0lClinsdzdxOQAPUeD2un3+8q++RWYJnnvqKFeWFvnqq7fZqa2RzzkcO/McTq6MnZjOVdEgRJOwvvg2RWaAcwxadcTrr3BqYYGp2XHU1cuMNBs8MVkmcse4mplWpfnKLF//7P/Byfe/j5NPnN/vWZaRYWcpo7ZNa9BD2pojx+epVPJYCHr9lH5vl34SMzEzRaGUI44VluMw7LbBiYV53nhjm5Vaj5yjmZkoYqkeYb/F5e2IXuxy5PAkd1a3+fobV7izsUXJ9/ngiaM8ffakaax9gB+KhyJwtda89p2X2Vi7BkJxfbDE3ZVVGrUO49UygZ8niyNyBWl2roRAZdDrNvCdPu3WBhpwBhEfbHXJuwJJTNhqMClthI7xggKtNMHvtclKY+h8nnbUo9NuGSNigCRCtNp89PwzfKH/TcLBgKm5SYRUWLaN4wekg5iRqsCyO2glKI9UkJYkE8aX4f2PH2VjeZH2oM9ON8Ox+0zPV0iTPleuvE1m5bDmK3z74hXmx0b5yJOnOTo5zlSliO3a3LUk7879PwA8JIEL0G422dlcJopCOpseiTbs/+c+8iyj1QleevMeAkWWDplGWhH3Wnz6kx+nXts1wkLLZmekwrX1XYTrYlemSEZL1F97g9Rx2Qxjxvp9SCM+PD/LTqtJe3UZkSUoNI2tXd545WWmZJmfe+I8K506UXOA5TtEShAEAUkWk8sXGC8WmPQCDk9PII2ZFxoIfIfzZ07wrYuV6mAZAAAGHUlEQVRX2ehmJEmXRGwwPjbKY4eneP3mJs2OzwsXHufJU2dwpMIVClQGtoN4dwOXAwzxUASuEILnn3+e27dvc/fuXbpxMrRh0pSLhkpX9DN69UV2ajs89thJXN+ht7WLylLOnTtnXqiUx/23/y30Zg0CG8cNSCpl/vjPPkevH5LrdzmxsY6favqLS1hSs/XKW1yujqMPzZIPfGbmJom6CdqWvK9yhCxT7IY9Wu0IHSkOj1RYEDkqYzkm/Bx+P2XXSXBGzOIsjGOOzk3SjSKu3F5irZcxrj3iMGaiEvD+M0f56nfeZn5qnMW1LaaqZcZG8kidoPRBAfdHxUMRuABnz57lV3/1V/n93/99nn32WU6ePMnVK1e4dOkSx44d4xc+8TxL95a5eCnkYy+8n1zg89aoz+1btzh58qR5ESV47Kn38zgS4cDu7g5ZnLLU7pMpGHVsnNe+hWvZiDTlbZHQunuNyq1DzMxNMTZW4dTkOTZWtui0Um5tN8gLh8PlMqcDj4JlmF6OBQVL0LU0Tr2N5WtcqwwCokjhWJqnzx6hVPD45uuXeWu1waGJEl4j4alzZ/hksURvMKBayuPljEduHA5IU2F4Nwf4oXgoAlcIcxk+c+YMv/Vbv4Xruti2zblz52g2G8zNzTM2PsrUzCTPfPjDBIGPLSXT0zPG2kcpms0mhVKRwHf53f/yd6k36ni+T5qm2K5LFsYMpORaGJPPWdzLu9wdmMdmzz+FtG2cIGBqfpzCWJWVxQ1WOy3WW13eXNtk3A/41Q88gZMl+OUi/aJLb6yEzLtYBR9p2UZO1O9TqeYQKI5Oj3Loky/w9Tcvc3Vli/efPkOpUGa8WqHb7yKFQimIk4RwEJFmDgQc7Jz9CHgoAhdM8E5NTfHxj398n7+5R7LZa+YxFMV8919Sr9f2m2YcP3aM6ZlpVtdW+dSnP41lSRbvrfDaq9+h69h8Lkk4fniWoFhkMlWcf+o8jz37IW5cv2as5z2X4ug4C65HYbRAbTdkebVOt9bgy8uLHK2OIhp9ypMlLB9G5g5j2TZxZurAuXyeRGk8x8L285DEfPwjH+LsxjZhqtms1RkfLyFtnywNSVJDQE+VRZju8VkPIveH4aHh4/72b//2uz7nu7m4D2LPHM7zjEV7r9cjSRKCIGCvG3mSGjcVMZTD7LUatW0b23FIkwStM2xreK3eI2grYzKsMmVMN4REYAzmLNsa9hkzoRYlGULpfd7PniXongOhZtjPQe7lA/r+fzVc3B1wce/j3fi4D0XgCiE6wI33+jx+TIzxXUrmRxAP2xgOaa3Hv98DD0uqcENr/fR7fRI/DoQQ3zkYw08PB9elAzySOAjcAzySeFgC9w/e6xP4CeBgDD9FPBSLswMc4G+Lh2XGPcAB/lZ4zwNXCPHzQogbQojbQojfea/P5wdBCPHPhRDbQojLD9xXFUJ8SQhxa3g7MrxfCCH+x+GYLgkhLrx3Z34fQoh5IcRXhRBXhRBXhBD/aHj/IzUOgHd2Jvwp/2DEu3eAo4ALvAWceS/P6V3O9WeAC8DlB+77p8DvDI9/B/i94fEngP8Hsy/xDPDKe33+w/OaBi4Mj4vATeDMozYOrd97lcgHgNta67ta6xjjQ/aL7/E5fV9orb+BsZR6EL+I8QZmePtLD9z/R9rgZYxB4PRP50x/MLTWG1rrN4bHHYxR9yyP2DjgvU8V9r10h3jQZ/dRwKTWemN4vAlMDo8f+nEJIQ4D54FXeATH8V4H7r8x0Oba+kiUaIQQBeDPgX+stW4/+NijMo73OnD3vHT38KDP7qOArb1L5/B2e3j/QzsuIYSDCdrPaq0/P7z7kRvHex24rwEnhBBHhBAuxpL0C+/xOf1tsOcFDN/rEfzvD1flzwCtBy7F7xmGvTv+ELimtf7vHnjokRoH8N5WFR5Yud7EVBf+8/f6fN7lPP8E2AASTK73m5jeFl8BbgFfBqrD5wrgfx6O6W3g6ff6/Ifn9RwmDbgEXBz+fOJRG4fW+mDn7ACPJt7rVOEAB/j/hIPAPcAjiYPAPcAjiYPAPcAjiYPAPcAjiYPAPcAjiYPAPcAjiYPAPcAjif8X96FZHQ1tlIoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  car  deer  ship horse\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQgKbVemD4bj",
        "outputId": "7cf0f54b-d28c-4ace-deb3-598929679d6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.5294, -0.4118, -0.3412,  ..., -0.4980, -0.4588, -0.1451],\n",
              "         [-0.6078, -0.6000, -0.5059,  ..., -0.4431, -0.5216, -0.3647],\n",
              "         [-0.6941, -0.8118, -0.7725,  ..., -0.4902, -0.5373, -0.4510],\n",
              "         ...,\n",
              "         [ 0.2471,  0.2078,  0.1922,  ...,  0.0980,  0.0196, -0.0275],\n",
              "         [ 0.2706,  0.2392,  0.2235,  ...,  0.0902,  0.0510,  0.0431],\n",
              "         [ 0.2863,  0.2549,  0.2706,  ...,  0.0980,  0.0980,  0.0588]],\n",
              "\n",
              "        [[-0.4275, -0.2941, -0.2392,  ..., -0.4118, -0.3647, -0.0588],\n",
              "         [-0.5137, -0.4824, -0.3882,  ..., -0.2941, -0.3882, -0.2235],\n",
              "         [-0.6000, -0.6941, -0.6549,  ..., -0.3098, -0.3804, -0.3176],\n",
              "         ...,\n",
              "         [ 0.1686,  0.1373,  0.1373,  ...,  0.0824,  0.0039, -0.0431],\n",
              "         [ 0.1843,  0.1686,  0.1608,  ...,  0.0745,  0.0353,  0.0275],\n",
              "         [ 0.2078,  0.1843,  0.2078,  ...,  0.0824,  0.0824,  0.0431]],\n",
              "\n",
              "        [[-0.5922, -0.4353, -0.3412,  ..., -0.6471, -0.6157, -0.2941],\n",
              "         [-0.6627, -0.6471, -0.5294,  ..., -0.6157, -0.6549, -0.5608],\n",
              "         [-0.7490, -0.8667, -0.8118,  ..., -0.6549, -0.6627, -0.6314],\n",
              "         ...,\n",
              "         [ 0.1529,  0.1137,  0.1137,  ...,  0.1137,  0.0118, -0.0588],\n",
              "         [ 0.1686,  0.1529,  0.1373,  ...,  0.0824,  0.0431,  0.0353],\n",
              "         [ 0.1922,  0.1608,  0.1843,  ...,  0.0902,  0.0902,  0.0510]]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dataiter = iter(trainloader)\n",
        "#images, labels = dataiter.next()\n",
        "print(images.shape)\n",
        "plt.imshow(np.transpose(images[1], (1, 2, 0)))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "pT-kfRbOrbDd",
        "outputId": "cbb4fe33-d295-4996-fe07-22ca33aa5f31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load Simple Model for CIFAR10"
      ],
      "metadata": {
        "id": "_kuN_xsegPEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dropout=0.10 \n",
        "output_dim=10\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__() \n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 2), # conv1\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 32, 2), # conv2\n",
        "            nn.BatchNorm2d(32), # bn_32\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Dropout(dropout))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, 2), # conv3\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, 3), # conv4\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Dropout(dropout))\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, 3), # conv5\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 128, 3), # conv6\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, stride=2),\n",
        "            nn.Dropout(dropout))\n",
        "\n",
        "        \n",
        "\n",
        "        self.fc = nn.Linear(128, 500)\n",
        "        self.fc2 = nn.Linear(500, 72)\n",
        "        self.fc3 = nn.Linear(72, output_dim)\n",
        "    def forward(self, x):\n",
        "\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        \n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.fc3(out)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "rPQDFU1IgX9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9afcNbDknklV"
      },
      "source": [
        "# Mondel training and validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCEGucgPAV94"
      },
      "source": [
        "# a map for the class\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83wg4pWx_39f",
        "outputId": "e8a4a46b-b055-44ea-f9d6-7d4e327c035f"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UH9WFziwALmi",
        "outputId": "9ee6061e-512f-4f31-b1fb-77f0951172cd"
      },
      "source": [
        "convNet = CNN().to(device)\n",
        "convNet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (layer1): Sequential(\n",
              "    (0): Conv2d(3, 32, kernel_size=(2, 2), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(32, 32, kernel_size=(2, 2), stride=(1, 1))\n",
              "    (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4): ReLU()\n",
              "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4): ReLU()\n",
              "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4): ReLU()\n",
              "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (fc): Linear(in_features=128, out_features=500, bias=True)\n",
              "  (fc2): Linear(in_features=500, out_features=72, bias=True)\n",
              "  (fc3): Linear(in_features=72, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RptyJfqUAOCK"
      },
      "source": [
        "# Define a loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#optimizer = optim.SGD(convNet.parameters(), lr=0.001, momentum=0.9)\n",
        "optimizer = torch.optim.Adam(convNet.parameters(), lr=0.01)\n",
        "#optimizer = optim.Adam(convNet.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTqA9FjhLPZt"
      },
      "source": [
        "Function for Training the Model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gbuwmcnAPyb"
      },
      "source": [
        "from statistics import mean\n",
        "def train_model (model, optimizer, EPOCHS, train_loader):\n",
        "  train_loss_list = []\n",
        "  loss = 0.0\n",
        "  for i in range(EPOCHS):\n",
        "    print(\"the %d th epoch...\" %i)\n",
        "    for k, data in enumerate(train_loader):\n",
        "      images, labels = data\n",
        "      if torch.cuda.is_available():\n",
        "            images=images.cuda()\n",
        "            labels=labels.cuda()\n",
        "      optimizer.zero_grad()\n",
        "      output_train = model(images)\n",
        "      train_loss = criterion(output_train, labels)\n",
        "      train_loss_list.append(train_loss)\n",
        "      train_loss.backward()\n",
        "      optimizer.step()\n",
        "      loss += train_loss.item()\n",
        "      if k%100 == 99:\n",
        "          print(k+1, 'mini-batch of',i, '-th epoch','train loss :', loss/100)\n",
        "          loss = 0.0\n",
        "        \n",
        "    train_loss_list.append(train_loss.item())\n",
        "  return train_loss_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHSVoowqASJs"
      },
      "source": [
        "# Save our trained model\n",
        "#PATH = './cifar_net.pth'\n",
        "#torch.save(convNet.state_dict(), PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sYIeRpzAT7x"
      },
      "source": [
        "# load trained model\n",
        "#model = torch.load('./cifar_net.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPs1H_neLen9"
      },
      "source": [
        "Function for testing the Model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4RUeIYpAXzQ"
      },
      "source": [
        "def test_model(model,data_loader, training=False):\n",
        "  correct = 0.0\n",
        "  total = 0.0\n",
        "  # for plotting\n",
        "  num_true = []\n",
        "  num_pred = []\n",
        "  letter_true = []\n",
        "  letter_pred = []\n",
        "  #\n",
        "  with torch.no_grad():\n",
        "      for data in data_loader:\n",
        "          images, labels = data\n",
        "          if torch.cuda.is_available():\n",
        "            images=images.cuda()\n",
        "            labels=labels.cuda()\n",
        "          outputs = model(images)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "  if not training:\n",
        "    print(print('Accuracy of the network on the  test images: {} '.format(correct / total)))\n",
        "    return (100 * correct / total)\n",
        "  else:\n",
        "    print('Accuracy of the network on the  training images: {}'.format( correct / total))\n",
        "    return (100 * correct / total)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy of the network on the  test images: {} '.format(50/100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvTFtgqJn3vo",
        "outputId": "d9be374a-e80d-43bb-ff73-44ec676538f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the  test images: 0.5 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMct5SC9Li_n"
      },
      "source": [
        "Apply Trainning and Testing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWE7NSLElq-L",
        "outputId": "2e3c4c65-357d-468a-e413-9a6dde70386c"
      },
      "source": [
        "optimizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Adam (\n",
              "Parameter Group 0\n",
              "    amsgrad: False\n",
              "    betas: (0.9, 0.999)\n",
              "    eps: 1e-08\n",
              "    lr: 0.01\n",
              "    weight_decay: 0\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MO_qN0PJAYhd"
      },
      "source": [
        "#scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.5)\n",
        "#scheduler = optim.lr_scheduler.ConstantLR(optimizer, factor=0.8, total_iters=10)\n",
        "def train_and_test(times, epoch):\n",
        "  loss = []\n",
        "  val_acc = []\n",
        "  train_acc = []\n",
        "  for time in range(times):\n",
        "    print(\"Training for the\", time+1, '-th times')\n",
        "    loss.extend(train_model(convNet, optimizer, epoch, trainloader))\n",
        "    if time == times-1:\n",
        "      train_acc.append(test_model (convNet, trainloader, training=True))\n",
        "      val_acc.append(test_model (convNet, testloader))\n",
        "      break\n",
        "      \n",
        "    train_acc.append(test_model (convNet, trainloader, training=True))\n",
        "    #val_acc.append(test_model (convNet, testloader))\n",
        "  return loss, train_acc, val_acc\n",
        "  '''\n",
        "  num_times = np.array(range(1,times+1))\n",
        "  num_epoch = np.array(range(1,times*epoch+1))\n",
        "  plt.plot(num_epoch, loss)\n",
        "  plt.title(\"training loss vs epochs\")\n",
        "  plt.show()\n",
        "\n",
        "  plt.plot(num_times, train_acc, label=\"training\")\n",
        "  plt.plot(num_times, val_acc, label=\"validation\")\n",
        "  plt.title(\"accuracy vs training times\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  '''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Tqox1Qrmzsq"
      },
      "source": [
        "def draw_graph(times, epoch, loss, train_acc, val_acc):\n",
        "  num_times = np.array(range(1,times+1))\n",
        "  num_epoch = np.array(range(1,times*epoch+1))\n",
        "  plt.plot(num_epoch, loss)\n",
        "  plt.title(\"training loss vs epochs\")\n",
        "  plt.xlabel('epoch')\n",
        "  plt.ylabel('training loss')\n",
        "  plt.show()\n",
        "\n",
        "  plt.plot(num_times, train_acc, label=\"training\")\n",
        "  plt.plot(num_times, val_acc, label=\"validation\")\n",
        "  plt.title(\"accuracy vs training times\")\n",
        "  plt.xlabel('times')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84CWvn_mnVTX",
        "outputId": "1cdd26ae-1247-4af3-8238-f899b300894a"
      },
      "source": [
        "loss, train_acc, val_acc = train_and_test(10, 3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for the 1 -th times\n",
            "the 0 th epoch...\n",
            "100 mini-batch of 0 -th epoch train loss : 2.2543905460834504\n",
            "200 mini-batch of 0 -th epoch train loss : 1.7438404476642608\n",
            "300 mini-batch of 0 -th epoch train loss : 1.558675490617752\n",
            "400 mini-batch of 0 -th epoch train loss : 1.4120349752902985\n",
            "500 mini-batch of 0 -th epoch train loss : 1.3244819337129592\n",
            "the 1 th epoch...\n",
            "100 mini-batch of 1 -th epoch train loss : 1.214234978556633\n",
            "200 mini-batch of 1 -th epoch train loss : 1.1750989270210266\n",
            "300 mini-batch of 1 -th epoch train loss : 1.1534900671243669\n",
            "400 mini-batch of 1 -th epoch train loss : 1.1221298956871033\n",
            "500 mini-batch of 1 -th epoch train loss : 1.0748437887430191\n",
            "the 2 th epoch...\n",
            "100 mini-batch of 2 -th epoch train loss : 1.0271512746810914\n",
            "200 mini-batch of 2 -th epoch train loss : 0.9987900632619858\n",
            "300 mini-batch of 2 -th epoch train loss : 0.9723154044151306\n",
            "400 mini-batch of 2 -th epoch train loss : 0.9372647851705551\n",
            "500 mini-batch of 2 -th epoch train loss : 0.9227344208955764\n",
            "Accuracy of the network on the  training images: 0.69654\n",
            "Training for the 2 -th times\n",
            "the 0 th epoch...\n",
            "100 mini-batch of 0 -th epoch train loss : 0.8571814036369324\n",
            "200 mini-batch of 0 -th epoch train loss : 0.8864511382579804\n",
            "300 mini-batch of 0 -th epoch train loss : 0.8519088762998581\n",
            "400 mini-batch of 0 -th epoch train loss : 0.8418339556455612\n",
            "500 mini-batch of 0 -th epoch train loss : 0.8317359101772308\n",
            "the 1 th epoch...\n",
            "100 mini-batch of 1 -th epoch train loss : 0.7932214561104775\n",
            "200 mini-batch of 1 -th epoch train loss : 0.7872806847095489\n",
            "300 mini-batch of 1 -th epoch train loss : 0.7778251457214356\n",
            "400 mini-batch of 1 -th epoch train loss : 0.7964143317937851\n",
            "500 mini-batch of 1 -th epoch train loss : 0.7693171721696853\n",
            "the 2 th epoch...\n",
            "100 mini-batch of 2 -th epoch train loss : 0.7005569970607758\n",
            "200 mini-batch of 2 -th epoch train loss : 0.7311236199736595\n",
            "300 mini-batch of 2 -th epoch train loss : 0.7387513864040375\n",
            "400 mini-batch of 2 -th epoch train loss : 0.7352284479141236\n",
            "500 mini-batch of 2 -th epoch train loss : 0.7104467982053757\n",
            "Accuracy of the network on the  training images: 0.77878\n",
            "Training for the 3 -th times\n",
            "the 0 th epoch...\n",
            "100 mini-batch of 0 -th epoch train loss : 0.676433724462986\n",
            "200 mini-batch of 0 -th epoch train loss : 0.6858772712945939\n",
            "300 mini-batch of 0 -th epoch train loss : 0.685664887726307\n",
            "400 mini-batch of 0 -th epoch train loss : 0.6802321907877922\n",
            "500 mini-batch of 0 -th epoch train loss : 0.6989603903889656\n",
            "the 1 th epoch...\n",
            "100 mini-batch of 1 -th epoch train loss : 0.6408709487318993\n",
            "200 mini-batch of 1 -th epoch train loss : 0.6656516325473786\n",
            "300 mini-batch of 1 -th epoch train loss : 0.6710685539245606\n",
            "400 mini-batch of 1 -th epoch train loss : 0.6410124337673188\n",
            "500 mini-batch of 1 -th epoch train loss : 0.6718330296874047\n",
            "the 2 th epoch...\n",
            "100 mini-batch of 2 -th epoch train loss : 0.5955463469028472\n",
            "200 mini-batch of 2 -th epoch train loss : 0.6111951276659966\n",
            "300 mini-batch of 2 -th epoch train loss : 0.6320518696308136\n",
            "400 mini-batch of 2 -th epoch train loss : 0.6243186375498772\n",
            "500 mini-batch of 2 -th epoch train loss : 0.6164410287141799\n",
            "Accuracy of the network on the  training images: 0.80268\n",
            "Training for the 4 -th times\n",
            "the 0 th epoch...\n",
            "100 mini-batch of 0 -th epoch train loss : 0.5651936513185501\n",
            "200 mini-batch of 0 -th epoch train loss : 0.588056053519249\n",
            "300 mini-batch of 0 -th epoch train loss : 0.5943460524082184\n",
            "400 mini-batch of 0 -th epoch train loss : 0.6021946769952774\n",
            "500 mini-batch of 0 -th epoch train loss : 0.6128573140501976\n",
            "the 1 th epoch...\n",
            "100 mini-batch of 1 -th epoch train loss : 0.5704768615961074\n",
            "200 mini-batch of 1 -th epoch train loss : 0.5365227961540222\n",
            "300 mini-batch of 1 -th epoch train loss : 0.5880596601963043\n",
            "400 mini-batch of 1 -th epoch train loss : 0.621703394651413\n",
            "500 mini-batch of 1 -th epoch train loss : 0.6044271114468575\n",
            "the 2 th epoch...\n",
            "100 mini-batch of 2 -th epoch train loss : 0.5269603475928306\n",
            "200 mini-batch of 2 -th epoch train loss : 0.5319953432679176\n",
            "300 mini-batch of 2 -th epoch train loss : 0.5723462781310081\n",
            "400 mini-batch of 2 -th epoch train loss : 0.5457450211048126\n",
            "500 mini-batch of 2 -th epoch train loss : 0.5517172765731811\n",
            "Accuracy of the network on the  training images: 0.81604\n",
            "Training for the 5 -th times\n",
            "the 0 th epoch...\n",
            "100 mini-batch of 0 -th epoch train loss : 0.5060787683725357\n",
            "200 mini-batch of 0 -th epoch train loss : 0.5318372771143913\n",
            "300 mini-batch of 0 -th epoch train loss : 0.5618670052289962\n",
            "400 mini-batch of 0 -th epoch train loss : 0.5323823118209838\n",
            "500 mini-batch of 0 -th epoch train loss : 0.5349626079201698\n",
            "the 1 th epoch...\n",
            "100 mini-batch of 1 -th epoch train loss : 0.4967429453134537\n",
            "200 mini-batch of 1 -th epoch train loss : 0.5035271739959717\n",
            "300 mini-batch of 1 -th epoch train loss : 0.5365059933066368\n",
            "400 mini-batch of 1 -th epoch train loss : 0.5268564131855965\n",
            "500 mini-batch of 1 -th epoch train loss : 0.5224001982808113\n",
            "the 2 th epoch...\n",
            "100 mini-batch of 2 -th epoch train loss : 0.4621888867020607\n",
            "200 mini-batch of 2 -th epoch train loss : 0.4855738979578018\n",
            "300 mini-batch of 2 -th epoch train loss : 0.5149596673250199\n",
            "400 mini-batch of 2 -th epoch train loss : 0.497300588786602\n",
            "500 mini-batch of 2 -th epoch train loss : 0.5221769630908966\n",
            "Accuracy of the network on the  training images: 0.83506\n",
            "Training for the 6 -th times\n",
            "the 0 th epoch...\n",
            "100 mini-batch of 0 -th epoch train loss : 0.4551658724248409\n",
            "200 mini-batch of 0 -th epoch train loss : 0.4921758097410202\n",
            "300 mini-batch of 0 -th epoch train loss : 0.4860913646221161\n",
            "400 mini-batch of 0 -th epoch train loss : 0.4992020684480667\n",
            "500 mini-batch of 0 -th epoch train loss : 0.5048507630825043\n",
            "the 1 th epoch...\n",
            "100 mini-batch of 1 -th epoch train loss : 0.4392396704852581\n",
            "200 mini-batch of 1 -th epoch train loss : 0.4715988764166832\n",
            "300 mini-batch of 1 -th epoch train loss : 0.4705997559428215\n",
            "400 mini-batch of 1 -th epoch train loss : 0.47786157310009003\n",
            "500 mini-batch of 1 -th epoch train loss : 0.48557091504335403\n",
            "the 2 th epoch...\n",
            "100 mini-batch of 2 -th epoch train loss : 0.4289309391379356\n",
            "200 mini-batch of 2 -th epoch train loss : 0.44215633705258367\n",
            "300 mini-batch of 2 -th epoch train loss : 0.4805769142508507\n",
            "400 mini-batch of 2 -th epoch train loss : 0.446483059078455\n",
            "500 mini-batch of 2 -th epoch train loss : 0.47438219204545023\n",
            "Accuracy of the network on the  training images: 0.84228\n",
            "Training for the 7 -th times\n",
            "the 0 th epoch...\n",
            "100 mini-batch of 0 -th epoch train loss : 0.433567156791687\n",
            "200 mini-batch of 0 -th epoch train loss : 0.44999409317970274\n",
            "300 mini-batch of 0 -th epoch train loss : 0.46207451343536377\n",
            "400 mini-batch of 0 -th epoch train loss : 0.4221476189792156\n",
            "500 mini-batch of 0 -th epoch train loss : 0.45659736916422844\n",
            "the 1 th epoch...\n",
            "100 mini-batch of 1 -th epoch train loss : 0.404258466809988\n",
            "200 mini-batch of 1 -th epoch train loss : 0.4296333935856819\n",
            "300 mini-batch of 1 -th epoch train loss : 0.44925918892025946\n",
            "400 mini-batch of 1 -th epoch train loss : 0.44533594205975535\n",
            "500 mini-batch of 1 -th epoch train loss : 0.4277346992492676\n",
            "the 2 th epoch...\n",
            "100 mini-batch of 2 -th epoch train loss : 0.41198141157627105\n",
            "200 mini-batch of 2 -th epoch train loss : 0.4047465418279171\n",
            "300 mini-batch of 2 -th epoch train loss : 0.4020515407621861\n",
            "400 mini-batch of 2 -th epoch train loss : 0.41755459159612657\n",
            "500 mini-batch of 2 -th epoch train loss : 0.43908076614141467\n",
            "Accuracy of the network on the  training images: 0.86824\n",
            "Training for the 8 -th times\n",
            "the 0 th epoch...\n",
            "100 mini-batch of 0 -th epoch train loss : 0.37216492265462875\n",
            "200 mini-batch of 0 -th epoch train loss : 0.39676380783319476\n",
            "300 mini-batch of 0 -th epoch train loss : 0.4039480485022068\n",
            "400 mini-batch of 0 -th epoch train loss : 0.40921254485845565\n",
            "500 mini-batch of 0 -th epoch train loss : 0.4256572000682354\n",
            "the 1 th epoch...\n",
            "100 mini-batch of 1 -th epoch train loss : 0.35873537227511404\n",
            "200 mini-batch of 1 -th epoch train loss : 0.3931003855168819\n",
            "300 mini-batch of 1 -th epoch train loss : 0.3878907088935375\n",
            "400 mini-batch of 1 -th epoch train loss : 0.39980051919817927\n",
            "500 mini-batch of 1 -th epoch train loss : 0.41514764964580536\n",
            "the 2 th epoch...\n",
            "100 mini-batch of 2 -th epoch train loss : 0.3885877645015717\n",
            "200 mini-batch of 2 -th epoch train loss : 0.3910503752529621\n",
            "300 mini-batch of 2 -th epoch train loss : 0.38894453093409537\n",
            "400 mini-batch of 2 -th epoch train loss : 0.3974944758415222\n",
            "500 mini-batch of 2 -th epoch train loss : 0.38890484020113947\n",
            "Accuracy of the network on the  training images: 0.87632\n",
            "Training for the 9 -th times\n",
            "the 0 th epoch...\n",
            "100 mini-batch of 0 -th epoch train loss : 0.3756819814443588\n",
            "200 mini-batch of 0 -th epoch train loss : 0.39249971494078634\n",
            "300 mini-batch of 0 -th epoch train loss : 0.3758558462560177\n",
            "400 mini-batch of 0 -th epoch train loss : 0.3799416135251522\n",
            "500 mini-batch of 0 -th epoch train loss : 0.39181086599826814\n",
            "the 1 th epoch...\n",
            "100 mini-batch of 1 -th epoch train loss : 0.3628524908423424\n",
            "200 mini-batch of 1 -th epoch train loss : 0.35976687118411066\n",
            "300 mini-batch of 1 -th epoch train loss : 0.3735064424574375\n",
            "400 mini-batch of 1 -th epoch train loss : 0.38107727497816085\n",
            "500 mini-batch of 1 -th epoch train loss : 0.3646507593989372\n",
            "the 2 th epoch...\n",
            "100 mini-batch of 2 -th epoch train loss : 0.3582881323993206\n",
            "200 mini-batch of 2 -th epoch train loss : 0.3717687475681305\n",
            "300 mini-batch of 2 -th epoch train loss : 0.36350971668958665\n",
            "400 mini-batch of 2 -th epoch train loss : 0.3778667098283768\n",
            "500 mini-batch of 2 -th epoch train loss : 0.37303870350122453\n",
            "Accuracy of the network on the  training images: 0.89032\n",
            "Training for the 10 -th times\n",
            "the 0 th epoch...\n",
            "100 mini-batch of 0 -th epoch train loss : 0.3368700040876865\n",
            "200 mini-batch of 0 -th epoch train loss : 0.33875948265194894\n",
            "300 mini-batch of 0 -th epoch train loss : 0.3549823547899723\n",
            "400 mini-batch of 0 -th epoch train loss : 0.3665061232447624\n",
            "500 mini-batch of 0 -th epoch train loss : 0.36969778180122376\n",
            "the 1 th epoch...\n",
            "100 mini-batch of 1 -th epoch train loss : 0.3248347045481205\n",
            "200 mini-batch of 1 -th epoch train loss : 0.3602202695608139\n",
            "300 mini-batch of 1 -th epoch train loss : 0.3389974483847618\n",
            "400 mini-batch of 1 -th epoch train loss : 0.3463447591662407\n",
            "500 mini-batch of 1 -th epoch train loss : 0.3669550637900829\n",
            "the 2 th epoch...\n",
            "100 mini-batch of 2 -th epoch train loss : 0.30822350561618805\n",
            "200 mini-batch of 2 -th epoch train loss : 0.3335802638530731\n",
            "300 mini-batch of 2 -th epoch train loss : 0.3421574033796787\n",
            "400 mini-batch of 2 -th epoch train loss : 0.3432388623058796\n",
            "500 mini-batch of 2 -th epoch train loss : 0.3821915519237518\n",
            "Accuracy of the network on the  training images: 0.88982\n",
            "Accuracy of the network on the  test images: 0.7714 \n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXV6vrbynYKJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "outputId": "50b17fc7-4eb7-49fa-a1b1-bd54bf04e3c5"
      },
      "source": [
        "draw_graph(10, 3, loss, train_acc, val_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-548e56507ee9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdraw_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-35-760ea47f3d0b>\u001b[0m in \u001b[0;36mdraw_graph\u001b[0;34m(times, epoch, loss, train_acc, val_acc)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mnum_times\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mnum_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training loss vs epochs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2761\u001b[0m     return gca().plot(\n\u001b[1;32m   2762\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2763\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1645\u001b[0m         \"\"\"\n\u001b[1;32m   1646\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1647\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1648\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    343\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (30,) and (15030,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX2GCW9PXu8e"
      },
      "source": [
        "'''\n",
        "def draw_graph(loss, train_acc, val_acc):\n",
        "  #num_times = np.array(range(1,times+1))\n",
        "  #num_epoch = np.array(range(1,times*epoch+1))\n",
        "  plt.plot(loss)\n",
        "  #plt.plot(num_epoch, loss)\n",
        "  plt.title(\"training loss vs epochs\")\n",
        "  plt.show()\n",
        "\n",
        "  plt.plot(train_acc, label=\"training\")\n",
        "  plt.plot(val_acc, label=\"validation\")\n",
        "\n",
        "  #plt.plot(num_times, train_acc, label=\"training\")\n",
        "  #plt.plot(num_times, val_acc, label=\"validation\")\n",
        "  plt.title(\"accuracy vs training times\")\n",
        "  plt.show()\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7grGPbKYC7d"
      },
      "source": [
        "loss, train_acc, val_acc = train_and_test(1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Pv1QktcXdj4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37ca1c67-e244-4765-8b02-b33ce3f23f44"
      },
      "source": [
        "train_and_test(1, 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for the 1 -th times\n",
            "the 0 th epoch...\n",
            "100 mini-batch of 0 -th epoch train loss : 0.31080619417130945\n",
            "200 mini-batch of 0 -th epoch train loss : 0.3305718846619129\n",
            "300 mini-batch of 0 -th epoch train loss : 0.33856473967432976\n",
            "400 mini-batch of 0 -th epoch train loss : 0.34351072415709494\n",
            "500 mini-batch of 0 -th epoch train loss : 0.3327855543792248\n",
            "Accuracy of the network on the  training images: 0.89548\n",
            "Accuracy of the network on the  test images: 0.7766 \n",
            "None\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([tensor(0.2930, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3441, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3168, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2799, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4001, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3496, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3641, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2809, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3213, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1472, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1252, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2727, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4122, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3452, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3309, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3307, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2923, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2067, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2651, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4283, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2350, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2289, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4561, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2217, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2104, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2859, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2721, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3599, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2063, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2773, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2784, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1151, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3196, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3853, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4347, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2990, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3305, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4093, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2103, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2447, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.6295, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3053, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3776, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3204, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2435, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2289, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4455, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2923, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3164, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3306, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4348, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2693, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2114, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2254, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.5281, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2349, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3265, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3374, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3227, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3287, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2581, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3170, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2628, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3105, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3681, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3639, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3393, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1739, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4149, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3869, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3958, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3817, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2396, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4232, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3113, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3213, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4075, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3983, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2758, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2473, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2061, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2526, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2608, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3040, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3069, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3056, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2462, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3365, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3610, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2405, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4069, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2355, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2814, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2624, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3918, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2135, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4101, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3207, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2140, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3304, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2662, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.5091, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3578, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4320, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2266, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4512, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4941, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4169, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.5205, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2816, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3048, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2399, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4975, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3115, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3528, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3022, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2117, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2212, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2526, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2913, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3625, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3667, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4250, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3695, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2656, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4356, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2414, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2559, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2619, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3731, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2285, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3751, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2367, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2823, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3006, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3064, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1889, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3734, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2675, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3045, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3724, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3655, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4125, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2780, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3622, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3172, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2388, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3993, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2890, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3777, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2872, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2688, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3424, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3694, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2588, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4425, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3849, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3557, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2864, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3507, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2729, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2330, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2461, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2932, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3546, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1357, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3477, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2241, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.6043, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3354, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3813, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.5588, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2153, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2150, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2406, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3565, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3704, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2491, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2832, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2605, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4208, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3850, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2992, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.5104, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3077, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3059, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2009, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3578, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4393, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4239, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2407, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2869, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3604, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1786, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4455, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2447, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3537, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.5018, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3692, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3246, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2712, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1901, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4121, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3755, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2959, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4025, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2864, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3759, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4597, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3653, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3411, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2703, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4588, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3328, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2054, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2951, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2327, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4097, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2760, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3065, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4157, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2674, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2604, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2951, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4448, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2693, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3188, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2229, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3686, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4591, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4047, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4806, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2513, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2185, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3507, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1988, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3624, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.5216, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3173, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3448, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3630, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3696, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2889, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2768, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3424, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3169, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2267, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2223, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3238, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3060, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2369, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3645, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.5060, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3345, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1854, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3623, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4313, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3568, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2721, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3319, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3235, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.5098, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3020, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4458, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3949, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3652, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.5495, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4400, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2659, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2737, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.6299, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4445, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3032, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2166, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2630, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2620, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2582, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3798, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3294, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1370, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3953, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3704, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3944, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4693, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3096, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3719, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3966, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4471, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3128, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2999, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2219, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3212, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3815, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3638, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3799, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3117, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1779, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3565, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3470, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3801, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2706, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3256, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2188, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3505, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.5593, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4639, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2454, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2861, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3228, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3095, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.5667, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.6611, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3771, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3203, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4393, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3806, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3418, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3702, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3733, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2699, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4832, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2708, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2876, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2650, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4253, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2712, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2784, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3782, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3560, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3403, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3934, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3615, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2954, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3370, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3808, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4381, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1622, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3320, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3909, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2135, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3017, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3598, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.5669, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2503, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2633, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3192, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4113, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3378, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2793, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3720, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3524, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3783, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4591, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4279, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1484, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2558, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3973, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3513, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4412, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.5534, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2905, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2192, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2500, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2988, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2531, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3803, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4358, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2462, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3900, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2778, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3630, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2624, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2607, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2753, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4224, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2139, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2717, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4739, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3191, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4547, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3723, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.5559, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4028, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3204, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3303, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3320, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2391, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3096, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3136, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2762, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3167, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3482, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2329, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4140, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2789, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2767, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3804, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3739, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2938, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2846, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2483, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2571, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3734, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3976, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3676, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4440, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4450, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2343, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4390, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2519, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2826, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2378, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4614, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4288, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2011, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1647, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3159, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2774, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2159, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2522, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3429, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3016, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3342, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4539, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3171, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3157, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4225, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1895, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4866, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3546, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2653, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4164, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3282, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3163, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4547, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2895, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2852, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.5689, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3187, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3116, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.5683, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4934, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3106, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1538, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3108, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3904, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3122, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3491, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2389, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3409, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2771, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2631, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3031, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3333, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2846, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2905, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2995, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.5241, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2368, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.5813, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3368, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3784, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2758, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2681, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3315, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2899, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3234, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3066, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2044, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2771, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2246, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4620, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2639, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2742, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1540, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2545, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4012, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.6015, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2393, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3534, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3191, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2172, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3836, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.6673, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3902, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3137, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2799, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4455, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2552, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2889, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1865, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2563, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2566, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3704, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4331, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3355, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2545, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3876, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2560, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.5299, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              "  0.5299276113510132],\n",
              " [89.548],\n",
              " [77.66])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZxUR4MfJsmwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEdSDODyZScj"
      },
      "source": [
        "#Load embeded model for CIFAR10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPk5SMDaZSck"
      },
      "source": [
        "RepVGG(self, num_blocks, num_classes=1000, width_multiplier=None, override_groups_map=None, deploy=False, use_se=False)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWdbAWGSZSck"
      },
      "source": [
        "#se_block.py\n",
        "dropout=0.10 \n",
        "output_dim=10\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#   https://openaccess.thecvf.com/content_cvpr_2018/html/Hu_Squeeze-and-Excitation_Networks_CVPR_2018_paper.html\n",
        "\n",
        "class SEBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, input_channels, internal_neurons):\n",
        "        super(SEBlock, self).__init__()\n",
        "        self.down = nn.Conv2d(in_channels=input_channels, out_channels=internal_neurons, kernel_size=1, stride=1, bias=True)\n",
        "        self.up = nn.Conv2d(in_channels=internal_neurons, out_channels=input_channels, kernel_size=1, stride=1, bias=True)\n",
        "        self.input_channels = input_channels\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = F.avg_pool2d(inputs, kernel_size=inputs.size(3))\n",
        "        x = self.down(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.up(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        x = x.view(-1, self.input_channels, 1, 1)\n",
        "        return inputs * x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTI6pBa2ZSck"
      },
      "source": [
        "# model.py \n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch\n",
        "import copy\n",
        "#from se_block import SEBlock\n",
        "\n",
        "def conv_bn(in_channels, out_channels, kernel_size, stride, padding, groups=1):\n",
        "    result = nn.Sequential()\n",
        "    result.add_module('conv', nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
        "                                                  kernel_size=kernel_size, stride=stride, padding=padding, groups=groups, bias=False))\n",
        "    result.add_module('bn', nn.BatchNorm2d(num_features=out_channels))\n",
        "    return result\n",
        "\n",
        "class RepVGGBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size,\n",
        "                 stride=1, padding=0, dilation=1, groups=1, padding_mode='zeros', deploy=False, use_se=False):\n",
        "        super(RepVGGBlock, self).__init__()\n",
        "        self.deploy = deploy\n",
        "        self.groups = groups\n",
        "        self.in_channels = in_channels\n",
        "\n",
        "        assert kernel_size == 3\n",
        "        assert padding == 1\n",
        "\n",
        "        padding_11 = padding - kernel_size // 2\n",
        "\n",
        "        self.nonlinearity = nn.ReLU()\n",
        "\n",
        "        if use_se:\n",
        "            self.se = SEBlock(out_channels, internal_neurons=out_channels // 16)\n",
        "        else:\n",
        "            self.se = nn.Identity()\n",
        "\n",
        "        if deploy:\n",
        "            self.rbr_reparam = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride,\n",
        "                                      padding=padding, dilation=dilation, groups=groups, bias=True, padding_mode=padding_mode)\n",
        "\n",
        "        else:\n",
        "            self.rbr_identity = nn.BatchNorm2d(num_features=in_channels) if out_channels == in_channels and stride == 1 else None\n",
        "            self.rbr_dense = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, groups=groups)\n",
        "            self.rbr_1x1 = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=stride, padding=padding_11, groups=groups)\n",
        "            print('RepVGG Block, identity = ', self.rbr_identity)\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        if hasattr(self, 'rbr_reparam'):\n",
        "            return self.nonlinearity(self.se(self.rbr_reparam(inputs)))\n",
        "\n",
        "        if self.rbr_identity is None:\n",
        "            id_out = 0\n",
        "        else:\n",
        "            id_out = self.rbr_identity(inputs)\n",
        "\n",
        "        return self.nonlinearity(self.se(self.rbr_dense(inputs) + self.rbr_1x1(inputs) + id_out))\n",
        "\n",
        "\n",
        "    #   Optional. This improves the accuracy and facilitates quantization.\n",
        "    #   1.  Cancel the original weight decay on rbr_dense.conv.weight and rbr_1x1.conv.weight.\n",
        "    #   2.  Use like this.\n",
        "    #       loss = criterion(....)\n",
        "    #       for every RepVGGBlock blk:\n",
        "    #           loss += weight_decay_coefficient * 0.5 * blk.get_cust_L2()\n",
        "    #       optimizer.zero_grad()\n",
        "    #       loss.backward()\n",
        "    def get_custom_L2(self):\n",
        "        K3 = self.rbr_dense.conv.weight\n",
        "        K1 = self.rbr_1x1.conv.weight\n",
        "        t3 = (self.rbr_dense.bn.weight / ((self.rbr_dense.bn.running_var + self.rbr_dense.bn.eps).sqrt())).reshape(-1, 1, 1, 1).detach()\n",
        "        t1 = (self.rbr_1x1.bn.weight / ((self.rbr_1x1.bn.running_var + self.rbr_1x1.bn.eps).sqrt())).reshape(-1, 1, 1, 1).detach()\n",
        "\n",
        "        l2_loss_circle = (K3 ** 2).sum() - (K3[:, :, 1:2, 1:2] ** 2).sum()      # The L2 loss of the \"circle\" of weights in 3x3 kernel. Use regular L2 on them.\n",
        "        eq_kernel = K3[:, :, 1:2, 1:2] * t3 + K1 * t1                           # The equivalent resultant central point of 3x3 kernel.\n",
        "        l2_loss_eq_kernel = (eq_kernel ** 2 / (t3 ** 2 + t1 ** 2)).sum()        # Normalize for an L2 coefficient comparable to regular L2.\n",
        "        return l2_loss_eq_kernel + l2_loss_circle\n",
        "\n",
        "\n",
        "\n",
        "#   This func derives the equivalent kernel and bias in a DIFFERENTIABLE way.\n",
        "#   You can get the equivalent kernel and bias at any time and do whatever you want,\n",
        "    #   for example, apply some penalties or constraints during training, just like you do to the other models.\n",
        "#   May be useful for quantization or pruning.\n",
        "    def get_equivalent_kernel_bias(self):\n",
        "        kernel3x3, bias3x3 = self._fuse_bn_tensor(self.rbr_dense)\n",
        "        kernel1x1, bias1x1 = self._fuse_bn_tensor(self.rbr_1x1)\n",
        "        kernelid, biasid = self._fuse_bn_tensor(self.rbr_identity)\n",
        "        return kernel3x3 + self._pad_1x1_to_3x3_tensor(kernel1x1) + kernelid, bias3x3 + bias1x1 + biasid\n",
        "\n",
        "    def _pad_1x1_to_3x3_tensor(self, kernel1x1):\n",
        "        if kernel1x1 is None:\n",
        "            return 0\n",
        "        else:\n",
        "            return torch.nn.functional.pad(kernel1x1, [1,1,1,1])\n",
        "\n",
        "    def _fuse_bn_tensor(self, branch):\n",
        "        if branch is None:\n",
        "            return 0, 0\n",
        "        if isinstance(branch, nn.Sequential):\n",
        "            kernel = branch.conv.weight\n",
        "            running_mean = branch.bn.running_mean\n",
        "            running_var = branch.bn.running_var\n",
        "            gamma = branch.bn.weight\n",
        "            beta = branch.bn.bias\n",
        "            eps = branch.bn.eps\n",
        "        else:\n",
        "            assert isinstance(branch, nn.BatchNorm2d)\n",
        "            if not hasattr(self, 'id_tensor'):\n",
        "                input_dim = self.in_channels // self.groups\n",
        "                kernel_value = np.zeros((self.in_channels, input_dim, 3, 3), dtype=np.float32)\n",
        "                for i in range(self.in_channels):\n",
        "                    kernel_value[i, i % input_dim, 1, 1] = 1\n",
        "                self.id_tensor = torch.from_numpy(kernel_value).to(branch.weight.device)\n",
        "            kernel = self.id_tensor\n",
        "            running_mean = branch.running_mean\n",
        "            running_var = branch.running_var\n",
        "            gamma = branch.weight\n",
        "            beta = branch.bias\n",
        "            eps = branch.eps\n",
        "        std = (running_var + eps).sqrt()\n",
        "        t = (gamma / std).reshape(-1, 1, 1, 1)\n",
        "        return kernel * t, beta - running_mean * gamma / std\n",
        "\n",
        "    def switch_to_deploy(self):\n",
        "        if hasattr(self, 'rbr_reparam'):\n",
        "            return\n",
        "        kernel, bias = self.get_equivalent_kernel_bias()\n",
        "        self.rbr_reparam = nn.Conv2d(in_channels=self.rbr_dense.conv.in_channels, out_channels=self.rbr_dense.conv.out_channels,\n",
        "                                     kernel_size=self.rbr_dense.conv.kernel_size, stride=self.rbr_dense.conv.stride,\n",
        "                                     padding=self.rbr_dense.conv.padding, dilation=self.rbr_dense.conv.dilation, groups=self.rbr_dense.conv.groups, bias=True)\n",
        "        self.rbr_reparam.weight.data = kernel\n",
        "        self.rbr_reparam.bias.data = bias\n",
        "        for para in self.parameters():\n",
        "            para.detach_()\n",
        "        self.__delattr__('rbr_dense')\n",
        "        self.__delattr__('rbr_1x1')\n",
        "        if hasattr(self, 'rbr_identity'):\n",
        "            self.__delattr__('rbr_identity')\n",
        "        if hasattr(self, 'id_tensor'):\n",
        "            self.__delattr__('id_tensor')\n",
        "        self.deploy = True\n",
        "\n",
        "\n",
        "\n",
        "class RepVGG(nn.Module):\n",
        "\n",
        "    def __init__(self, num_blocks, num_classes=1000, width_multiplier=None, override_groups_map=None, deploy=False, use_se=False):\n",
        "        super(RepVGG, self).__init__()\n",
        "\n",
        "        assert len(width_multiplier) == 4\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 2), # conv1\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 32, 2), # conv2\n",
        "            nn.BatchNorm2d(32), # bn_32\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Dropout(dropout))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, 2), # conv3\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, 3), # conv4\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Dropout(dropout))\n",
        "\n",
        "        self.deploy = deploy\n",
        "        self.override_groups_map = override_groups_map or dict()\n",
        "        self.use_se = use_se\n",
        "\n",
        "        assert 0 not in self.override_groups_map\n",
        "\n",
        "        self.in_planes = 64 #min(64, int(64 * width_multiplier[0]))\n",
        "        self.cur_layer_idx = 1\n",
        "        \n",
        "\n",
        "        self.stage = self._make_stage(128,2,2)\n",
        "        self.fc = nn.Linear(1152, 500)\n",
        "        self.fc2 = nn.Linear(500, 72)\n",
        "        self.fc3 = nn.Linear(72, output_dim)\n",
        "\n",
        "    def _make_stage(self, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        blocks = []\n",
        "        for stride in strides:\n",
        "            cur_groups = self.override_groups_map.get(self.cur_layer_idx, 1)\n",
        "            blocks.append(RepVGGBlock(in_channels=self.in_planes, out_channels=planes, kernel_size=3,\n",
        "                                      stride=stride, padding=1, groups=cur_groups, deploy=self.deploy, use_se=self.use_se))\n",
        "            self.in_planes = planes\n",
        "            self.cur_layer_idx += 1\n",
        "        return nn.Sequential(*blocks)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.stage(out)\n",
        "        \n",
        "\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.fc3(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "optional_groupwise_layers = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26]\n",
        "g2_map = {l: 2 for l in optional_groupwise_layers}\n",
        "g4_map = {l: 4 for l in optional_groupwise_layers}\n",
        "\n",
        "def create_RepVGG_A0(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[0.75, 0.75, 0.75, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_A1(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[1, 1, 1, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_A2(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[1.5, 1.5, 1.5, 2.75], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B0(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[1, 1, 1, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "def create_RepVGG_B2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B2g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B2g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "def create_RepVGG_B3(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B3g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B3g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_D2se(deploy=False):\n",
        "    return RepVGG(num_blocks=[8, 14, 24, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=None, deploy=deploy, use_se=True)\n",
        "\n",
        "\n",
        "func_dict = {\n",
        "'RepVGG-A0': create_RepVGG_A0,\n",
        "'RepVGG-A1': create_RepVGG_A1,\n",
        "'RepVGG-A2': create_RepVGG_A2,\n",
        "'RepVGG-B0': create_RepVGG_B0,\n",
        "'RepVGG-B1': create_RepVGG_B1,\n",
        "'RepVGG-B1g2': create_RepVGG_B1g2,\n",
        "'RepVGG-B1g4': create_RepVGG_B1g4,\n",
        "'RepVGG-B2': create_RepVGG_B2,\n",
        "'RepVGG-B2g2': create_RepVGG_B2g2,\n",
        "'RepVGG-B2g4': create_RepVGG_B2g4,\n",
        "'RepVGG-B3': create_RepVGG_B3,\n",
        "'RepVGG-B3g2': create_RepVGG_B3g2,\n",
        "'RepVGG-B3g4': create_RepVGG_B3g4,\n",
        "'RepVGG-D2se': create_RepVGG_D2se,      #   Updated at April 25, 2021. This is not reported in the CVPR paper.\n",
        "}\n",
        "def get_RepVGG_func_by_name(name):\n",
        "    return func_dict[name]\n",
        "\n",
        "\n",
        "\n",
        "#   Use this for converting a RepVGG model or a bigger model with RepVGG as its component\n",
        "#   Use like this\n",
        "#   model = create_RepVGG_A0(deploy=False)\n",
        "#   train model or load weights\n",
        "#   repvgg_model_convert(model, save_path='repvgg_deploy.pth')\n",
        "#   If you want to preserve the original model, call with do_copy=True\n",
        "\n",
        "#   ====================== for using RepVGG as the backbone of a bigger model, e.g., PSPNet, the pseudo code will be like\n",
        "#   train_backbone = create_RepVGG_B2(deploy=False)\n",
        "#   train_backbone.load_state_dict(torch.load('RepVGG-B2-train.pth'))\n",
        "#   train_pspnet = build_pspnet(backbone=train_backbone)\n",
        "#   segmentation_train(train_pspnet)\n",
        "#   deploy_pspnet = repvgg_model_convert(train_pspnet)\n",
        "#   segmentation_test(deploy_pspnet)\n",
        "#   =====================   example_pspnet.py shows an example\n",
        "\n",
        "def repvgg_model_convert(model:torch.nn.Module, save_path=None, do_copy=True):\n",
        "    if do_copy:\n",
        "        model = copy.deepcopy(model)\n",
        "    for module in model.modules():\n",
        "        if hasattr(module, 'switch_to_deploy'):\n",
        "            module.switch_to_deploy()\n",
        "    if save_path is not None:\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Rhf9CKjtssDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqU99pUvwyuL"
      },
      "source": [
        "#Train and test functions for RepVGG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OH7lmvt9t_v4"
      },
      "source": [
        "# in seconds\n",
        "from time import process_time\n",
        "def train(model, criterion, optimizer, epochs=80):\n",
        "  start = process_time() \n",
        "  #total_time = process_time() \n",
        "  for epoch in range(epochs):\n",
        "    print(\"--------------------Epoch {}--------------------\".format(epoch))\n",
        "    epoch_start = process_time() \n",
        "    for i, (inputs, labels) in enumerate(trainloader):\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "      outputs = model(inputs)\n",
        "      #print(outputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      \n",
        "      if (i+1) % 100 == 0:\n",
        "        print (\"Mini-batch {}, Loss: {:.2f}\".format(i+1, loss.item()))\n",
        "    time_elapsed = process_time() - epoch_start\n",
        "    print(\"Time elapsed: {:.2f} min\".format(time_elapsed/60))\n",
        "  print('Finished Training. Total time elapsed: {:.2f} min'.format((process_time()-start)/60))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHv-epaDveWN"
      },
      "source": [
        "def test(model):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "      total = 0\n",
        "      correct =0\n",
        "      for images, labels in testloader:\n",
        "          images = images.to(device)\n",
        "          labels = labels.to(device)\n",
        "          outputs = model(images)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "      print('Accuracy ( test images ) : {} %'.format(100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlerzHdsxIW9"
      },
      "source": [
        "#Train and test RepVGG-A0 with CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--ubzeLNlOUU",
        "outputId": "3c7773ba-dca7-4477-cd0d-44f91c852591"
      },
      "source": [
        "base_lr = 0.01\n",
        "lr_decay = 0.0001\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "#num_workers = 3\n",
        "\n",
        "#RepVGG_model = create_RepVGG_A0(deploy=True)\n",
        "RepVGG_A0 = RepVGG(num_blocks=[2, 4, 14, 1], num_classes=10,\n",
        "                  width_multiplier=[0.75,0.75, 0.75, 2.5], override_groups_map=None, deploy=False)\n",
        "RepVGG_A0_model = RepVGG_A0.to(device)\n",
        "RepVGG_A0_criterion = nn.CrossEntropyLoss()\n",
        "#RepVGG_A0_optimizer = torch.optim.SGD(convNet.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "RepVGG_A0_optimizer = torch.optim.Adam(RepVGG_A0_model.parameters(), lr=base_lr)\n",
        "      "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RepVGG_A0_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ztrj7XvyhYEx",
        "outputId": "cbfaca5c-4b5d-4555-9925-3da05739b512"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RepVGG(\n",
              "  (layer1): Sequential(\n",
              "    (0): Conv2d(3, 32, kernel_size=(2, 2), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(32, 32, kernel_size=(2, 2), stride=(1, 1))\n",
              "    (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4): ReLU()\n",
              "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4): ReLU()\n",
              "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (stage): Sequential(\n",
              "    (0): RepVGGBlock(\n",
              "      (nonlinearity): ReLU()\n",
              "      (se): Identity()\n",
              "      (rbr_dense): Sequential(\n",
              "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (rbr_1x1): Sequential(\n",
              "        (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): RepVGGBlock(\n",
              "      (nonlinearity): ReLU()\n",
              "      (se): Identity()\n",
              "      (rbr_identity): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (rbr_dense): Sequential(\n",
              "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (rbr_1x1): Sequential(\n",
              "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (fc): Linear(in_features=1152, out_features=500, bias=True)\n",
              "  (fc2): Linear(in_features=500, out_features=72, bias=True)\n",
              "  (fc3): Linear(in_features=72, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CPDLm4FlorM",
        "outputId": "35791083-25ec-458a-ec29-0e1c9fe5b8be"
      },
      "source": [
        "\n",
        "train(RepVGG_A0_model, RepVGG_A0_criterion, RepVGG_A0_optimizer, epochs=30)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------Epoch 0--------------------\n",
            "Mini-batch 100, Loss: 2.27\n",
            "Mini-batch 200, Loss: 2.24\n",
            "Mini-batch 300, Loss: 2.26\n",
            "Mini-batch 400, Loss: 1.82\n",
            "Mini-batch 500, Loss: 1.63\n",
            "Time elapsed: 0.16 min\n",
            "--------------------Epoch 1--------------------\n",
            "Mini-batch 100, Loss: 1.51\n",
            "Mini-batch 200, Loss: 1.30\n",
            "Mini-batch 300, Loss: 1.45\n",
            "Mini-batch 400, Loss: 1.38\n",
            "Mini-batch 500, Loss: 1.40\n",
            "Time elapsed: 0.16 min\n",
            "--------------------Epoch 2--------------------\n",
            "Mini-batch 100, Loss: 1.08\n",
            "Mini-batch 200, Loss: 1.24\n",
            "Mini-batch 300, Loss: 1.19\n",
            "Mini-batch 400, Loss: 1.24\n",
            "Mini-batch 500, Loss: 1.00\n",
            "Time elapsed: 0.16 min\n",
            "--------------------Epoch 3--------------------\n",
            "Mini-batch 100, Loss: 1.03\n",
            "Mini-batch 200, Loss: 1.06\n",
            "Mini-batch 300, Loss: 0.97\n",
            "Mini-batch 400, Loss: 0.80\n",
            "Mini-batch 500, Loss: 0.85\n",
            "Time elapsed: 0.17 min\n",
            "--------------------Epoch 4--------------------\n",
            "Mini-batch 100, Loss: 1.05\n",
            "Mini-batch 200, Loss: 1.11\n",
            "Mini-batch 300, Loss: 0.87\n",
            "Mini-batch 400, Loss: 0.79\n",
            "Mini-batch 500, Loss: 0.86\n",
            "Time elapsed: 0.16 min\n",
            "--------------------Epoch 5--------------------\n",
            "Mini-batch 100, Loss: 0.84\n",
            "Mini-batch 200, Loss: 0.94\n",
            "Mini-batch 300, Loss: 1.18\n",
            "Mini-batch 400, Loss: 0.75\n",
            "Mini-batch 500, Loss: 0.92\n",
            "Time elapsed: 0.17 min\n",
            "--------------------Epoch 6--------------------\n",
            "Mini-batch 100, Loss: 0.96\n",
            "Mini-batch 200, Loss: 0.79\n",
            "Mini-batch 300, Loss: 0.88\n",
            "Mini-batch 400, Loss: 0.65\n",
            "Mini-batch 500, Loss: 0.69\n",
            "Time elapsed: 0.16 min\n",
            "--------------------Epoch 7--------------------\n",
            "Mini-batch 100, Loss: 0.96\n",
            "Mini-batch 200, Loss: 0.77\n",
            "Mini-batch 300, Loss: 0.73\n",
            "Mini-batch 400, Loss: 0.70\n",
            "Mini-batch 500, Loss: 0.75\n",
            "Time elapsed: 0.16 min\n",
            "--------------------Epoch 8--------------------\n",
            "Mini-batch 100, Loss: 0.80\n",
            "Mini-batch 200, Loss: 0.68\n",
            "Mini-batch 300, Loss: 0.70\n",
            "Mini-batch 400, Loss: 0.68\n",
            "Mini-batch 500, Loss: 0.61\n",
            "Time elapsed: 0.16 min\n",
            "--------------------Epoch 9--------------------\n",
            "Mini-batch 100, Loss: 0.72\n",
            "Mini-batch 200, Loss: 0.56\n",
            "Mini-batch 300, Loss: 0.75\n",
            "Mini-batch 400, Loss: 0.71\n",
            "Mini-batch 500, Loss: 0.89\n",
            "Time elapsed: 0.16 min\n",
            "--------------------Epoch 10--------------------\n",
            "Mini-batch 100, Loss: 0.62\n",
            "Mini-batch 200, Loss: 0.63\n",
            "Mini-batch 300, Loss: 0.47\n",
            "Mini-batch 400, Loss: 0.54\n",
            "Mini-batch 500, Loss: 0.61\n",
            "Time elapsed: 0.16 min\n",
            "--------------------Epoch 11--------------------\n",
            "Mini-batch 100, Loss: 0.57\n",
            "Mini-batch 200, Loss: 0.42\n",
            "Mini-batch 300, Loss: 0.43\n",
            "Mini-batch 400, Loss: 0.59\n",
            "Mini-batch 500, Loss: 0.77\n",
            "Time elapsed: 0.17 min\n",
            "--------------------Epoch 12--------------------\n",
            "Mini-batch 100, Loss: 0.55\n",
            "Mini-batch 200, Loss: 0.75\n",
            "Mini-batch 300, Loss: 0.53\n",
            "Mini-batch 400, Loss: 0.61\n",
            "Mini-batch 500, Loss: 0.44\n",
            "Time elapsed: 0.16 min\n",
            "--------------------Epoch 13--------------------\n",
            "Mini-batch 100, Loss: 0.43\n",
            "Mini-batch 200, Loss: 0.61\n",
            "Mini-batch 300, Loss: 0.56\n",
            "Mini-batch 400, Loss: 0.48\n",
            "Mini-batch 500, Loss: 0.77\n",
            "Time elapsed: 0.17 min\n",
            "--------------------Epoch 14--------------------\n",
            "Mini-batch 100, Loss: 0.50\n",
            "Mini-batch 200, Loss: 0.58\n",
            "Mini-batch 300, Loss: 0.58\n",
            "Mini-batch 400, Loss: 0.80\n",
            "Mini-batch 500, Loss: 0.60\n",
            "Time elapsed: 0.16 min\n",
            "--------------------Epoch 15--------------------\n",
            "Mini-batch 100, Loss: 0.44\n",
            "Mini-batch 200, Loss: 0.49\n",
            "Mini-batch 300, Loss: 0.63\n",
            "Mini-batch 400, Loss: 0.42\n",
            "Mini-batch 500, Loss: 0.70\n",
            "Time elapsed: 0.16 min\n",
            "--------------------Epoch 16--------------------\n",
            "Mini-batch 100, Loss: 0.42\n",
            "Mini-batch 200, Loss: 0.35\n",
            "Mini-batch 300, Loss: 0.46\n",
            "Mini-batch 400, Loss: 0.52\n",
            "Mini-batch 500, Loss: 0.41\n",
            "Time elapsed: 0.17 min\n",
            "--------------------Epoch 17--------------------\n",
            "Mini-batch 100, Loss: 0.56\n",
            "Mini-batch 200, Loss: 0.47\n",
            "Mini-batch 300, Loss: 0.59\n",
            "Mini-batch 400, Loss: 0.39\n",
            "Mini-batch 500, Loss: 0.51\n",
            "Time elapsed: 0.17 min\n",
            "--------------------Epoch 18--------------------\n",
            "Mini-batch 100, Loss: 0.61\n",
            "Mini-batch 200, Loss: 0.35\n",
            "Mini-batch 300, Loss: 0.67\n",
            "Mini-batch 400, Loss: 0.46\n",
            "Mini-batch 500, Loss: 0.66\n",
            "Time elapsed: 0.17 min\n",
            "--------------------Epoch 19--------------------\n",
            "Mini-batch 100, Loss: 0.61\n",
            "Mini-batch 200, Loss: 0.47\n",
            "Mini-batch 300, Loss: 0.50\n",
            "Mini-batch 400, Loss: 0.41\n",
            "Mini-batch 500, Loss: 0.41\n",
            "Time elapsed: 0.17 min\n",
            "--------------------Epoch 20--------------------\n",
            "Mini-batch 100, Loss: 0.26\n",
            "Mini-batch 200, Loss: 0.43\n",
            "Mini-batch 300, Loss: 0.55\n",
            "Mini-batch 400, Loss: 0.67\n",
            "Mini-batch 500, Loss: 0.56\n",
            "Time elapsed: 0.17 min\n",
            "--------------------Epoch 21--------------------\n",
            "Mini-batch 100, Loss: 0.37\n",
            "Mini-batch 200, Loss: 0.58\n",
            "Mini-batch 300, Loss: 0.49\n",
            "Mini-batch 400, Loss: 0.66\n",
            "Mini-batch 500, Loss: 0.33\n",
            "Time elapsed: 0.17 min\n",
            "--------------------Epoch 22--------------------\n",
            "Mini-batch 100, Loss: 0.65\n",
            "Mini-batch 200, Loss: 0.49\n",
            "Mini-batch 300, Loss: 0.57\n",
            "Mini-batch 400, Loss: 0.39\n",
            "Mini-batch 500, Loss: 0.74\n",
            "Time elapsed: 0.17 min\n",
            "--------------------Epoch 23--------------------\n",
            "Mini-batch 100, Loss: 0.26\n",
            "Mini-batch 200, Loss: 0.39\n",
            "Mini-batch 300, Loss: 0.26\n",
            "Mini-batch 400, Loss: 0.55\n",
            "Mini-batch 500, Loss: 0.62\n",
            "Time elapsed: 0.17 min\n",
            "--------------------Epoch 24--------------------\n",
            "Mini-batch 100, Loss: 0.44\n",
            "Mini-batch 200, Loss: 0.32\n",
            "Mini-batch 300, Loss: 0.37\n",
            "Mini-batch 400, Loss: 0.34\n",
            "Mini-batch 500, Loss: 0.40\n",
            "Time elapsed: 0.17 min\n",
            "--------------------Epoch 25--------------------\n",
            "Mini-batch 100, Loss: 0.39\n",
            "Mini-batch 200, Loss: 0.37\n",
            "Mini-batch 300, Loss: 0.56\n",
            "Mini-batch 400, Loss: 0.37\n",
            "Mini-batch 500, Loss: 0.52\n",
            "Time elapsed: 0.17 min\n",
            "--------------------Epoch 26--------------------\n",
            "Mini-batch 100, Loss: 0.21\n",
            "Mini-batch 200, Loss: 0.54\n",
            "Mini-batch 300, Loss: 0.54\n",
            "Mini-batch 400, Loss: 0.48\n",
            "Mini-batch 500, Loss: 0.46\n",
            "Time elapsed: 0.17 min\n",
            "--------------------Epoch 27--------------------\n",
            "Mini-batch 100, Loss: 0.30\n",
            "Mini-batch 200, Loss: 0.33\n",
            "Mini-batch 300, Loss: 0.39\n",
            "Mini-batch 400, Loss: 0.34\n",
            "Mini-batch 500, Loss: 0.38\n",
            "Time elapsed: 0.17 min\n",
            "--------------------Epoch 28--------------------\n",
            "Mini-batch 100, Loss: 0.35\n",
            "Mini-batch 200, Loss: 0.57\n",
            "Mini-batch 300, Loss: 0.29\n",
            "Mini-batch 400, Loss: 0.38\n",
            "Mini-batch 500, Loss: 0.41\n",
            "Time elapsed: 0.17 min\n",
            "--------------------Epoch 29--------------------\n",
            "Mini-batch 100, Loss: 0.17\n",
            "Mini-batch 200, Loss: 0.42\n",
            "Mini-batch 300, Loss: 0.32\n",
            "Mini-batch 400, Loss: 0.35\n",
            "Mini-batch 500, Loss: 0.36\n",
            "Time elapsed: 0.17 min\n",
            "Finished Training. Total time elapsed: 4.99 min\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCokjRHJn7Yv",
        "outputId": "ec4ee0fb-e1bb-487f-aa1e-2a5bb1635dee"
      },
      "source": [
        "deploy_model = repvgg_model_convert(RepVGG_A0_model, save_path='RepVGG-A0-deploy.pth')\n",
        "\n",
        "test(deploy_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy ( test images ) : 78.55 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(RepVGG_A0_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRW8wt_hgtAZ",
        "outputId": "b00b37b6-2f44-4800-984f-d95060cf3f88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy ( test images ) : 78.55 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZR55q3EUwDIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CIFAR100"
      ],
      "metadata": {
        "id": "ZvXtt08As45T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## load CIFAR100"
      ],
      "metadata": {
        "id": "CgANEpUpwD1J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "          [transforms.ToTensor(),\n",
        "          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "    \n",
        "train_dataset = torchvision.datasets.CIFAR100(root='./data', train=True, transform=transform, download=True)\n",
        "train_dataset, validation_dataset = torch.utils.data.random_split(train_dataset, [45000, 5000])\n",
        "    #test_dataset = torchvision.datasets.CIFAR100(root='./data', train=False, transform=transform, download=True)\n",
        "    \n",
        "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=100, shuffle=True, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(validation_dataset, batch_size=100, shuffle=True, num_workers=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103,
          "referenced_widgets": [
            "0619ad17caf54d65958cb1882e40205e",
            "7ebf249b77f5481c8aa29f9f37eb7679",
            "12a9a335577e417ab37ee1dc4185ccf0",
            "11eddc37958244119d384d3aeb142f60",
            "df3ef09503fd42a49bca57ad6c667384",
            "8ba76a2f5ef14ef2a3cfd2e614f6215a",
            "4d2542e972e74645bf1958e1daa67ed0",
            "63c2c57a91734fc2a8daeba297686800",
            "dbc8a076426e4bbab953b06fb4cf7ac9",
            "f3d2584f1c10488fa5bb2d384c3eac91",
            "7881e881b6814cbc9495dcb11124618a"
          ]
        },
        "id": "y3p2HhhBwHkN",
        "outputId": "a17fdc83-9257-4403-a51a-b4a1cfe41248"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0619ad17caf54d65958cb1882e40205e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/169001437 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-100-python.tar.gz to ./data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Q87ea2I5wQUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MivtTniBwny3"
      },
      "source": [
        "##Load embeded model for CIFAR100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbUMUYTlwny3"
      },
      "source": [
        "RepVGG(self, num_blocks, num_classes=1000, width_multiplier=None, override_groups_map=None, deploy=False, use_se=False)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pot9A_gZwny3"
      },
      "source": [
        "#se_block.py\n",
        "dropout=0.10 \n",
        "output_dim=100\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#   https://openaccess.thecvf.com/content_cvpr_2018/html/Hu_Squeeze-and-Excitation_Networks_CVPR_2018_paper.html\n",
        "\n",
        "class SEBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, input_channels, internal_neurons):\n",
        "        super(SEBlock, self).__init__()\n",
        "        self.down = nn.Conv2d(in_channels=input_channels, out_channels=internal_neurons, kernel_size=1, stride=1, bias=True)\n",
        "        self.up = nn.Conv2d(in_channels=internal_neurons, out_channels=input_channels, kernel_size=1, stride=1, bias=True)\n",
        "        self.input_channels = input_channels\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = F.avg_pool2d(inputs, kernel_size=inputs.size(3))\n",
        "        x = self.down(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.up(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        x = x.view(-1, self.input_channels, 1, 1)\n",
        "        return inputs * x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3crDGkQwny4"
      },
      "source": [
        "# model.py \n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch\n",
        "import copy\n",
        "#from se_block import SEBlock\n",
        "\n",
        "def conv_bn(in_channels, out_channels, kernel_size, stride, padding, groups=1):\n",
        "    result = nn.Sequential()\n",
        "    result.add_module('conv', nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
        "                                                  kernel_size=kernel_size, stride=stride, padding=padding, groups=groups, bias=False))\n",
        "    result.add_module('bn', nn.BatchNorm2d(num_features=out_channels))\n",
        "    return result\n",
        "\n",
        "class RepVGGBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size,\n",
        "                 stride=1, padding=0, dilation=1, groups=1, padding_mode='zeros', deploy=False, use_se=False):\n",
        "        super(RepVGGBlock, self).__init__()\n",
        "        self.deploy = deploy\n",
        "        self.groups = groups\n",
        "        self.in_channels = in_channels\n",
        "\n",
        "        assert kernel_size == 3\n",
        "        assert padding == 1\n",
        "\n",
        "        padding_11 = padding - kernel_size // 2\n",
        "\n",
        "        self.nonlinearity = nn.ReLU()\n",
        "\n",
        "        if use_se:\n",
        "            self.se = SEBlock(out_channels, internal_neurons=out_channels // 16)\n",
        "        else:\n",
        "            self.se = nn.Identity()\n",
        "\n",
        "        if deploy:\n",
        "            self.rbr_reparam = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride,\n",
        "                                      padding=padding, dilation=dilation, groups=groups, bias=True, padding_mode=padding_mode)\n",
        "\n",
        "        else:\n",
        "            self.rbr_identity = nn.BatchNorm2d(num_features=in_channels) if out_channels == in_channels and stride == 1 else None\n",
        "            self.rbr_dense = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, groups=groups)\n",
        "            self.rbr_1x1 = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=stride, padding=padding_11, groups=groups)\n",
        "            print('RepVGG Block, identity = ', self.rbr_identity)\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        if hasattr(self, 'rbr_reparam'):\n",
        "            return self.nonlinearity(self.se(self.rbr_reparam(inputs)))\n",
        "\n",
        "        if self.rbr_identity is None:\n",
        "            id_out = 0\n",
        "        else:\n",
        "            id_out = self.rbr_identity(inputs)\n",
        "\n",
        "        return self.nonlinearity(self.se(self.rbr_dense(inputs) + self.rbr_1x1(inputs) + id_out))\n",
        "\n",
        "\n",
        "    #   Optional. This improves the accuracy and facilitates quantization.\n",
        "    #   1.  Cancel the original weight decay on rbr_dense.conv.weight and rbr_1x1.conv.weight.\n",
        "    #   2.  Use like this.\n",
        "    #       loss = criterion(....)\n",
        "    #       for every RepVGGBlock blk:\n",
        "    #           loss += weight_decay_coefficient * 0.5 * blk.get_cust_L2()\n",
        "    #       optimizer.zero_grad()\n",
        "    #       loss.backward()\n",
        "    def get_custom_L2(self):\n",
        "        K3 = self.rbr_dense.conv.weight\n",
        "        K1 = self.rbr_1x1.conv.weight\n",
        "        t3 = (self.rbr_dense.bn.weight / ((self.rbr_dense.bn.running_var + self.rbr_dense.bn.eps).sqrt())).reshape(-1, 1, 1, 1).detach()\n",
        "        t1 = (self.rbr_1x1.bn.weight / ((self.rbr_1x1.bn.running_var + self.rbr_1x1.bn.eps).sqrt())).reshape(-1, 1, 1, 1).detach()\n",
        "\n",
        "        l2_loss_circle = (K3 ** 2).sum() - (K3[:, :, 1:2, 1:2] ** 2).sum()      # The L2 loss of the \"circle\" of weights in 3x3 kernel. Use regular L2 on them.\n",
        "        eq_kernel = K3[:, :, 1:2, 1:2] * t3 + K1 * t1                           # The equivalent resultant central point of 3x3 kernel.\n",
        "        l2_loss_eq_kernel = (eq_kernel ** 2 / (t3 ** 2 + t1 ** 2)).sum()        # Normalize for an L2 coefficient comparable to regular L2.\n",
        "        return l2_loss_eq_kernel + l2_loss_circle\n",
        "\n",
        "\n",
        "\n",
        "#   This func derives the equivalent kernel and bias in a DIFFERENTIABLE way.\n",
        "#   You can get the equivalent kernel and bias at any time and do whatever you want,\n",
        "    #   for example, apply some penalties or constraints during training, just like you do to the other models.\n",
        "#   May be useful for quantization or pruning.\n",
        "    def get_equivalent_kernel_bias(self):\n",
        "        kernel3x3, bias3x3 = self._fuse_bn_tensor(self.rbr_dense)\n",
        "        kernel1x1, bias1x1 = self._fuse_bn_tensor(self.rbr_1x1)\n",
        "        kernelid, biasid = self._fuse_bn_tensor(self.rbr_identity)\n",
        "        return kernel3x3 + self._pad_1x1_to_3x3_tensor(kernel1x1) + kernelid, bias3x3 + bias1x1 + biasid\n",
        "\n",
        "    def _pad_1x1_to_3x3_tensor(self, kernel1x1):\n",
        "        if kernel1x1 is None:\n",
        "            return 0\n",
        "        else:\n",
        "            return torch.nn.functional.pad(kernel1x1, [1,1,1,1])\n",
        "\n",
        "    def _fuse_bn_tensor(self, branch):\n",
        "        if branch is None:\n",
        "            return 0, 0\n",
        "        if isinstance(branch, nn.Sequential):\n",
        "            kernel = branch.conv.weight\n",
        "            running_mean = branch.bn.running_mean\n",
        "            running_var = branch.bn.running_var\n",
        "            gamma = branch.bn.weight\n",
        "            beta = branch.bn.bias\n",
        "            eps = branch.bn.eps\n",
        "        else:\n",
        "            assert isinstance(branch, nn.BatchNorm2d)\n",
        "            if not hasattr(self, 'id_tensor'):\n",
        "                input_dim = self.in_channels // self.groups\n",
        "                kernel_value = np.zeros((self.in_channels, input_dim, 3, 3), dtype=np.float32)\n",
        "                for i in range(self.in_channels):\n",
        "                    kernel_value[i, i % input_dim, 1, 1] = 1\n",
        "                self.id_tensor = torch.from_numpy(kernel_value).to(branch.weight.device)\n",
        "            kernel = self.id_tensor\n",
        "            running_mean = branch.running_mean\n",
        "            running_var = branch.running_var\n",
        "            gamma = branch.weight\n",
        "            beta = branch.bias\n",
        "            eps = branch.eps\n",
        "        std = (running_var + eps).sqrt()\n",
        "        t = (gamma / std).reshape(-1, 1, 1, 1)\n",
        "        return kernel * t, beta - running_mean * gamma / std\n",
        "\n",
        "    def switch_to_deploy(self):\n",
        "        if hasattr(self, 'rbr_reparam'):\n",
        "            return\n",
        "        kernel, bias = self.get_equivalent_kernel_bias()\n",
        "        self.rbr_reparam = nn.Conv2d(in_channels=self.rbr_dense.conv.in_channels, out_channels=self.rbr_dense.conv.out_channels,\n",
        "                                     kernel_size=self.rbr_dense.conv.kernel_size, stride=self.rbr_dense.conv.stride,\n",
        "                                     padding=self.rbr_dense.conv.padding, dilation=self.rbr_dense.conv.dilation, groups=self.rbr_dense.conv.groups, bias=True)\n",
        "        self.rbr_reparam.weight.data = kernel\n",
        "        self.rbr_reparam.bias.data = bias\n",
        "        for para in self.parameters():\n",
        "            para.detach_()\n",
        "        self.__delattr__('rbr_dense')\n",
        "        self.__delattr__('rbr_1x1')\n",
        "        if hasattr(self, 'rbr_identity'):\n",
        "            self.__delattr__('rbr_identity')\n",
        "        if hasattr(self, 'id_tensor'):\n",
        "            self.__delattr__('id_tensor')\n",
        "        self.deploy = True\n",
        "\n",
        "\n",
        "\n",
        "class RepVGG(nn.Module):\n",
        "\n",
        "    def __init__(self, num_blocks, num_classes=1000, width_multiplier=None, override_groups_map=None, deploy=False, use_se=False):\n",
        "        super(RepVGG, self).__init__()\n",
        "\n",
        "        assert len(width_multiplier) == 4\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 2), # conv1\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 32, 2), # conv2\n",
        "            nn.BatchNorm2d(32), # bn_32\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Dropout(dropout))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, 2), # conv3\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, 3), # conv4\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Dropout(dropout))\n",
        "\n",
        "        self.deploy = deploy\n",
        "        self.override_groups_map = override_groups_map or dict()\n",
        "        self.use_se = use_se\n",
        "\n",
        "        assert 0 not in self.override_groups_map\n",
        "\n",
        "        self.in_planes = 64 #min(64, int(64 * width_multiplier[0]))\n",
        "        self.cur_layer_idx = 1\n",
        "        \n",
        "\n",
        "        self.stage = self._make_stage(128,1,2)\n",
        "        self.fc = nn.Linear(1152, 500)\n",
        "        self.fc2 = nn.Linear(500, 72)\n",
        "        self.fc3 = nn.Linear(72, output_dim)\n",
        "\n",
        "    def _make_stage(self, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        blocks = []\n",
        "        for stride in strides:\n",
        "            cur_groups = self.override_groups_map.get(self.cur_layer_idx, 1)\n",
        "            blocks.append(RepVGGBlock(in_channels=self.in_planes, out_channels=planes, kernel_size=3,\n",
        "                                      stride=stride, padding=1, groups=cur_groups, deploy=self.deploy, use_se=self.use_se))\n",
        "            self.in_planes = planes\n",
        "            self.cur_layer_idx += 1\n",
        "        return nn.Sequential(*blocks)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.stage(out)\n",
        "        \n",
        "\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.fc3(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "optional_groupwise_layers = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26]\n",
        "g2_map = {l: 2 for l in optional_groupwise_layers}\n",
        "g4_map = {l: 4 for l in optional_groupwise_layers}\n",
        "\n",
        "def create_RepVGG_A0(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[0.75, 0.75, 0.75, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_A1(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[1, 1, 1, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_A2(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[1.5, 1.5, 1.5, 2.75], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B0(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[1, 1, 1, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "def create_RepVGG_B2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B2g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B2g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "def create_RepVGG_B3(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B3g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B3g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_D2se(deploy=False):\n",
        "    return RepVGG(num_blocks=[8, 14, 24, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=None, deploy=deploy, use_se=True)\n",
        "\n",
        "\n",
        "func_dict = {\n",
        "'RepVGG-A0': create_RepVGG_A0,\n",
        "'RepVGG-A1': create_RepVGG_A1,\n",
        "'RepVGG-A2': create_RepVGG_A2,\n",
        "'RepVGG-B0': create_RepVGG_B0,\n",
        "'RepVGG-B1': create_RepVGG_B1,\n",
        "'RepVGG-B1g2': create_RepVGG_B1g2,\n",
        "'RepVGG-B1g4': create_RepVGG_B1g4,\n",
        "'RepVGG-B2': create_RepVGG_B2,\n",
        "'RepVGG-B2g2': create_RepVGG_B2g2,\n",
        "'RepVGG-B2g4': create_RepVGG_B2g4,\n",
        "'RepVGG-B3': create_RepVGG_B3,\n",
        "'RepVGG-B3g2': create_RepVGG_B3g2,\n",
        "'RepVGG-B3g4': create_RepVGG_B3g4,\n",
        "'RepVGG-D2se': create_RepVGG_D2se,      #   Updated at April 25, 2021. This is not reported in the CVPR paper.\n",
        "}\n",
        "def get_RepVGG_func_by_name(name):\n",
        "    return func_dict[name]\n",
        "\n",
        "\n",
        "\n",
        "#   Use this for converting a RepVGG model or a bigger model with RepVGG as its component\n",
        "#   Use like this\n",
        "#   model = create_RepVGG_A0(deploy=False)\n",
        "#   train model or load weights\n",
        "#   repvgg_model_convert(model, save_path='repvgg_deploy.pth')\n",
        "#   If you want to preserve the original model, call with do_copy=True\n",
        "\n",
        "#   ====================== for using RepVGG as the backbone of a bigger model, e.g., PSPNet, the pseudo code will be like\n",
        "#   train_backbone = create_RepVGG_B2(deploy=False)\n",
        "#   train_backbone.load_state_dict(torch.load('RepVGG-B2-train.pth'))\n",
        "#   train_pspnet = build_pspnet(backbone=train_backbone)\n",
        "#   segmentation_train(train_pspnet)\n",
        "#   deploy_pspnet = repvgg_model_convert(train_pspnet)\n",
        "#   segmentation_test(deploy_pspnet)\n",
        "#   =====================   example_pspnet.py shows an example\n",
        "\n",
        "def repvgg_model_convert(model:torch.nn.Module, save_path=None, do_copy=True):\n",
        "    if do_copy:\n",
        "        model = copy.deepcopy(model)\n",
        "    for module in model.modules():\n",
        "        if hasattr(module, 'switch_to_deploy'):\n",
        "            module.switch_to_deploy()\n",
        "    if save_path is not None:\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Wu0tJ6cKwny6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_1opTv0wXT_"
      },
      "source": [
        "##Train and test RepVGG-A0 with CIFAR100\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9ab00d5-c65f-47d2-b001-289ca31048fc",
        "id": "3Xlwq0YmwXT_"
      },
      "source": [
        "base_lr = 0.01\n",
        "lr_decay = 0.0001\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "#num_workers = 3\n",
        "\n",
        "#RepVGG_model = create_RepVGG_A0(deploy=True)\n",
        "RepVGG_A0 = RepVGG(num_blocks=[2, 4, 14, 1], num_classes=100,\n",
        "                  width_multiplier=[0.75,0.75, 0.75, 2.5], override_groups_map=None, deploy=False)\n",
        "RepVGG_A0_model = RepVGG_A0.to(device)\n",
        "RepVGG_A0_criterion = nn.CrossEntropyLoss()\n",
        "#RepVGG_A0_optimizer = torch.optim.SGD(convNet.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "RepVGG_A0_optimizer = torch.optim.Adam(RepVGG_A0_model.parameters(), lr=base_lr)\n",
        "      "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RepVGG Block, identity =  None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kVonljzGwXUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "a5290a58-6ecb-4788-acee-4dda01f0c6b4",
        "id": "ZnsFndHxwXUA"
      },
      "source": [
        "\n",
        "train(RepVGG_A0_model, RepVGG_A0_criterion, RepVGG_A0_optimizer, epochs=100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-f6be49863356>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRepVGG_A0_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRepVGG_A0_criterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRepVGG_A0_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZ9_xYqPwXUA"
      },
      "source": [
        "deploy_model = repvgg_model_convert(RepVGG_A0_model, save_path='RepVGG-A0-deploy.pth')\n",
        "\n",
        "test(deploy_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(RepVGG_A0_model)"
      ],
      "metadata": {
        "id": "UzBlXVVhwXUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-etjD8o9wXUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load Simple Model for CIFAR100"
      ],
      "metadata": {
        "id": "ULK_RCteugZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dropout=0.10 \n",
        "output_dim=100\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__() \n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 2), # conv1\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 32, 2), # conv2\n",
        "            nn.BatchNorm2d(32), # bn_32\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Dropout(dropout))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, 2), # conv3\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, 3), # conv4\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Dropout(dropout))\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, 3), # conv5\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 128, 3), # conv6\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, stride=2),\n",
        "            nn.Dropout(dropout))\n",
        "\n",
        "        \n",
        "\n",
        "        self.fc = nn.Linear(128, 500)\n",
        "        self.fc2 = nn.Linear(500, 72)\n",
        "        self.fc3 = nn.Linear(72, output_dim)\n",
        "    def forward(self, x):\n",
        "\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        \n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.fc3(out)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "5TNdf5nCugZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJFYFxepuOgz"
      },
      "source": [
        "## Mondel training and validation for CIFAR100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5675cfbb-b611-4f4a-9596-5ed56bba2c9e",
        "id": "OV4pmVtBuOg6"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34feaf23-56c9-4850-f6a0-fd287bd65bdf",
        "id": "Mfl4yJpluOg6"
      },
      "source": [
        "convNet = CNN().to(device)\n",
        "convNet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (layer1): Sequential(\n",
              "    (0): Conv2d(3, 32, kernel_size=(2, 2), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(32, 32, kernel_size=(2, 2), stride=(1, 1))\n",
              "    (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4): ReLU()\n",
              "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4): ReLU()\n",
              "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4): ReLU()\n",
              "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (fc): Linear(in_features=128, out_features=500, bias=True)\n",
              "  (fc2): Linear(in_features=500, out_features=72, bias=True)\n",
              "  (fc3): Linear(in_features=72, out_features=100, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRtzfiD_uOg7"
      },
      "source": [
        "# Define a loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#optimizer = optim.SGD(convNet.parameters(), lr=0.001, momentum=0.9)\n",
        "optimizer = torch.optim.Adam(convNet.parameters(), lr=0.01)\n",
        "#optimizer = optim.Adam(convNet.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLibJZP_uOg7"
      },
      "source": [
        "Function for Training the Model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTLhFV-7uOg7"
      },
      "source": [
        "from statistics import mean\n",
        "def train_model (model, optimizer, EPOCHS, train_loader):\n",
        "  train_loss_list = []\n",
        "  loss = 0.0\n",
        "  for i in range(EPOCHS):\n",
        "    print(\"the %d th epoch...\" %i)\n",
        "    for k, data in enumerate(train_loader):\n",
        "      images, labels = data\n",
        "      if torch.cuda.is_available():\n",
        "            images=images.cuda()\n",
        "            labels=labels.cuda()\n",
        "      optimizer.zero_grad()\n",
        "      output_train = model(images)\n",
        "      train_loss = criterion(output_train, labels)\n",
        "      train_loss_list.append(train_loss)\n",
        "      train_loss.backward()\n",
        "      optimizer.step()\n",
        "      loss += train_loss.item()\n",
        "      if k%100 == 99:\n",
        "          print(k+1, 'mini-batch of',i, '-th epoch','train loss :', loss/100)\n",
        "          loss = 0.0\n",
        "        \n",
        "    train_loss_list.append(train_loss.item())\n",
        "  return train_loss_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vy30TFe6uOg7"
      },
      "source": [
        "# Save our trained model\n",
        "#PATH = './cifar_net.pth'\n",
        "#torch.save(convNet.state_dict(), PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6I9-xR2cuOg8"
      },
      "source": [
        "# load trained model\n",
        "#model = torch.load('./cifar_net.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-7MTnTvuOg8"
      },
      "source": [
        "Function for testing the Model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qa087ppXuOg8"
      },
      "source": [
        "def test_model(model,data_loader, training=False):\n",
        "  correct = 0.0\n",
        "  total = 0.0\n",
        "  # for plotting\n",
        "  num_true = []\n",
        "  num_pred = []\n",
        "  letter_true = []\n",
        "  letter_pred = []\n",
        "  #\n",
        "  with torch.no_grad():\n",
        "      for data in data_loader:\n",
        "          images, labels = data\n",
        "          if torch.cuda.is_available():\n",
        "            images=images.cuda()\n",
        "            labels=labels.cuda()\n",
        "          outputs = model(images)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "  if not training:\n",
        "    print(print('Accuracy of the network on the  test images: {} '.format(correct / total)))\n",
        "    return (100 * correct / total)\n",
        "  else:\n",
        "    print('Accuracy of the network on the  training images: {}'.format( correct / total))\n",
        "    return (100 * correct / total)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEAwvBOyuOg9"
      },
      "source": [
        "Apply Trainning and Testing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b31caa1b-2b87-40d1-ba38-092b8ca14f69",
        "id": "VEOi5SZ-uOg9"
      },
      "source": [
        "optimizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Adam (\n",
              "Parameter Group 0\n",
              "    amsgrad: False\n",
              "    betas: (0.9, 0.999)\n",
              "    eps: 1e-08\n",
              "    lr: 0.01\n",
              "    weight_decay: 0\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AQAXyNfuOg9"
      },
      "source": [
        "#scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.5)\n",
        "#scheduler = optim.lr_scheduler.ConstantLR(optimizer, factor=0.8, total_iters=10)\n",
        "def train_and_test(times, epoch):\n",
        "  loss = []\n",
        "  val_acc = []\n",
        "  train_acc = []\n",
        "  for time in range(times):\n",
        "    print(\"Training for the\", time+1, '-th times')\n",
        "    loss.extend(train_model(convNet, optimizer, epoch, trainloader))\n",
        "    if time == times-1:\n",
        "      train_acc.append(test_model (convNet, trainloader, training=True))\n",
        "      val_acc.append(test_model (convNet, testloader))\n",
        "      break\n",
        "      \n",
        "    train_acc.append(test_model (convNet, trainloader, training=True))\n",
        "    val_acc.append(test_model (convNet, testloader))\n",
        "  return loss, train_acc, val_acc\n",
        "  '''\n",
        "  num_times = np.array(range(1,times+1))\n",
        "  num_epoch = np.array(range(1,times*epoch+1))\n",
        "  plt.plot(num_epoch, loss)\n",
        "  plt.title(\"training loss vs epochs\")\n",
        "  plt.show()\n",
        "\n",
        "  plt.plot(num_times, train_acc, label=\"training\")\n",
        "  plt.plot(num_times, val_acc, label=\"validation\")\n",
        "  plt.title(\"accuracy vs training times\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  '''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3K0z0zzuOg9"
      },
      "source": [
        "def draw_graph(times, epoch, loss, train_acc, val_acc):\n",
        "  num_times = np.array(range(1,times+1))\n",
        "  num_epoch = np.array(range(1,times*epoch+1))\n",
        "  plt.plot(num_epoch, loss)\n",
        "  plt.title(\"training loss vs epochs\")\n",
        "  plt.xlabel('epoch')\n",
        "  plt.ylabel('training loss')\n",
        "  plt.show()\n",
        "\n",
        "  plt.plot(num_times, train_acc, label=\"training\")\n",
        "  plt.plot(num_times, val_acc, label=\"validation\")\n",
        "  plt.title(\"accuracy vs training times\")\n",
        "  plt.xlabel('times')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19b323e8-6af6-41e3-e587-1e8ba405e68f",
        "id": "rK-E-o9zuOg-"
      },
      "source": [
        "loss, train_acc, val_acc = train_and_test(33, 3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for the 1 -th times\n",
            "the 0 th epoch...\n",
            "100 mini-batch of 0 -th epoch train loss : 4.597432384490967\n",
            "200 mini-batch of 0 -th epoch train loss : 4.242462661266327\n",
            "300 mini-batch of 0 -th epoch train loss : 4.111354784965515\n",
            "400 mini-batch of 0 -th epoch train loss : 3.99225656747818\n",
            "the 1 th epoch...\n",
            "100 mini-batch of 1 -th epoch train loss : 5.82615553855896\n",
            "200 mini-batch of 1 -th epoch train loss : 3.801353032588959\n",
            "300 mini-batch of 1 -th epoch train loss : 3.7527927017211913\n",
            "400 mini-batch of 1 -th epoch train loss : 3.7085210990905764\n",
            "the 2 th epoch...\n",
            "100 mini-batch of 2 -th epoch train loss : 5.410656805038452\n",
            "200 mini-batch of 2 -th epoch train loss : 3.5527931475639343\n",
            "300 mini-batch of 2 -th epoch train loss : 3.5385106658935546\n",
            "400 mini-batch of 2 -th epoch train loss : 3.474556188583374\n",
            "Accuracy of the network on the  training images: 0.17242222222222223\n",
            "Accuracy of the network on the  test images: 0.1628 \n",
            "None\n",
            "Training for the 2 -th times\n",
            "the 0 th epoch...\n",
            "100 mini-batch of 0 -th epoch train loss : 3.376616940498352\n",
            "200 mini-batch of 0 -th epoch train loss : 3.404699053764343\n",
            "300 mini-batch of 0 -th epoch train loss : 3.336414840221405\n",
            "400 mini-batch of 0 -th epoch train loss : 3.2579846143722535\n",
            "the 1 th epoch...\n",
            "100 mini-batch of 1 -th epoch train loss : 4.783384897708893\n",
            "200 mini-batch of 1 -th epoch train loss : 3.157713522911072\n",
            "300 mini-batch of 1 -th epoch train loss : 3.1005606722831724\n",
            "400 mini-batch of 1 -th epoch train loss : 3.0708670663833617\n",
            "the 2 th epoch...\n",
            "100 mini-batch of 2 -th epoch train loss : 4.512218618392945\n",
            "200 mini-batch of 2 -th epoch train loss : 2.984299590587616\n",
            "300 mini-batch of 2 -th epoch train loss : 2.967727963924408\n",
            "400 mini-batch of 2 -th epoch train loss : 2.8907282304763795\n",
            "Accuracy of the network on the  training images: 0.2804888888888889\n",
            "Accuracy of the network on the  test images: 0.2724 \n",
            "None\n",
            "Training for the 3 -th times\n",
            "the 0 th epoch...\n",
            "100 mini-batch of 0 -th epoch train loss : 2.8777273726463317\n",
            "200 mini-batch of 0 -th epoch train loss : 2.8539264178276063\n",
            "300 mini-batch of 0 -th epoch train loss : 2.8302070021629335\n",
            "400 mini-batch of 0 -th epoch train loss : 2.8145227789878846\n",
            "the 1 th epoch...\n",
            "100 mini-batch of 1 -th epoch train loss : 4.189365305900574\n",
            "200 mini-batch of 1 -th epoch train loss : 2.7748293709754943\n",
            "300 mini-batch of 1 -th epoch train loss : 2.734639599323273\n",
            "400 mini-batch of 1 -th epoch train loss : 2.750469236373901\n",
            "the 2 th epoch...\n",
            "100 mini-batch of 2 -th epoch train loss : 4.044997715950013\n",
            "200 mini-batch of 2 -th epoch train loss : 2.6896409964561463\n",
            "300 mini-batch of 2 -th epoch train loss : 2.683092668056488\n",
            "400 mini-batch of 2 -th epoch train loss : 2.6464724111557008\n",
            "Accuracy of the network on the  training images: 0.3287111111111111\n",
            "Accuracy of the network on the  test images: 0.3054 \n",
            "None\n",
            "Training for the 4 -th times\n",
            "the 0 th epoch...\n",
            "100 mini-batch of 0 -th epoch train loss : 2.546927273273468\n",
            "200 mini-batch of 0 -th epoch train loss : 2.6036079001426695\n",
            "300 mini-batch of 0 -th epoch train loss : 2.6059024310112\n",
            "400 mini-batch of 0 -th epoch train loss : 2.6055033087730406\n",
            "the 1 th epoch...\n",
            "100 mini-batch of 1 -th epoch train loss : 3.7979687571525576\n",
            "200 mini-batch of 1 -th epoch train loss : 2.538490905761719\n",
            "300 mini-batch of 1 -th epoch train loss : 2.5579923152923585\n",
            "400 mini-batch of 1 -th epoch train loss : 2.514381629228592\n",
            "the 2 th epoch...\n",
            "100 mini-batch of 2 -th epoch train loss : 3.736380760669708\n",
            "200 mini-batch of 2 -th epoch train loss : 2.4674952173233033\n",
            "300 mini-batch of 2 -th epoch train loss : 2.506380441188812\n",
            "400 mini-batch of 2 -th epoch train loss : 2.4651595973968505\n",
            "Accuracy of the network on the  training images: 0.3592222222222222\n",
            "Accuracy of the network on the  test images: 0.3162 \n",
            "None\n",
            "Training for the 5 -th times\n",
            "the 0 th epoch...\n",
            "100 mini-batch of 0 -th epoch train loss : 2.4123956954479215\n",
            "200 mini-batch of 0 -th epoch train loss : 2.4287019419670104\n",
            "300 mini-batch of 0 -th epoch train loss : 2.4779997277259826\n",
            "400 mini-batch of 0 -th epoch train loss : 2.4161124205589295\n",
            "the 1 th epoch...\n",
            "100 mini-batch of 1 -th epoch train loss : 3.577931867837906\n",
            "200 mini-batch of 1 -th epoch train loss : 2.354398719072342\n",
            "300 mini-batch of 1 -th epoch train loss : 2.4292867279052732\n",
            "400 mini-batch of 1 -th epoch train loss : 2.393105351924896\n",
            "the 2 th epoch...\n",
            "100 mini-batch of 2 -th epoch train loss : 3.5174359500408174\n",
            "200 mini-batch of 2 -th epoch train loss : 2.3604514169692994\n",
            "300 mini-batch of 2 -th epoch train loss : 2.336487842798233\n",
            "400 mini-batch of 2 -th epoch train loss : 2.396954034566879\n",
            "Accuracy of the network on the  training images: 0.3864666666666667\n",
            "Accuracy of the network on the  test images: 0.338 \n",
            "None\n",
            "Training for the 6 -th times\n",
            "the 0 th epoch...\n",
            "100 mini-batch of 0 -th epoch train loss : 2.2857738649845123\n",
            "200 mini-batch of 0 -th epoch train loss : 2.300964124202728\n",
            "300 mini-batch of 0 -th epoch train loss : 2.3055599319934843\n",
            "400 mini-batch of 0 -th epoch train loss : 2.306623876094818\n",
            "the 1 th epoch...\n",
            "100 mini-batch of 1 -th epoch train loss : 3.3951655066013338\n",
            "200 mini-batch of 1 -th epoch train loss : 2.2758252215385437\n",
            "300 mini-batch of 1 -th epoch train loss : 2.2800797522068024\n",
            "400 mini-batch of 1 -th epoch train loss : 2.2889936292171478\n",
            "the 2 th epoch...\n",
            "100 mini-batch of 2 -th epoch train loss : 3.3846891045570375\n",
            "200 mini-batch of 2 -th epoch train loss : 2.2347917568683626\n",
            "300 mini-batch of 2 -th epoch train loss : 2.248976948261261\n",
            "400 mini-batch of 2 -th epoch train loss : 2.2463419008255006\n",
            "Accuracy of the network on the  training images: 0.4209555555555556\n",
            "Accuracy of the network on the  test images: 0.3638 \n",
            "None\n",
            "Training for the 7 -th times\n",
            "the 0 th epoch...\n",
            "100 mini-batch of 0 -th epoch train loss : 2.1441666650772095\n",
            "200 mini-batch of 0 -th epoch train loss : 2.2291188502311705\n",
            "300 mini-batch of 0 -th epoch train loss : 2.224506813287735\n",
            "400 mini-batch of 0 -th epoch train loss : 2.19895220041275\n",
            "the 1 th epoch...\n",
            "100 mini-batch of 1 -th epoch train loss : 3.2447903001308442\n",
            "200 mini-batch of 1 -th epoch train loss : 2.2038408756256103\n",
            "300 mini-batch of 1 -th epoch train loss : 2.1656029343605043\n",
            "400 mini-batch of 1 -th epoch train loss : 2.241311959028244\n",
            "the 2 th epoch...\n",
            "100 mini-batch of 2 -th epoch train loss : 3.268090077638626\n",
            "200 mini-batch of 2 -th epoch train loss : 2.172158601284027\n",
            "300 mini-batch of 2 -th epoch train loss : 2.163606140613556\n",
            "400 mini-batch of 2 -th epoch train loss : 2.178445760011673\n",
            "Accuracy of the network on the  training images: 0.4334\n",
            "Accuracy of the network on the  test images: 0.3626 \n",
            "None\n",
            "Training for the 8 -th times\n",
            "the 0 th epoch...\n",
            "100 mini-batch of 0 -th epoch train loss : 2.072098082304001\n",
            "200 mini-batch of 0 -th epoch train loss : 2.1230985164642333\n",
            "300 mini-batch of 0 -th epoch train loss : 2.1546390783786773\n",
            "400 mini-batch of 0 -th epoch train loss : 2.1575262224674225\n",
            "the 1 th epoch...\n",
            "100 mini-batch of 1 -th epoch train loss : 3.199310141801834\n",
            "200 mini-batch of 1 -th epoch train loss : 2.1070365691185\n",
            "300 mini-batch of 1 -th epoch train loss : 2.1187285685539248\n",
            "400 mini-batch of 1 -th epoch train loss : 2.13418816447258\n",
            "the 2 th epoch...\n",
            "100 mini-batch of 2 -th epoch train loss : 3.141401413679123\n",
            "200 mini-batch of 2 -th epoch train loss : 2.0498687613010405\n",
            "300 mini-batch of 2 -th epoch train loss : 2.1085796189308166\n",
            "400 mini-batch of 2 -th epoch train loss : 2.117410087585449\n",
            "Accuracy of the network on the  training images: 0.4528\n",
            "Accuracy of the network on the  test images: 0.3818 \n",
            "None\n",
            "Training for the 9 -th times\n",
            "the 0 th epoch...\n",
            "100 mini-batch of 0 -th epoch train loss : 2.0495567464828492\n",
            "200 mini-batch of 0 -th epoch train loss : 2.0885208582878114\n",
            "300 mini-batch of 0 -th epoch train loss : 2.053371613025665\n",
            "400 mini-batch of 0 -th epoch train loss : 2.0639634311199186\n",
            "the 1 th epoch...\n",
            "100 mini-batch of 1 -th epoch train loss : 3.080861192941666\n",
            "200 mini-batch of 1 -th epoch train loss : 2.077612369060516\n",
            "300 mini-batch of 1 -th epoch train loss : 2.0589085257053377\n",
            "400 mini-batch of 1 -th epoch train loss : 2.0832679259777067\n",
            "the 2 th epoch...\n",
            "100 mini-batch of 2 -th epoch train loss : 3.0368358623981475\n",
            "200 mini-batch of 2 -th epoch train loss : 2.035795615911484\n",
            "300 mini-batch of 2 -th epoch train loss : 2.0564048182964325\n",
            "400 mini-batch of 2 -th epoch train loss : 2.051836755275726\n",
            "Accuracy of the network on the  training images: 0.4604888888888889\n",
            "Accuracy of the network on the  test images: 0.3836 \n",
            "None\n",
            "Training for the 10 -th times\n",
            "the 0 th epoch...\n",
            "100 mini-batch of 0 -th epoch train loss : 1.9572901451587676\n",
            "200 mini-batch of 0 -th epoch train loss : 2.0152437782287596\n",
            "300 mini-batch of 0 -th epoch train loss : 2.0421286714076996\n",
            "400 mini-batch of 0 -th epoch train loss : 2.0614768946170807\n",
            "the 1 th epoch...\n",
            "100 mini-batch of 1 -th epoch train loss : 3.0094838511943816\n",
            "200 mini-batch of 1 -th epoch train loss : 2.0114449095726012\n",
            "300 mini-batch of 1 -th epoch train loss : 2.0405399060249327\n",
            "400 mini-batch of 1 -th epoch train loss : 2.009954525232315\n",
            "the 2 th epoch...\n",
            "100 mini-batch of 2 -th epoch train loss : 2.958361726999283\n",
            "200 mini-batch of 2 -th epoch train loss : 1.967636524438858\n",
            "300 mini-batch of 2 -th epoch train loss : 1.983502494096756\n",
            "400 mini-batch of 2 -th epoch train loss : 2.019063676595688\n",
            "Accuracy of the network on the  training images: 0.47884444444444446\n",
            "Accuracy of the network on the  test images: 0.3776 \n",
            "None\n",
            "Training for the 11 -th times\n",
            "the 0 th epoch...\n",
            "100 mini-batch of 0 -th epoch train loss : 1.9537724030017853\n",
            "200 mini-batch of 0 -th epoch train loss : 1.9677449142932892\n",
            "300 mini-batch of 0 -th epoch train loss : 1.96273610830307\n",
            "400 mini-batch of 0 -th epoch train loss : 2.006731451749802\n",
            "the 1 th epoch...\n",
            "100 mini-batch of 1 -th epoch train loss : 2.9129149651527406\n",
            "200 mini-batch of 1 -th epoch train loss : 1.9324056422710418\n",
            "300 mini-batch of 1 -th epoch train loss : 1.9682476031780243\n",
            "400 mini-batch of 1 -th epoch train loss : 1.9667593955993652\n",
            "the 2 th epoch...\n",
            "100 mini-batch of 2 -th epoch train loss : 2.9389318764209746\n",
            "200 mini-batch of 2 -th epoch train loss : 1.954803651571274\n",
            "300 mini-batch of 2 -th epoch train loss : 1.9555569791793823\n",
            "400 mini-batch of 2 -th epoch train loss : 1.9632907140254974\n",
            "Accuracy of the network on the  training images: 0.47604444444444444\n",
            "Accuracy of the network on the  test images: 0.373 \n",
            "None\n",
            "Training for the 12 -th times\n",
            "the 0 th epoch...\n",
            "100 mini-batch of 0 -th epoch train loss : 1.8853166687488556\n",
            "200 mini-batch of 0 -th epoch train loss : 1.9510213088989259\n",
            "300 mini-batch of 0 -th epoch train loss : 1.9580425477027894\n",
            "400 mini-batch of 0 -th epoch train loss : 1.9554155921936036\n",
            "the 1 th epoch...\n",
            "100 mini-batch of 1 -th epoch train loss : 2.857154006958008\n",
            "200 mini-batch of 1 -th epoch train loss : 1.8996447122097015\n",
            "300 mini-batch of 1 -th epoch train loss : 1.931934187412262\n",
            "400 mini-batch of 1 -th epoch train loss : 1.9214494931697845\n",
            "the 2 th epoch...\n",
            "100 mini-batch of 2 -th epoch train loss : 2.7871413052082064\n",
            "200 mini-batch of 2 -th epoch train loss : 1.8850883316993714\n",
            "300 mini-batch of 2 -th epoch train loss : 1.9386859357357025\n",
            "400 mini-batch of 2 -th epoch train loss : 1.9514975786209106\n",
            "Accuracy of the network on the  training images: 0.48113333333333336\n",
            "Accuracy of the network on the  test images: 0.3744 \n",
            "None\n",
            "Training for the 13 -th times\n",
            "the 0 th epoch...\n",
            "100 mini-batch of 0 -th epoch train loss : 1.8325491905212403\n",
            "200 mini-batch of 0 -th epoch train loss : 1.8969756090641021\n",
            "300 mini-batch of 0 -th epoch train loss : 1.894170002937317\n",
            "400 mini-batch of 0 -th epoch train loss : 1.9197206556797028\n",
            "the 1 th epoch...\n",
            "100 mini-batch of 1 -th epoch train loss : 2.8376832854747773\n",
            "200 mini-batch of 1 -th epoch train loss : 1.8739738309383391\n",
            "300 mini-batch of 1 -th epoch train loss : 1.9027982676029205\n",
            "400 mini-batch of 1 -th epoch train loss : 1.8812976634502412\n",
            "the 2 th epoch...\n",
            "100 mini-batch of 2 -th epoch train loss : 2.7536260330677034\n",
            "200 mini-batch of 2 -th epoch train loss : 1.8603180265426635\n",
            "300 mini-batch of 2 -th epoch train loss : 1.851682552099228\n",
            "400 mini-batch of 2 -th epoch train loss : 1.9053894460201264\n",
            "Accuracy of the network on the  training images: 0.49275555555555556\n",
            "Accuracy of the network on the  test images: 0.3744 \n",
            "None\n",
            "Training for the 14 -th times\n",
            "the 0 th epoch...\n",
            "100 mini-batch of 0 -th epoch train loss : 1.8189761352539062\n",
            "200 mini-batch of 0 -th epoch train loss : 1.8576665139198303\n",
            "300 mini-batch of 0 -th epoch train loss : 1.8823667228221894\n",
            "400 mini-batch of 0 -th epoch train loss : 1.8848143100738526\n",
            "the 1 th epoch...\n",
            "100 mini-batch of 1 -th epoch train loss : 2.7681584656238556\n",
            "200 mini-batch of 1 -th epoch train loss : 1.8100024545192719\n",
            "300 mini-batch of 1 -th epoch train loss : 1.8694066214561462\n",
            "400 mini-batch of 1 -th epoch train loss : 1.9066556286811829\n",
            "the 2 th epoch...\n",
            "100 mini-batch of 2 -th epoch train loss : 2.724078559875488\n",
            "200 mini-batch of 2 -th epoch train loss : 1.8483658599853516\n",
            "300 mini-batch of 2 -th epoch train loss : 1.865597608089447\n",
            "400 mini-batch of 2 -th epoch train loss : 1.8513762307167054\n",
            "Accuracy of the network on the  training images: 0.5031111111111111\n",
            "Accuracy of the network on the  test images: 0.3906 \n",
            "None\n",
            "Training for the 15 -th times\n",
            "the 0 th epoch...\n",
            "100 mini-batch of 0 -th epoch train loss : 1.7428236865997315\n",
            "200 mini-batch of 0 -th epoch train loss : 1.85263134598732\n",
            "300 mini-batch of 0 -th epoch train loss : 1.8438934206962585\n",
            "400 mini-batch of 0 -th epoch train loss : 1.8467321002483368\n",
            "the 1 th epoch...\n",
            "100 mini-batch of 1 -th epoch train loss : 2.730276200771332\n",
            "200 mini-batch of 1 -th epoch train loss : 1.8059210884571075\n",
            "300 mini-batch of 1 -th epoch train loss : 1.8472522962093354\n",
            "400 mini-batch of 1 -th epoch train loss : 1.8483622014522552\n",
            "the 2 th epoch...\n",
            "100 mini-batch of 2 -th epoch train loss : 2.695634136199951\n",
            "200 mini-batch of 2 -th epoch train loss : 1.81610511302948\n",
            "300 mini-batch of 2 -th epoch train loss : 1.8012230825424194\n",
            "400 mini-batch of 2 -th epoch train loss : 1.8501334393024444\n",
            "Accuracy of the network on the  training images: 0.5121111111111111\n",
            "Accuracy of the network on the  test images: 0.3804 \n",
            "None\n",
            "Training for the 16 -th times\n",
            "the 0 th epoch...\n",
            "100 mini-batch of 0 -th epoch train loss : 1.7395662760734558\n",
            "200 mini-batch of 0 -th epoch train loss : 1.7869342184066772\n",
            "300 mini-batch of 0 -th epoch train loss : 1.8320777785778046\n",
            "400 mini-batch of 0 -th epoch train loss : 1.8455608701705932\n",
            "the 1 th epoch...\n",
            "100 mini-batch of 1 -th epoch train loss : 2.638287305831909\n",
            "200 mini-batch of 1 -th epoch train loss : 1.8057058572769165\n",
            "300 mini-batch of 1 -th epoch train loss : 1.7917290449142456\n",
            "400 mini-batch of 1 -th epoch train loss : 1.8193667900562287\n",
            "the 2 th epoch...\n",
            "100 mini-batch of 2 -th epoch train loss : 2.645114526748657\n",
            "200 mini-batch of 2 -th epoch train loss : 1.7946101593971253\n",
            "300 mini-batch of 2 -th epoch train loss : 1.8039147770404815\n",
            "400 mini-batch of 2 -th epoch train loss : 1.8236595797538757\n",
            "Accuracy of the network on the  training images: 0.5183777777777778\n",
            "Accuracy of the network on the  test images: 0.3842 \n",
            "None\n",
            "Training for the 17 -th times\n",
            "the 0 th epoch...\n",
            "100 mini-batch of 0 -th epoch train loss : 1.73131232380867\n",
            "200 mini-batch of 0 -th epoch train loss : 1.7866056859493256\n",
            "300 mini-batch of 0 -th epoch train loss : 1.8056812262535096\n",
            "400 mini-batch of 0 -th epoch train loss : 1.7891787195205688\n",
            "the 1 th epoch...\n",
            "100 mini-batch of 1 -th epoch train loss : 2.652903425693512\n",
            "200 mini-batch of 1 -th epoch train loss : 1.7350382435321807\n",
            "300 mini-batch of 1 -th epoch train loss : 1.754535390138626\n",
            "400 mini-batch of 1 -th epoch train loss : 1.8214862167835235\n",
            "the 2 th epoch...\n",
            "100 mini-batch of 2 -th epoch train loss : 2.666584095954895\n",
            "200 mini-batch of 2 -th epoch train loss : 1.7732457089424134\n",
            "300 mini-batch of 2 -th epoch train loss : 1.7637910628318787\n",
            "400 mini-batch of 2 -th epoch train loss : 1.790156272649765\n",
            "Accuracy of the network on the  training images: 0.5264888888888889\n",
            "Accuracy of the network on the  test images: 0.4012 \n",
            "None\n",
            "Training for the 18 -th times\n",
            "the 0 th epoch...\n",
            "100 mini-batch of 0 -th epoch train loss : 1.7163272631168365\n",
            "200 mini-batch of 0 -th epoch train loss : 1.7377096176147462\n",
            "300 mini-batch of 0 -th epoch train loss : 1.7440687596797944\n",
            "400 mini-batch of 0 -th epoch train loss : 1.8157959365844727\n",
            "the 1 th epoch...\n",
            "100 mini-batch of 1 -th epoch train loss : 2.5961909079551697\n",
            "200 mini-batch of 1 -th epoch train loss : 1.7090558218955993\n",
            "300 mini-batch of 1 -th epoch train loss : 1.7456631124019624\n",
            "400 mini-batch of 1 -th epoch train loss : 1.780297964811325\n",
            "the 2 th epoch...\n",
            "100 mini-batch of 2 -th epoch train loss : 2.6114643466472627\n",
            "200 mini-batch of 2 -th epoch train loss : 1.7411098241806031\n",
            "300 mini-batch of 2 -th epoch train loss : 1.7483558499813079\n",
            "400 mini-batch of 2 -th epoch train loss : 1.7736306226253509\n",
            "Accuracy of the network on the  training images: 0.5283111111111111\n",
            "Accuracy of the network on the  test images: 0.3878 \n",
            "None\n",
            "Training for the 19 -th times\n",
            "the 0 th epoch...\n",
            "100 mini-batch of 0 -th epoch train loss : 1.6860117292404175\n",
            "200 mini-batch of 0 -th epoch train loss : 1.7165595555305482\n",
            "300 mini-batch of 0 -th epoch train loss : 1.7509119391441346\n",
            "400 mini-batch of 0 -th epoch train loss : 1.7671784377098083\n",
            "the 1 th epoch...\n",
            "100 mini-batch of 1 -th epoch train loss : 2.561004875898361\n",
            "200 mini-batch of 1 -th epoch train loss : 1.7231118595600128\n",
            "300 mini-batch of 1 -th epoch train loss : 1.7564414858818054\n",
            "400 mini-batch of 1 -th epoch train loss : 1.7360619235038757\n",
            "the 2 th epoch...\n",
            "100 mini-batch of 2 -th epoch train loss : 2.5483279037475586\n",
            "200 mini-batch of 2 -th epoch train loss : 1.7280839991569519\n",
            "300 mini-batch of 2 -th epoch train loss : 1.7176782536506652\n",
            "400 mini-batch of 2 -th epoch train loss : 1.7712949955463408\n",
            "Accuracy of the network on the  training images: 0.5229111111111111\n",
            "Accuracy of the network on the  test images: 0.3892 \n",
            "None\n",
            "Training for the 20 -th times\n",
            "the 0 th epoch...\n",
            "100 mini-batch of 0 -th epoch train loss : 1.6514074766635896\n",
            "200 mini-batch of 0 -th epoch train loss : 1.7239547264575958\n",
            "300 mini-batch of 0 -th epoch train loss : 1.741294540166855\n",
            "400 mini-batch of 0 -th epoch train loss : 1.7561844658851624\n",
            "the 1 th epoch...\n",
            "100 mini-batch of 1 -th epoch train loss : 2.5464213621616363\n",
            "200 mini-batch of 1 -th epoch train loss : 1.7176644897460938\n",
            "300 mini-batch of 1 -th epoch train loss : 1.7273123681545257\n",
            "400 mini-batch of 1 -th epoch train loss : 1.7427106928825378\n",
            "the 2 th epoch...\n",
            "100 mini-batch of 2 -th epoch train loss : 2.563700280189514\n",
            "200 mini-batch of 2 -th epoch train loss : 1.6846127593517304\n",
            "300 mini-batch of 2 -th epoch train loss : 1.7433083152770996\n",
            "400 mini-batch of 2 -th epoch train loss : 1.7354555380344392\n",
            "Accuracy of the network on the  training images: 0.5332444444444444\n",
            "Accuracy of the network on the  test images: 0.3866 \n",
            "None\n",
            "Training for the 21 -th times\n",
            "the 0 th epoch...\n",
            "100 mini-batch of 0 -th epoch train loss : 1.652658952474594\n",
            "200 mini-batch of 0 -th epoch train loss : 1.7025857710838317\n",
            "300 mini-batch of 0 -th epoch train loss : 1.7028011357784272\n",
            "400 mini-batch of 0 -th epoch train loss : 1.765682806968689\n",
            "the 1 th epoch...\n",
            "100 mini-batch of 1 -th epoch train loss : 2.5508604395389556\n",
            "200 mini-batch of 1 -th epoch train loss : 1.7060502278804779\n",
            "300 mini-batch of 1 -th epoch train loss : 1.7073449051380158\n",
            "400 mini-batch of 1 -th epoch train loss : 1.7185134065151215\n",
            "the 2 th epoch...\n",
            "100 mini-batch of 2 -th epoch train loss : 2.5014246487617493\n",
            "200 mini-batch of 2 -th epoch train loss : 1.6744399642944336\n",
            "300 mini-batch of 2 -th epoch train loss : 1.6726624441146851\n",
            "400 mini-batch of 2 -th epoch train loss : 1.726792515516281\n",
            "Accuracy of the network on the  training images: 0.5410666666666667\n",
            "Accuracy of the network on the  test images: 0.3954 \n",
            "None\n",
            "Training for the 22 -th times\n",
            "the 0 th epoch...\n",
            "100 mini-batch of 0 -th epoch train loss : 1.6470203268527985\n",
            "200 mini-batch of 0 -th epoch train loss : 1.6850224757194519\n",
            "300 mini-batch of 0 -th epoch train loss : 1.6801465141773224\n",
            "400 mini-batch of 0 -th epoch train loss : 1.755138589143753\n",
            "the 1 th epoch...\n",
            "100 mini-batch of 1 -th epoch train loss : 2.46890110373497\n",
            "200 mini-batch of 1 -th epoch train loss : 1.6872655618190766\n",
            "300 mini-batch of 1 -th epoch train loss : 1.6737624025344848\n",
            "400 mini-batch of 1 -th epoch train loss : 1.7317083954811097\n",
            "the 2 th epoch...\n",
            "100 mini-batch of 2 -th epoch train loss : 2.517885969877243\n",
            "200 mini-batch of 2 -th epoch train loss : 1.6576203465461732\n",
            "300 mini-batch of 2 -th epoch train loss : 1.656732414960861\n",
            "400 mini-batch of 2 -th epoch train loss : 1.688923921585083\n",
            "Accuracy of the network on the  training images: 0.542\n",
            "Accuracy of the network on the  test images: 0.39 \n",
            "None\n",
            "Training for the 23 -th times\n",
            "the 0 th epoch...\n",
            "100 mini-batch of 0 -th epoch train loss : 1.6355401587486267\n",
            "200 mini-batch of 0 -th epoch train loss : 1.6625720131397248\n",
            "300 mini-batch of 0 -th epoch train loss : 1.6549515581130982\n",
            "400 mini-batch of 0 -th epoch train loss : 1.724073407649994\n",
            "the 1 th epoch...\n",
            "100 mini-batch of 1 -th epoch train loss : 2.460754418373108\n",
            "200 mini-batch of 1 -th epoch train loss : 1.665577805042267\n",
            "300 mini-batch of 1 -th epoch train loss : 1.6715011751651765\n",
            "400 mini-batch of 1 -th epoch train loss : 1.7052949023246766\n",
            "the 2 th epoch...\n",
            "100 mini-batch of 2 -th epoch train loss : 2.4142821788787843\n",
            "200 mini-batch of 2 -th epoch train loss : 1.6261470198631287\n",
            "300 mini-batch of 2 -th epoch train loss : 1.663346482515335\n",
            "400 mini-batch of 2 -th epoch train loss : 1.7311778283119201\n",
            "Accuracy of the network on the  training images: 0.5504444444444444\n",
            "Accuracy of the network on the  test images: 0.3866 \n",
            "None\n",
            "Training for the 24 -th times\n",
            "the 0 th epoch...\n",
            "100 mini-batch of 0 -th epoch train loss : 1.6164871072769165\n",
            "200 mini-batch of 0 -th epoch train loss : 1.6362845063209535\n",
            "300 mini-batch of 0 -th epoch train loss : 1.6722872745990753\n",
            "400 mini-batch of 0 -th epoch train loss : 1.6659164822101593\n",
            "the 1 th epoch...\n",
            "100 mini-batch of 1 -th epoch train loss : 2.462225080728531\n",
            "200 mini-batch of 1 -th epoch train loss : 1.6315612721443176\n",
            "300 mini-batch of 1 -th epoch train loss : 1.6633651518821717\n",
            "400 mini-batch of 1 -th epoch train loss : 1.690546988248825\n",
            "the 2 th epoch...\n",
            "100 mini-batch of 2 -th epoch train loss : 2.4826470494270323\n",
            "200 mini-batch of 2 -th epoch train loss : 1.6318554186820984\n",
            "300 mini-batch of 2 -th epoch train loss : 1.654684635400772\n",
            "400 mini-batch of 2 -th epoch train loss : 1.6775485610961913\n",
            "Accuracy of the network on the  training images: 0.5411555555555555\n",
            "Accuracy of the network on the  test images: 0.3842 \n",
            "None\n",
            "Training for the 25 -th times\n",
            "the 0 th epoch...\n",
            "100 mini-batch of 0 -th epoch train loss : 1.6161795830726624\n",
            "200 mini-batch of 0 -th epoch train loss : 1.6176330208778382\n",
            "300 mini-batch of 0 -th epoch train loss : 1.6448267006874084\n",
            "400 mini-batch of 0 -th epoch train loss : 1.6659605753421785\n",
            "the 1 th epoch...\n",
            "100 mini-batch of 1 -th epoch train loss : 2.428647812604904\n",
            "200 mini-batch of 1 -th epoch train loss : 1.6160544705390931\n",
            "300 mini-batch of 1 -th epoch train loss : 1.629349217414856\n",
            "400 mini-batch of 1 -th epoch train loss : 1.6557168185710907\n",
            "the 2 th epoch...\n",
            "100 mini-batch of 2 -th epoch train loss : 2.427945514917374\n",
            "200 mini-batch of 2 -th epoch train loss : 1.6337959349155426\n",
            "300 mini-batch of 2 -th epoch train loss : 1.660497806072235\n",
            "400 mini-batch of 2 -th epoch train loss : 1.6530753672122955\n",
            "Accuracy of the network on the  training images: 0.539\n",
            "Accuracy of the network on the  test images: 0.3812 \n",
            "None\n",
            "Training for the 26 -th times\n",
            "the 0 th epoch...\n",
            "100 mini-batch of 0 -th epoch train loss : 1.5730625307559967\n",
            "200 mini-batch of 0 -th epoch train loss : 1.5978002226352692\n",
            "300 mini-batch of 0 -th epoch train loss : 1.6409733951091767\n",
            "400 mini-batch of 0 -th epoch train loss : 1.676526528596878\n",
            "the 1 th epoch...\n",
            "100 mini-batch of 1 -th epoch train loss : 2.4049447214603425\n",
            "200 mini-batch of 1 -th epoch train loss : 1.6199793350696563\n",
            "300 mini-batch of 1 -th epoch train loss : 1.6196499168872833\n",
            "400 mini-batch of 1 -th epoch train loss : 1.6418533742427825\n",
            "the 2 th epoch...\n",
            "100 mini-batch of 2 -th epoch train loss : 2.378251637220383\n",
            "200 mini-batch of 2 -th epoch train loss : 1.6155847561359407\n",
            "300 mini-batch of 2 -th epoch train loss : 1.6120304620265962\n",
            "400 mini-batch of 2 -th epoch train loss : 1.6558060932159424\n",
            "Accuracy of the network on the  training images: 0.5405555555555556\n",
            "Accuracy of the network on the  test images: 0.3808 \n",
            "None\n",
            "Training for the 27 -th times\n",
            "the 0 th epoch...\n",
            "100 mini-batch of 0 -th epoch train loss : 1.5674437057971955\n",
            "200 mini-batch of 0 -th epoch train loss : 1.6046411836147307\n",
            "300 mini-batch of 0 -th epoch train loss : 1.614543616771698\n",
            "400 mini-batch of 0 -th epoch train loss : 1.617431948184967\n",
            "the 1 th epoch...\n",
            "100 mini-batch of 1 -th epoch train loss : 2.413801180124283\n",
            "200 mini-batch of 1 -th epoch train loss : 1.5955959117412568\n",
            "300 mini-batch of 1 -th epoch train loss : 1.602099347114563\n",
            "400 mini-batch of 1 -th epoch train loss : 1.6555283641815186\n",
            "the 2 th epoch...\n",
            "100 mini-batch of 2 -th epoch train loss : 2.3847711193561554\n",
            "200 mini-batch of 2 -th epoch train loss : 1.5833101999759673\n",
            "300 mini-batch of 2 -th epoch train loss : 1.6112131202220916\n",
            "400 mini-batch of 2 -th epoch train loss : 1.6307731282711029\n",
            "Accuracy of the network on the  training images: 0.5359333333333334\n",
            "Accuracy of the network on the  test images: 0.3764 \n",
            "None\n",
            "Training for the 28 -th times\n",
            "the 0 th epoch...\n",
            "100 mini-batch of 0 -th epoch train loss : 1.5718992531299592\n",
            "200 mini-batch of 0 -th epoch train loss : 1.6259067046642304\n",
            "300 mini-batch of 0 -th epoch train loss : 1.6359654939174653\n",
            "400 mini-batch of 0 -th epoch train loss : 1.6449976861476898\n",
            "the 1 th epoch...\n",
            "100 mini-batch of 1 -th epoch train loss : 2.366242994070053\n",
            "200 mini-batch of 1 -th epoch train loss : 1.5919287383556366\n",
            "300 mini-batch of 1 -th epoch train loss : 1.6295797383785249\n",
            "400 mini-batch of 1 -th epoch train loss : 1.6260702204704285\n",
            "the 2 th epoch...\n",
            "100 mini-batch of 2 -th epoch train loss : 2.3972200918197633\n",
            "200 mini-batch of 2 -th epoch train loss : 1.5723101806640625\n",
            "300 mini-batch of 2 -th epoch train loss : 1.6176524126529694\n",
            "400 mini-batch of 2 -th epoch train loss : 1.6104123902320862\n",
            "Accuracy of the network on the  training images: 0.5565555555555556\n",
            "Accuracy of the network on the  test images: 0.3752 \n",
            "None\n",
            "Training for the 29 -th times\n",
            "the 0 th epoch...\n",
            "100 mini-batch of 0 -th epoch train loss : 1.581262856721878\n",
            "200 mini-batch of 0 -th epoch train loss : 1.5683541560173035\n",
            "300 mini-batch of 0 -th epoch train loss : 1.6099208748340608\n",
            "400 mini-batch of 0 -th epoch train loss : 1.6172588062286377\n",
            "the 1 th epoch...\n",
            "100 mini-batch of 1 -th epoch train loss : 2.373282754421234\n",
            "200 mini-batch of 1 -th epoch train loss : 1.5919952178001404\n",
            "300 mini-batch of 1 -th epoch train loss : 1.592467713356018\n",
            "400 mini-batch of 1 -th epoch train loss : 1.632249323129654\n",
            "the 2 th epoch...\n",
            "100 mini-batch of 2 -th epoch train loss : 2.3356903171539307\n",
            "200 mini-batch of 2 -th epoch train loss : 1.5959715843200684\n",
            "300 mini-batch of 2 -th epoch train loss : 1.58980508685112\n",
            "400 mini-batch of 2 -th epoch train loss : 1.6195778560638427\n",
            "Accuracy of the network on the  training images: 0.5564888888888889\n",
            "Accuracy of the network on the  test images: 0.3878 \n",
            "None\n",
            "Training for the 30 -th times\n",
            "the 0 th epoch...\n",
            "100 mini-batch of 0 -th epoch train loss : 1.5460730516910552\n",
            "200 mini-batch of 0 -th epoch train loss : 1.5943260729312896\n",
            "300 mini-batch of 0 -th epoch train loss : 1.5908445370197297\n",
            "400 mini-batch of 0 -th epoch train loss : 1.5973565149307252\n",
            "the 1 th epoch...\n",
            "100 mini-batch of 1 -th epoch train loss : 2.345548313856125\n",
            "200 mini-batch of 1 -th epoch train loss : 1.5548714423179626\n",
            "300 mini-batch of 1 -th epoch train loss : 1.5611162567138672\n",
            "400 mini-batch of 1 -th epoch train loss : 1.604901248216629\n",
            "the 2 th epoch...\n",
            "100 mini-batch of 2 -th epoch train loss : 2.3463935446739197\n",
            "200 mini-batch of 2 -th epoch train loss : 1.5649538254737854\n",
            "300 mini-batch of 2 -th epoch train loss : 1.5890758073329925\n",
            "400 mini-batch of 2 -th epoch train loss : 1.6414165925979614\n",
            "Accuracy of the network on the  training images: 0.5545333333333333\n",
            "Accuracy of the network on the  test images: 0.379 \n",
            "None\n",
            "Training for the 31 -th times\n",
            "the 0 th epoch...\n",
            "100 mini-batch of 0 -th epoch train loss : 1.5344320940971374\n",
            "200 mini-batch of 0 -th epoch train loss : 1.5582965636253356\n",
            "300 mini-batch of 0 -th epoch train loss : 1.576121417284012\n",
            "400 mini-batch of 0 -th epoch train loss : 1.572803453207016\n",
            "the 1 th epoch...\n",
            "100 mini-batch of 1 -th epoch train loss : 2.3155356359481813\n",
            "200 mini-batch of 1 -th epoch train loss : 1.556219630241394\n",
            "300 mini-batch of 1 -th epoch train loss : 1.5610046672821045\n",
            "400 mini-batch of 1 -th epoch train loss : 1.5919823122024537\n",
            "the 2 th epoch...\n",
            "100 mini-batch of 2 -th epoch train loss : 2.2998858273029326\n",
            "200 mini-batch of 2 -th epoch train loss : 1.58378702044487\n",
            "300 mini-batch of 2 -th epoch train loss : 1.5745937848091125\n",
            "400 mini-batch of 2 -th epoch train loss : 1.574060539007187\n",
            "Accuracy of the network on the  training images: 0.5664666666666667\n",
            "Accuracy of the network on the  test images: 0.3942 \n",
            "None\n",
            "Training for the 32 -th times\n",
            "the 0 th epoch...\n",
            "100 mini-batch of 0 -th epoch train loss : 1.5065198570489884\n",
            "200 mini-batch of 0 -th epoch train loss : 1.5343827831745147\n",
            "300 mini-batch of 0 -th epoch train loss : 1.5611036813259125\n",
            "400 mini-batch of 0 -th epoch train loss : 1.6151457989215852\n",
            "the 1 th epoch...\n",
            "100 mini-batch of 1 -th epoch train loss : 2.3213065528869627\n",
            "200 mini-batch of 1 -th epoch train loss : 1.5424291729927062\n",
            "300 mini-batch of 1 -th epoch train loss : 1.5738894581794738\n",
            "400 mini-batch of 1 -th epoch train loss : 1.6022382378578186\n",
            "the 2 th epoch...\n",
            "100 mini-batch of 2 -th epoch train loss : 2.321335246562958\n",
            "200 mini-batch of 2 -th epoch train loss : 1.5665640008449555\n",
            "300 mini-batch of 2 -th epoch train loss : 1.5765796244144439\n",
            "400 mini-batch of 2 -th epoch train loss : 1.5715729022026061\n",
            "Accuracy of the network on the  training images: 0.5664222222222223\n",
            "Accuracy of the network on the  test images: 0.3874 \n",
            "None\n",
            "Training for the 33 -th times\n",
            "the 0 th epoch...\n",
            "100 mini-batch of 0 -th epoch train loss : 1.4621162068843843\n",
            "200 mini-batch of 0 -th epoch train loss : 1.5518725001811982\n",
            "300 mini-batch of 0 -th epoch train loss : 1.5257901418209077\n",
            "400 mini-batch of 0 -th epoch train loss : 1.6034875893592835\n",
            "the 1 th epoch...\n",
            "100 mini-batch of 1 -th epoch train loss : 2.3096240794658662\n",
            "200 mini-batch of 1 -th epoch train loss : 1.5181659030914307\n",
            "300 mini-batch of 1 -th epoch train loss : 1.5518676388263701\n",
            "400 mini-batch of 1 -th epoch train loss : 1.565297076702118\n",
            "the 2 th epoch...\n",
            "100 mini-batch of 2 -th epoch train loss : 2.2982246220111846\n",
            "200 mini-batch of 2 -th epoch train loss : 1.5462909400463105\n",
            "300 mini-batch of 2 -th epoch train loss : 1.541595309972763\n",
            "400 mini-batch of 2 -th epoch train loss : 1.5859531593322753\n",
            "Accuracy of the network on the  training images: 0.5571777777777778\n",
            "Accuracy of the network on the  test images: 0.3648 \n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "outputId": "a504a627-89a6-4964-9cb3-39285fd6aae5",
        "id": "ZMc6eB4muOg-"
      },
      "source": [
        "draw_graph(10, 3, loss, train_acc, val_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-548e56507ee9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdraw_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-30-760ea47f3d0b>\u001b[0m in \u001b[0;36mdraw_graph\u001b[0;34m(times, epoch, loss, train_acc, val_acc)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mnum_times\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mnum_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training loss vs epochs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2761\u001b[0m     return gca().plot(\n\u001b[1;32m   2762\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2763\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1645\u001b[0m         \"\"\"\n\u001b[1;32m   1646\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1647\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1648\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    343\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (30,) and (44649,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xv4rh2skuOg-"
      },
      "source": [
        "'''\n",
        "def draw_graph(loss, train_acc, val_acc):\n",
        "  #num_times = np.array(range(1,times+1))\n",
        "  #num_epoch = np.array(range(1,times*epoch+1))\n",
        "  plt.plot(loss)\n",
        "  #plt.plot(num_epoch, loss)\n",
        "  plt.title(\"training loss vs epochs\")\n",
        "  plt.show()\n",
        "\n",
        "  plt.plot(train_acc, label=\"training\")\n",
        "  plt.plot(val_acc, label=\"validation\")\n",
        "\n",
        "  #plt.plot(num_times, train_acc, label=\"training\")\n",
        "  #plt.plot(num_times, val_acc, label=\"validation\")\n",
        "  plt.title(\"accuracy vs training times\")\n",
        "  plt.show()\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jum5lxKruOg-"
      },
      "source": [
        "loss, train_acc, val_acc = train_and_test(1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDnnFakJuOg_"
      },
      "source": [
        "train_and_test(1, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xEGjDs4cuOg_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}